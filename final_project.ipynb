{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC5HnUvkAVBj"
      },
      "source": [
        "Imports and other things to start the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from fastparquet) (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from fastparquet) (2.1.3)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.9.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: fsspec in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\robbi\\appdata\\roaming\\python\\python311\\site-packages (from fastparquet) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\robbi\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\robbi\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl (671 kB)\n",
            "   ---------------------------------------- 0.0/671.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 671.0/671.0 kB 13.2 MB/s eta 0:00:00\n",
            "Downloading cramjam-2.9.1-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.1/2.1 MB 14.6 MB/s eta 0:00:00\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.9.1 fastparquet-2024.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vCbQXGK1AVrY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import psutil\n",
        "import json\n",
        "import urllib.request\n",
        "import fastparquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMg6fMnm_8ri"
      },
      "source": [
        "In order to properly use this data, we must start by importing it and then preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPQiszpK9qqe",
        "outputId": "6c9e4387-adfc-4998-b0d9-ae7e19eb814f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          hexsha   size ext    lang  \\\n",
            "0       f70001f658d4dfaa72dd4f0d1b3176492f6658bb   6442  py  Python   \n",
            "1       f7000273e22d5a0f2d5b40c38a0ed8511d1b8995   2250  py  Python   \n",
            "2       f70002926d1d600b4b068459c9dd40ebf3aef47d    757  py  Python   \n",
            "3       f7000327daf9ff11a381ce6d5de401ff007d1323   1094  py  Python   \n",
            "4       f7000371f0315cd55c0b14b33e7e8e56697cfc2e  10498  py  Python   \n",
            "...                                          ...    ...  ..     ...   \n",
            "117540  793e7c8154dde86884b9669622b32aeea1185d21   1853  py  Python   \n",
            "117541  793e7d1ab6c0471710bdbffc3c1b2a68e0aa3516    948  py  Python   \n",
            "117542  793e7e0a68202e76b818772ff6d01655ca87546e   2485  py  Python   \n",
            "117543  793e7ea61a6d183a0434da1b893d3870cec79aba   1406  py  Python   \n",
            "117544  793e7fc5c6f5a39a1fb0909ab5a3e5ce33f87ab8  25955  py  Python   \n",
            "\n",
            "                                      max_stars_repo_path  \\\n",
            "0                                       spider/openwrt.py   \n",
            "1                                        utils/compare.py   \n",
            "2                              sdk/python/kfp/__main__.py   \n",
            "3                        TestProject/app/view/RoomItem.py   \n",
            "4                       src/winforms/toga_winforms/app.py   \n",
            "...                                                   ...   \n",
            "117540                    tests/test_common_workaround.py   \n",
            "117541  www/app/Personal_development/album/migrations/...   \n",
            "117542                                    SessionState.py   \n",
            "117543                                             o3d.py   \n",
            "117544  venv/Lib/site-packages/sqlalchemy/sql/visitors.py   \n",
            "\n",
            "                       max_stars_repo_name  \\\n",
            "0                                CNDB/CNDB   \n",
            "1                              adcrn/knest   \n",
            "2                     ConverJens/pipelines   \n",
            "3                      ChinSing00/ChatChat   \n",
            "4                                holg/toga   \n",
            "...                                    ...   \n",
            "117540                  janEbert/pytorch3d   \n",
            "117541              yohei4/Django-Scraping   \n",
            "117542  VijaySingh-GSLab/venue_recommender   \n",
            "117543                  knei-knurow/AnyNet   \n",
            "117544                     MWildFire/IPCam   \n",
            "\n",
            "                      max_stars_repo_head_hexsha max_stars_repo_licenses  \\\n",
            "0       2e3a41111f604cf2f4f22a7c9370bb3f753e3e88          [BSD-3-Clause]   \n",
            "1       a274dc9ddb642cc30f837e225f000bf33430eb43          [BSD-3-Clause]   \n",
            "2       a1d453af214ec9eebad73fb05845dd3499d60d00            [Apache-2.0]   \n",
            "3       48654e2e125298c00a558449353e38d0cec06d03                   [MIT]   \n",
            "4       9dd766e749c6cf29cdb1127c7637150381ac396d          [BSD-3-Clause]   \n",
            "...                                          ...                     ...   \n",
            "117540  accdac80fb29e82f72d4e8e73135ba8fd790b6c0     [MIT, BSD-3-Clause]   \n",
            "117541  1ac72b414025e703c21076d044b5b9b421f95049                   [MIT]   \n",
            "117542  3c3bddc19c2f3be71833b85c5a1de2522771f0b3                   [MIT]   \n",
            "117543  0f726822eded48956eea6a7c9c76ae1490e8725a                   [MIT]   \n",
            "117544  7012f991a028843df8288824124f6f4b2369f155                   [MIT]   \n",
            "\n",
            "        max_stars_count max_stars_repo_stars_event_min_datetime  ...  \\\n",
            "0                   NaN                                    None  ...   \n",
            "1                   8.0                2018-03-15T23:42:51.000Z  ...   \n",
            "2                   6.0                2020-05-19T02:35:11.000Z  ...   \n",
            "3                   NaN                                    None  ...   \n",
            "4                   1.0                2020-07-16T00:46:24.000Z  ...   \n",
            "...                 ...                                     ...  ...   \n",
            "117540              1.0                2022-01-24T20:51:16.000Z  ...   \n",
            "117541              1.0                2021-09-05T02:45:59.000Z  ...   \n",
            "117542              NaN                                    None  ...   \n",
            "117543              NaN                                    None  ...   \n",
            "117544              1.0                2021-05-14T01:38:21.000Z  ...   \n",
            "\n",
            "                       max_forks_repo_name  \\\n",
            "0                                CNDB/CNDB   \n",
            "1                              adcrn/knest   \n",
            "2                     ConverJens/pipelines   \n",
            "3                      ChinSing00/ChatChat   \n",
            "4                                holg/toga   \n",
            "...                                    ...   \n",
            "117540                  janEbert/pytorch3d   \n",
            "117541              yohei4/Django-Scraping   \n",
            "117542  VijaySingh-GSLab/venue_recommender   \n",
            "117543                  knei-knurow/AnyNet   \n",
            "117544                     MWildFire/IPCam   \n",
            "\n",
            "                      max_forks_repo_head_hexsha max_forks_repo_licenses  \\\n",
            "0       2e3a41111f604cf2f4f22a7c9370bb3f753e3e88          [BSD-3-Clause]   \n",
            "1       a274dc9ddb642cc30f837e225f000bf33430eb43          [BSD-3-Clause]   \n",
            "2       a1d453af214ec9eebad73fb05845dd3499d60d00            [Apache-2.0]   \n",
            "3       48654e2e125298c00a558449353e38d0cec06d03                   [MIT]   \n",
            "4       9dd766e749c6cf29cdb1127c7637150381ac396d          [BSD-3-Clause]   \n",
            "...                                          ...                     ...   \n",
            "117540  accdac80fb29e82f72d4e8e73135ba8fd790b6c0     [MIT, BSD-3-Clause]   \n",
            "117541  1ac72b414025e703c21076d044b5b9b421f95049                   [MIT]   \n",
            "117542  3c3bddc19c2f3be71833b85c5a1de2522771f0b3                   [MIT]   \n",
            "117543  0f726822eded48956eea6a7c9c76ae1490e8725a                   [MIT]   \n",
            "117544  7012f991a028843df8288824124f6f4b2369f155                   [MIT]   \n",
            "\n",
            "       max_forks_count max_forks_repo_forks_event_min_datetime  \\\n",
            "0                  NaN                                    None   \n",
            "1                  NaN                                    None   \n",
            "2                 11.0                2020-05-19T22:26:41.000Z   \n",
            "3                  NaN                                    None   \n",
            "4                  NaN                                    None   \n",
            "...                ...                                     ...   \n",
            "117540             1.0                2022-03-29T04:29:06.000Z   \n",
            "117541             NaN                                    None   \n",
            "117542             2.0                2021-05-10T10:59:55.000Z   \n",
            "117543             NaN                                    None   \n",
            "117544             2.0                2021-05-23T16:46:31.000Z   \n",
            "\n",
            "        max_forks_repo_forks_event_max_datetime  \\\n",
            "0                                          None   \n",
            "1                                          None   \n",
            "2                      2021-01-25T09:56:21.000Z   \n",
            "3                                          None   \n",
            "4                                          None   \n",
            "...                                         ...   \n",
            "117540                 2022-03-29T04:29:06.000Z   \n",
            "117541                                     None   \n",
            "117542                 2021-05-10T11:09:11.000Z   \n",
            "117543                                     None   \n",
            "117544                 2021-05-26T23:51:09.000Z   \n",
            "\n",
            "                                                  content avg_line_length  \\\n",
            "0       #!/usr/bin/python\\n# -*- coding: utf-8 -*-\\n# ...       34.449198   \n",
            "1       # UCF Senior Design 2017-18\\n# Group 38\\n\\nfro...       24.725275   \n",
            "2       # Copyright 2018 Google LLC\\n#\\n# Licensed und...       32.913043   \n",
            "3       import time\\n\\nfrom PyQt5 import QtGui, QtCore...       45.583333   \n",
            "4       import asyncio\\nimport re\\nimport sys\\nimport ...       35.952055   \n",
            "...                                                   ...             ...   \n",
            "117540  # Copyright (c) Meta Platforms, Inc. and affil...       32.508772   \n",
            "117541  # Generated by Django 3.2.4 on 2021-07-10 18:0...       32.689655   \n",
            "117542  \\n# https://gist.github.com/FranzDiebold/89839...       29.939759   \n",
            "117543  from __future__ import (absolute_import, divis...       36.051282   \n",
            "117544  # sql/visitors.py\\n# Copyright (C) 2005-2021 t...       31.885749   \n",
            "\n",
            "       max_line_length alphanum_fraction  \n",
            "0                   78          0.472369  \n",
            "1                   78          0.646667  \n",
            "2                   74          0.749009  \n",
            "3                  138          0.659049  \n",
            "4                  101          0.597638  \n",
            "...                ...               ...  \n",
            "117540              88          0.618996  \n",
            "117541             141          0.644515  \n",
            "117542              80          0.665996  \n",
            "117543              98          0.690612  \n",
            "117544              79          0.663957  \n",
            "\n",
            "[117545 rows x 29 columns]\n",
            "#!/usr/bin/python\n",
            "# -*- coding: utf-8 -*-\n",
            "# #*** <License> ************************************************************#\n",
            "# This module is part of the repository CNDB.\n",
            "#\n",
            "# This module is licensed under the terms of the BSD 3-Clause License\n",
            "# <http://www.c-tanzer.at/license/bsd_3c.html>.\n",
            "# #*** </License> ***********************************************************#\n",
            "\n",
            "from   _TFL.pyk           import pyk\n",
            "\n",
            "from   rsclib.HTML_Parse  import tag, Page_Tree\n",
            "from   rsclib.autosuper   import autosuper\n",
            "from   spider.common      import Interface, Inet4, Inet6, unroutable\n",
            "from   spider.common      import WLAN_Config\n",
            "from   spider.luci        import Version_Mixin\n",
            "\n",
            "class Status (Page_Tree, Version_Mixin) :\n",
            "    url          = 'cgi-bin/luci/freifunk/status/status'\n",
            "    retries      = 2\n",
            "    timeout      = 10\n",
            "    html_charset = 'utf-8' # force utf-8 encoding\n",
            "\n",
            "    wl_names = dict \\\n",
            "        ( ssid    = 'ssid'\n",
            "        , _bsiid  = 'bssid'\n",
            "        , channel = 'channel'\n",
            "        , mode    = 'mode'\n",
            "        )\n",
            "\n",
            "    def parse (self) :\n",
            "        root  = self.tree.getroot ()\n",
            "        self.wlans  = []\n",
            "        self.routes = {}\n",
            "        for div in root.findall (\".//%s\" % tag (\"div\")) :\n",
            "            id = div.get ('id')\n",
            "            if id == 'cbi-wireless' :\n",
            "                wlan_div = div\n",
            "            elif id == 'cbi-routes' :\n",
            "                route_div = div\n",
            "            self.try_get_version (div)\n",
            "        for d in self.tbl_iter (wlan_div) :\n",
            "            for k, newkey in pyk.iteritems (self.wl_names) :\n",
            "                if k in d :\n",
            "                    d [newkey] = d [k]\n",
            "            wl = WLAN_Config (** d)\n",
            "            self.wlans.append (wl)\n",
            "        for d in self.tbl_iter (route_div) :\n",
            "            iface = d.get ('iface')\n",
            "            gw    = d.get ('gateway')\n",
            "            if iface and gw :\n",
            "                self.routes [iface] = gw\n",
            "        self.set_version (root)\n",
            "    # end def parse\n",
            "\n",
            "    def tbl_iter (self, div) :\n",
            "        tbl = div.find (\".//%s\" % tag (\"table\"))\n",
            "        assert tbl.get ('class') == 'cbi-section-table'\n",
            "        d = {}\n",
            "        for tr in tbl :\n",
            "            if 'cbi-section-table-row' not in tr.get ('class').split () :\n",
            "                continue\n",
            "            for input in tr.findall (\".//%s\" % tag ('input')) :\n",
            "                name = input.get ('id').split ('.') [-1]\n",
            "                val  = input.get ('value')\n",
            "                d [name] = val\n",
            "            if not d :\n",
            "                continue\n",
            "            yield d\n",
            "    # end def tbl_iter\n",
            "\n",
            "# end class Status\n",
            "\n",
            "class Table_Iter (Page_Tree) :\n",
            "\n",
            "    def table_iter (self) :\n",
            "        root  = self.tree.getroot ()\n",
            "        for div in root.findall (\".//%s\" % tag (\"div\")) :\n",
            "            if div.get ('id') == 'maincontent' :\n",
            "                break\n",
            "        tbl = div.find (\".//%s\" % tag (\"table\"))\n",
            "        if tbl is None :\n",
            "            return\n",
            "        for tr in tbl :\n",
            "            if tr [0].tag == tag ('th') :\n",
            "                continue\n",
            "            yield (self.tree.get_text (x) for x in tr)\n",
            "    # end def table_iter\n",
            "\n",
            "# end class Table_Iter\n",
            "\n",
            "class OLSR_Connections (Table_Iter) :\n",
            "    url          = 'cgi-bin/luci/freifunk/olsr/'\n",
            "    retries      = 2\n",
            "    timeout      = 10\n",
            "    html_charset = 'utf-8' # force utf-8 encoding\n",
            "\n",
            "    def parse (self) :\n",
            "        self.neighbors = {}\n",
            "        for l in self.table_iter () :\n",
            "            neighbor, ip, lq, nlq, etx = l\n",
            "            lq, nlq, etx = (float (x) for x in (lq, nlq, etx))\n",
            "            self.neighbors [neighbor] = [ip, lq, nlq, etx]\n",
            "    # end def parse\n",
            "\n",
            "# end class OLSR_Connections\n",
            "\n",
            "class OLSR_Routes (Table_Iter) :\n",
            "    url          = 'cgi-bin/luci/freifunk/olsr/routes'\n",
            "    retries      = 2\n",
            "    timeout      = 10\n",
            "    html_charset = 'utf-8' # force utf-8 encoding\n",
            "\n",
            "    def parse (self) :\n",
            "        self.iface_by_gw = {}\n",
            "        for l in self.table_iter () :\n",
            "            announced, gw, iface, metric, etx = l\n",
            "            if gw in self.iface_by_gw :\n",
            "                assert iface == self.iface_by_gw [gw]\n",
            "            else :\n",
            "                self.iface_by_gw [gw] = iface\n",
            "    # end def parse\n",
            "\n",
            "# end class OLSR_Routes\n",
            "\n",
            "class OpenWRT (autosuper) :\n",
            "\n",
            "    def __init__ (self, site, request) :\n",
            "        self.site    = site\n",
            "        self.request = request\n",
            "        if 'interfaces' in self.request or 'ips' in self.request :\n",
            "            st    = Status           (site = site)\n",
            "            conn  = OLSR_Connections (site = site)\n",
            "            route = OLSR_Routes      (site = site)\n",
            "            self.version = st.version\n",
            "            assert len (st.wlans) <= 1\n",
            "            interfaces   = {}\n",
            "            ips          = {}\n",
            "            count = 0\n",
            "            for gw, ifname in pyk.iteritems (route.iface_by_gw) :\n",
            "                ip, lq, nlq, etx  = conn.neighbors [gw]\n",
            "                i4 = Inet4 (ip, None, None, iface = ifname)\n",
            "                ips [i4] = 1\n",
            "                is_wlan = True\n",
            "                if lq == nlq == etx == 1.0 :\n",
            "                    is_wlan = False\n",
            "                if ifname in interfaces :\n",
            "                    iface = interfaces [ifname]\n",
            "                    if not iface.is_wlan and is_wlan :\n",
            "                        iface.is_wlan   = True\n",
            "                        iface.wlan_info = st.wlans [0]\n",
            "                else :\n",
            "                    iface = Interface (count, ifname, None)\n",
            "                    iface.is_wlan = is_wlan\n",
            "                    if is_wlan :\n",
            "                        iface.wlan_info = st.wlans [0]\n",
            "                    count += 1\n",
            "                    interfaces [ifname] = iface\n",
            "                if i4 not in iface.inet4 :\n",
            "                    iface.append_inet4 (i4)\n",
            "            wl_if = None\n",
            "            for iface in pyk.itervalues (interfaces) :\n",
            "                if iface.is_wlan :\n",
            "                    if wl_if :\n",
            "                        m = \"Duplicate wlan: %s/%s\" % (iface.name, wl_if.name)\n",
            "                        raise ValueError (m)\n",
            "                    wl_if = iface\n",
            "            # check own ip\n",
            "            n  = 'unknown'\n",
            "            i4 = Inet4 (self.request ['ip'], None, None, iface = n)\n",
            "            if i4 not in ips :\n",
            "                assert n not in interfaces\n",
            "                iface = interfaces [n] = Interface (count, n, None)\n",
            "                iface.append_inet4 (i4)\n",
            "                iface.is_wlan = False\n",
            "                if not wl_if and st.wlans :\n",
            "                    iface.is_wlan   = True\n",
            "                    iface.wlan_info = st.wlans [0]\n",
            "                ips [i4] = True\n",
            "\n",
            "            self.request ['ips']        = ips\n",
            "            self.request ['interfaces'] = interfaces\n",
            "            self.request ['version']    = st.version\n",
            "    # end def __init__\n",
            "\n",
            "# end class OpenWRT\n",
            "\n",
            "import os\n",
            "import json\n",
            "\n",
            "Environ = os._Environ\n",
            "\n",
            "\n",
            "def is_on_cloudfoundry(env: Environ=os.environ) -> bool:\n",
            "    return 'VCAP_SERVICES' in env\n",
            "\n",
            "\n",
            "def load_cups_from_vcap_services(name: str, env: Environ=os.environ) -> None:\n",
            "    '''\n",
            "    Detects if VCAP_SERVICES exists in the environment; if so, parses\n",
            "    it and imports all the credentials from the given custom\n",
            "    user-provided service (CUPS) as strings into the environment.\n",
            "    For more details on CUPS, see:\n",
            "    https://docs.cloudfoundry.org/devguide/services/user-provided.html\n",
            "    '''\n",
            "\n",
            "    if not is_on_cloudfoundry(env):\n",
            "        return\n",
            "\n",
            "    vcap = json.loads(env['VCAP_SERVICES'])\n",
            "\n",
            "    for entry in vcap.get('user-provided', []):\n",
            "        if entry['name'] == name:\n",
            "            for key, value in entry['credentials'].items():\n",
            "                env[key] = value\n",
            "\n",
            "\n",
            "def load_database_url_from_vcap_services(name: str, service: str,\n",
            "                                         env: Environ=os.environ) -> str:\n",
            "    \"\"\"\n",
            "    Sets os.environ[DATABASE_URL] from a service entry in VCAP_SERVICES.\n",
            "    \"\"\"\n",
            "    if not is_on_cloudfoundry(env):\n",
            "        return\n",
            "\n",
            "    # FIXME: this'll break if there are multiple databases. Not an issue right\n",
            "    # now, but could be in the future. Keep an eye on it.\n",
            "    vcap = json.loads(env['VCAP_SERVICES'])\n",
            "    env['DATABASE_URL'] = vcap[service][0][\"credentials\"][\"uri\"]\n",
            "\n",
            "#name_scan \"d/yourdomain\" 1\n",
            "import sys, os\n",
            "#sys.path.append('/home/khal/sources/nmcontrol/lib/')\n",
            "import DNS\n",
            "import rpcClient\n",
            "import struct, listdns, base64, types, json, random\n",
            "#from jsonrpc import ServiceProxy\n",
            "from utils import *\n",
            "from common import *\n",
            "\n",
            "class Source(object):\n",
            "    #def __init__(self):\n",
            "        #self.servers = app['services']['dns'].conf['resolver'].split(',')\n",
            "        #self.reqobj = DNS.Request()\n",
            "        #jsonfile = open(\"config.json\", \"r\")\n",
            "        #data = json.loads(jsonfile.read())\n",
            "        #jsonfile.close()\n",
            "        #username = str(data[u\"username\"])\n",
            "        #port = data[u\"port\"]\n",
            "        #password = str(data[u\"password\"])\n",
            "        #self.sp = ServiceProxy(\"http://%(user)s:%(passwd)s@127.0.0.1:%(port)d\" % dict(user=username, passwd=password, port=port))\n",
            "        #elf.sp = rpcClient.rpcClientNamecoin('127.0.0.1', port, username, password)\n",
            "        #self.sp = app['plugins']['domain']\n",
            "\n",
            "#    def _parse_file(self):\n",
            "#        f = open(self._filename, \"r\")\n",
            "#        for line in f.readlines():\n",
            "#            line = line.strip()\n",
            "#            if line and line[0] != '#':\n",
            "#                question, type, value = line.split()\n",
            "#                question = question.lower()\n",
            "#                type = type.upper()\n",
            "#                if question == '@':\n",
            "#                    question = ''\n",
            "#                if type == 'A':\n",
            "#                    answer = struct.pack(\"!I\", ipstr2int(value))\n",
            "#                    qtype = 1\n",
            "#                if type == 'NS':\n",
            "#                    answer = labels2str(value.split(\".\"))\n",
            "#                    qtype = 2\n",
            "#                elif type == 'CNAME':\n",
            "#                    answer = labels2str(value.split(\".\"))\n",
            "#                    qtype = 5\n",
            "#                elif type == 'TXT':\n",
            "#                    answer = label2str(value)\n",
            "#                    qtype = 16\n",
            "#                elif type == 'MX':\n",
            "#                    preference, domain = value.split(\":\")\n",
            "#                    answer = struct.pack(\"!H\", int(preference))\n",
            "#                    answer += labels2str(domain.split(\".\"))\n",
            "#                    qtype = 15\n",
            "#                self._answers.setdefault(question, {}).setdefault(qtype, []).append(answer)\n",
            "#        f.close()\n",
            "\n",
            "    def isIP(self, host) :\n",
            "        parts = host.split(\".\")\n",
            "        if len(parts) != 4:\n",
            "            return False\n",
            "        try :\n",
            "            valid = False\n",
            "            for part in parts :\n",
            "                intpart = int(part)\n",
            "                if intpart <= 255 and intpart >= 0 :\n",
            "                    valid = True\n",
            "                else : return False\n",
            "            if valid :\n",
            "                return True\n",
            "            return False\n",
            "        except : return False\n",
            "    def get_response(self, query, domain, qtype, qclass, src_addr):\n",
            "        #print query\n",
            "        #print domain\n",
            "        #print qtype\n",
            "        #print qclass\n",
            "        #print src_addr\n",
            "        if qtype == 1:\n",
            "            #answer = struct.pack(\"!I\", ipstr2int(value))\n",
            "            reqtype = \"A\"\n",
            "        if qtype == 2:\n",
            "            #answer = labels2str(value.split(\".\"))\n",
            "            reqtype = \"NS\"\n",
            "        elif qtype == 5:\n",
            "            #answer = labels2str(value.split(\".\"))\n",
            "            reqtype = \"CNAME\"\n",
            "        elif qtype == 16:\n",
            "            #answer = label2str(value)\n",
            "            reqtype = \"TXT\"\n",
            "        elif qtype == 15:\n",
            "            #preference, domain = value.split(\":\")\n",
            "            #nswer = struct.pack(\"!H\", int(preference))\n",
            "            #answer += labels2str(domain.split(\".\"))\n",
            "            reqtype = \"MX\"\n",
            "        elif qtype == 28:\n",
            "            #answer = struct.pack(\"!I\", ipstr2int(value))\n",
            "            reqtype = \"AAAA\"\n",
            "        elif qtype == 52:\n",
            "            reqtype = \"TLSA\"\n",
            "        else : reqtype = None\n",
            "        answers = app['services']['dns'].lookup({\"query\":query, \"domain\":domain, \"qtype\":qtype, \"qclass\":qclass, \"src_addr\":src_addr})\n",
            "        #print 'domain:', domain\n",
            "        #print 'answers:', answers\n",
            "        if domain.endswith(\".bit\") or domain.endswith(\".tor\") :\n",
            "            #response = listdns.lookup(self.sp, {\"query\":query, \"domain\":domain, \"qtype\":qtype, \"qclass\":qclass, \"src_addr\":src_addr})\n",
            "            #response = self.sp.lookup({\"query\":query, \"domain\":domain, \"qtype\":qtype, \"qclass\":qclass, \"src_addr\":src_addr})\n",
            "            response = answers\n",
            "            results = []\n",
            "            if type(response) == types.DictType :\n",
            "                tempresults = {\"qtype\":response[\"type\"], \"qclass\":response[\"class\"], \"ttl\":response[\"ttl\"]}\n",
            "                if response[\"type\"] == 1 :\n",
            "                    #if answers == [] :\n",
            "                    #    return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "                    tempresults[\"rdata\"] = struct.pack(\"!I\", ipstr2int(response[\"data\"]))\n",
            "                elif response[\"type\"] == 2 or response[\"type\"] == 5:\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"].split(\".\"))\n",
            "                elif response[\"type\"] == 16 :\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"])\n",
            "                elif response[\"type\"] == 15 :\n",
            "                    tempresult = struct.pack(\"!H\", response[\"data\"][0])\n",
            "                    tempresult += labels2str(response[\"data\"][1].split(\".\"))\n",
            "                    tempresults[\"rdata\"] = tempresult\n",
            "                elif response[\"type\"] == 28 :\n",
            "                    tempresults[\"rdata\"] = response[\"data\"]\n",
            "                elif response[\"type\"] == 52 :\n",
            "                    tempresult = '\\x03\\x00'\n",
            "                    tempresult += chr(int(response[\"data\"][0][0]))\n",
            "                    tempresult += bytearray.fromhex(response[\"data\"][0][1])\n",
            "                    tempresults[\"rdata\"] = tempresult\n",
            "                #else : return 3, []\n",
            "                results.append(tempresults)\n",
            "                return 0, results\n",
            "            if type(response) == types.StringType :\n",
            "                if self.isIP(response) :\n",
            "                    return 0, [{\"qtype\":1, \"qclass\":qclass, \"ttl\":300, \"rdata\":struct.pack(\"!I\", ipstr2int(response))}]\n",
            "            return 3, []\n",
            "            #if query not in self._answers:\n",
            "                #return 3, []\n",
            "            #if qtype in self._answers[query]:\n",
            "            #if domain == \"sonicrules.bit\":\n",
            "            #    results = [{'qtype': 1, 'qclass':qclass, 'ttl': 300, 'rdata': struct.pack(\"!I\", ipstr2int(self.reqobj.req(\"sonicrules.org\", qtype=1).answers[0][\"data\"]))}]\n",
            "            #    return 0, results\n",
            "            #elif qtype == 1:\n",
            "                # if they asked for an A record and we didn't find one, check for a CNAME\n",
            "                #return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "        else:\n",
            "            #server = self.servers[random.randrange(0, len(self.servers)-1)]\n",
            "            #answers = self.reqobj.req(name=domain, qtype=qtype, server=server).answers\n",
            "            results = []\n",
            "            for response in answers :\n",
            "                tempresults = {\"qtype\":response[\"type\"], \"qclass\":response[\"class\"], \"ttl\":response[\"ttl\"]}\n",
            "                if response[\"type\"] == 1 :\n",
            "                    if answers == [] :\n",
            "                        return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "                    tempresults[\"rdata\"] = struct.pack(\"!I\", ipstr2int(response[\"data\"]))\n",
            "                elif response[\"type\"] == 2 or response[\"type\"] == 5:\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"].split(\".\"))\n",
            "                elif response[\"type\"] == 16 :\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"])\n",
            "                elif response[\"type\"] == 15 :\n",
            "                    tempresult = struct.pack(\"!H\", response[\"data\"][0])\n",
            "                    tempresult += labels2str(response[\"data\"][1].split(\".\"))\n",
            "                    tempresults[\"rdata\"] = tempresult\n",
            "                elif response[\"type\"] == 28 :\n",
            "                    if answers == [] :\n",
            "                        return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "                    #tempresults[\"rdata\"] = struct.pack(\"!I\", ipstr2int(response[\"data\"]))\n",
            "                    tempresults[\"rdata\"] = response[\"data\"]\n",
            "                elif response[\"type\"] == 52 :\n",
            "                    tempresults[\"rdata\"] = response[\"data\"]\n",
            "                #else : return 3, []\n",
            "                results.append(tempresults)\n",
            "            return 0, results\n",
            "        return 3, []\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = \"train-00000-of-00206.parquet\"\n",
        "\n",
        "df = pd.read_parquet(file_path, engine = \"fastparquet\")\n",
        "\n",
        "first_entry_code = df.iloc[0][\"content\"]\n",
        "second_entry_code = df.iloc[100][\"content\"]\n",
        "third_entry_code = df.iloc[1000][\"content\"]\n",
        "\n",
        "print(df)\n",
        "print(first_entry_code)\n",
        "print(second_entry_code)\n",
        "print(third_entry_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zznu8S8AjDF",
        "outputId": "67152646-3282-48a6-fc83-fc8274e5d343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# UCF Senior Design 2017-18\n",
            "# Group 38\n",
            "\n",
            "from PIL import Image\n",
            "import cv2\n",
            "import imagehash\n",
            "import math\n",
            "import numpy as np\n",
            "\n",
            "DIFF_THRES = 20\n",
            "LIMIT = 2\n",
            "RESIZE = 1000\n",
            "\n",
            "\n",
            "def calc_hash(img):\n",
            "    \"\"\"\n",
            "    Calculate the wavelet hash of the image\n",
            "        img: (ndarray) image file\n",
            "    \"\"\"\n",
            "    # resize image if height > 1000\n",
            "    img = resize(img)\n",
            "    return imagehash.whash(Image.fromarray(img))\n",
            "\n",
            "\n",
            "def compare(hash1, hash2):\n",
            "    \"\"\"\n",
            "    Calculate the difference between two images\n",
            "        hash1: (array) first wavelet hash\n",
            "        hash2: (array) second wavelet hash\n",
            "    \"\"\"\n",
            "    return hash1 - hash2\n",
            "\n",
            "\n",
            "def limit(img, std_hash, count):\n",
            "    \"\"\"\n",
            "    Determine whether image should be removed from image dictionary in main.py\n",
            "        img: (ndarray) image file\n",
            "        std_hash: (array) wavelet hash of comparison standard\n",
            "        count: (int) global count of images similar to comparison standard\n",
            "    \"\"\"\n",
            "    # calculate hash for given image\n",
            "    cmp_hash = calc_hash(img)\n",
            "\n",
            "    # compare to standard\n",
            "    diff = compare(std_hash, cmp_hash)\n",
            "\n",
            "    # image is similar to standard\n",
            "    if diff <= DIFF_THRES:\n",
            "        # if there are 3 similar images already, remove image\n",
            "        if count >= LIMIT:\n",
            "            return 'remove'\n",
            "\n",
            "    # non-similar image found\n",
            "    else:\n",
            "        # update comparison standard\n",
            "        return 'update_std'\n",
            "\n",
            "    # else continue reading images with same standard\n",
            "    return 'continue'\n",
            "\n",
            "\n",
            "def resize(img):\n",
            "    \"\"\"\n",
            "    Resize an image\n",
            "        img: (ndarray) RGB color image\n",
            "    \"\"\"\n",
            "    # get dimensions of image\n",
            "    width = np.shape(img)[1]\n",
            "    height = np.shape(img)[0]\n",
            "\n",
            "    # if height of image is greater than 1000, resize it to 1000\n",
            "    if width > RESIZE:\n",
            "        # keep resize proportional\n",
            "        scale = RESIZE / width\n",
            "        resized_img = cv2.resize(\n",
            "            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\n",
            "        # return resized image\n",
            "        return resized_img\n",
            "\n",
            "    # if height of image is less than 1000, return image unresized\n",
            "    return img\n",
            "\n",
            "\n",
            "def set_standard(images, filename):\n",
            "    \"\"\"\n",
            "    Set new comparison standard and update information\n",
            "        images: (dictionary) dictionary containing all the image data\n",
            "        filename: (String) name of the image file\n",
            "    \"\"\"\n",
            "    return filename, calc_hash(images[filename]), 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get only the code\n",
        "\n",
        "code_series = df[\"content\"].head(1000)\n",
        "print(code_series[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXvHaSwNBgIE"
      },
      "outputs": [],
      "source": [
        "# Preprocess\n",
        "\n",
        "def clean_code(code):\n",
        "    # Remove multiline docstrings \n",
        "    code = re.sub(r'\"\"\"[\\s\\S]*?\"\"\"', '', code)\n",
        "    code = re.sub(r\"'''[\\s\\S]*?'''\", '', code)\n",
        "\n",
        "    # Remove single-line comments \n",
        "    code = re.sub(r'#.*', '', code)\n",
        "\n",
        "    # Remove blank lines\n",
        "    code = re.sub(r'^\\s*\\n', '', code)\n",
        "\n",
        "    return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlXp8hYhB51I",
        "outputId": "670c599f-8dd8-4648-9ce5-d1f6e6377a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "from PIL import Image\n",
            "import cv2\n",
            "import imagehash\n",
            "import math\n",
            "import numpy as np\n",
            "\n",
            "DIFF_THRES = 20\n",
            "LIMIT = 2\n",
            "RESIZE = 1000\n",
            "\n",
            "\n",
            "def calc_hash(img):\n",
            "    \n",
            "    \n",
            "    img = resize(img)\n",
            "    return imagehash.whash(Image.fromarray(img))\n",
            "\n",
            "\n",
            "def compare(hash1, hash2):\n",
            "    \n",
            "    return hash1 - hash2\n",
            "\n",
            "\n",
            "def limit(img, std_hash, count):\n",
            "    \n",
            "    \n",
            "    cmp_hash = calc_hash(img)\n",
            "\n",
            "    \n",
            "    diff = compare(std_hash, cmp_hash)\n",
            "\n",
            "    \n",
            "    if diff <= DIFF_THRES:\n",
            "        \n",
            "        if count >= LIMIT:\n",
            "            return 'remove'\n",
            "\n",
            "    \n",
            "    else:\n",
            "        \n",
            "        return 'update_std'\n",
            "\n",
            "    \n",
            "    return 'continue'\n",
            "\n",
            "\n",
            "def resize(img):\n",
            "    \n",
            "    \n",
            "    width = np.shape(img)[1]\n",
            "    height = np.shape(img)[0]\n",
            "\n",
            "    \n",
            "    if width > RESIZE:\n",
            "        \n",
            "        scale = RESIZE / width\n",
            "        resized_img = cv2.resize(\n",
            "            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\n",
            "        \n",
            "        return resized_img\n",
            "\n",
            "    \n",
            "    return img\n",
            "\n",
            "\n",
            "def set_standard(images, filename):\n",
            "    \n",
            "    return filename, calc_hash(images[filename]), 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_data = code_series.apply(clean_code)\n",
        "\n",
        "print(cleaned_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfySHxBQESho",
        "outputId": "e1a3edcc-c8cd-44b1-d3b0-2132fcc77b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to cleaned_data.json\n"
          ]
        }
      ],
      "source": [
        "#Save as json\n",
        "cleaned_data_list = cleaned_data.tolist()\n",
        "\n",
        "formatted_data = [{\"code\": item} for item in cleaned_data_list]\n",
        "\n",
        "payload = json.dumps(formatted_data, ensure_ascii=False).encode(\"utf-8\")\n",
        "\n",
        "output_filename = \"cleaned_data.json\"\n",
        "\n",
        "with open(output_filename, \"w\") as f:\n",
        "    json.dump(formatted_data, f, indent=4)\n",
        "\n",
        "print(f\"Data saved to {output_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkfXqCaDKEI"
      },
      "source": [
        "Generate summaries for data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "atojrnWiDMtv",
        "outputId": "c1d5a900-f702-4da5-858e-78ca97bb25a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "#Check ollama\n",
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAxWz-z2DOOg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llamas primarily eat grasses and hay. They are herbivores and have a digestive system that allows them to digest cellulose, which is found in plant material. In the wild, llamas graze on grasses, leaves, and bark from trees and bushes. In captivity or when kept as pets, they are usually fed commercial llama pellets, supplemented with fresh grass and hay.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"qwen2.5-coder:7b\",\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    \n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     \n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "   \n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        \n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "\n",
        "model = \"qwen2.5-coder:7b\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uOpuMeqEQMj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSyLt2cFDj34"
      },
      "outputs": [],
      "source": [
        "def add_summaries_to_json(input_json_filename, output_json_filename):\n",
        "    with open(input_json_filename, \"r\") as infile:\n",
        "        code_data = json.load(infile)\n",
        "    \n",
        "    if not isinstance(code_data, list):\n",
        "        raise ValueError(\"Expected a list of dictionaries but got a different format.\")\n",
        "    \n",
        "    \n",
        "    id = 0\n",
        "    for entry in code_data:\n",
        "        if not isinstance(entry, dict) or \"code\" not in entry:\n",
        "            raise ValueError(f\"Invalid entry format: {entry}\")\n",
        "        \n",
        "        prompt = f\"Summarize the following Python code:\\n{entry['code']}\"\n",
        "        summary = query_model(prompt)\n",
        "        entry[\"summary\"] = summary\n",
        "        print(f\"ID: {id}\")\n",
        "        print(f\"Entry: {entry}\")\n",
        "        print(\"Summary: \" + summary)\n",
        "        print()\n",
        "        print()\n",
        "        id = id + 1\n",
        "\n",
        "   \n",
        "    with open(output_json_filename, \"w\") as outfile:\n",
        "        json.dump(code_data, outfile, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to cleaned_data_test.json\n",
            "ID: 0\n",
            "Entry: {'code': 'from   _TFL.pyk           import pyk\\n\\nfrom   rsclib.HTML_Parse  import tag, Page_Tree\\nfrom   rsclib.autosuper   import autosuper\\nfrom   spider.common      import Interface, Inet4, Inet6, unroutable\\nfrom   spider.common      import WLAN_Config\\nfrom   spider.luci        import Version_Mixin\\n\\nclass Status (Page_Tree, Version_Mixin) :\\n    url          = \\'cgi-bin/luci/freifunk/status/status\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    wl_names = dict \\\\\\n        ( ssid    = \\'ssid\\'\\n        , _bsiid  = \\'bssid\\'\\n        , channel = \\'channel\\'\\n        , mode    = \\'mode\\'\\n        )\\n\\n    def parse (self) :\\n        root  = self.tree.getroot ()\\n        self.wlans  = []\\n        self.routes = {}\\n        for div in root.findall (\".//%s\" % tag (\"div\")) :\\n            id = div.get (\\'id\\')\\n            if id == \\'cbi-wireless\\' :\\n                wlan_div = div\\n            elif id == \\'cbi-routes\\' :\\n                route_div = div\\n            self.try_get_version (div)\\n        for d in self.tbl_iter (wlan_div) :\\n            for k, newkey in pyk.iteritems (self.wl_names) :\\n                if k in d :\\n                    d [newkey] = d [k]\\n            wl = WLAN_Config (** d)\\n            self.wlans.append (wl)\\n        for d in self.tbl_iter (route_div) :\\n            iface = d.get (\\'iface\\')\\n            gw    = d.get (\\'gateway\\')\\n            if iface and gw :\\n                self.routes [iface] = gw\\n        self.set_version (root)\\n    \\n\\n    def tbl_iter (self, div) :\\n        tbl = div.find (\".//%s\" % tag (\"table\"))\\n        assert tbl.get (\\'class\\') == \\'cbi-section-table\\'\\n        d = {}\\n        for tr in tbl :\\n            if \\'cbi-section-table-row\\' not in tr.get (\\'class\\').split () :\\n                continue\\n            for input in tr.findall (\".//%s\" % tag (\\'input\\')) :\\n                name = input.get (\\'id\\').split (\\'.\\') [-1]\\n                val  = input.get (\\'value\\')\\n                d [name] = val\\n            if not d :\\n                continue\\n            yield d\\n    \\n\\n\\n\\nclass Table_Iter (Page_Tree) :\\n\\n    def table_iter (self) :\\n        root  = self.tree.getroot ()\\n        for div in root.findall (\".//%s\" % tag (\"div\")) :\\n            if div.get (\\'id\\') == \\'maincontent\\' :\\n                break\\n        tbl = div.find (\".//%s\" % tag (\"table\"))\\n        if tbl is None :\\n            return\\n        for tr in tbl :\\n            if tr [0].tag == tag (\\'th\\') :\\n                continue\\n            yield (self.tree.get_text (x) for x in tr)\\n    \\n\\n\\n\\nclass OLSR_Connections (Table_Iter) :\\n    url          = \\'cgi-bin/luci/freifunk/olsr/\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    def parse (self) :\\n        self.neighbors = {}\\n        for l in self.table_iter () :\\n            neighbor, ip, lq, nlq, etx = l\\n            lq, nlq, etx = (float (x) for x in (lq, nlq, etx))\\n            self.neighbors [neighbor] = [ip, lq, nlq, etx]\\n    \\n\\n\\n\\nclass OLSR_Routes (Table_Iter) :\\n    url          = \\'cgi-bin/luci/freifunk/olsr/routes\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    def parse (self) :\\n        self.iface_by_gw = {}\\n        for l in self.table_iter () :\\n            announced, gw, iface, metric, etx = l\\n            if gw in self.iface_by_gw :\\n                assert iface == self.iface_by_gw [gw]\\n            else :\\n                self.iface_by_gw [gw] = iface\\n    \\n\\n\\n\\nclass OpenWRT (autosuper) :\\n\\n    def __init__ (self, site, request) :\\n        self.site    = site\\n        self.request = request\\n        if \\'interfaces\\' in self.request or \\'ips\\' in self.request :\\n            st    = Status           (site = site)\\n            conn  = OLSR_Connections (site = site)\\n            route = OLSR_Routes      (site = site)\\n            self.version = st.version\\n            assert len (st.wlans) <= 1\\n            interfaces   = {}\\n            ips          = {}\\n            count = 0\\n            for gw, ifname in pyk.iteritems (route.iface_by_gw) :\\n                ip, lq, nlq, etx  = conn.neighbors [gw]\\n                i4 = Inet4 (ip, None, None, iface = ifname)\\n                ips [i4] = 1\\n                is_wlan = True\\n                if lq == nlq == etx == 1.0 :\\n                    is_wlan = False\\n                if ifname in interfaces :\\n                    iface = interfaces [ifname]\\n                    if not iface.is_wlan and is_wlan :\\n                        iface.is_wlan   = True\\n                        iface.wlan_info = st.wlans [0]\\n                else :\\n                    iface = Interface (count, ifname, None)\\n                    iface.is_wlan = is_wlan\\n                    if is_wlan :\\n                        iface.wlan_info = st.wlans [0]\\n                    count += 1\\n                    interfaces [ifname] = iface\\n                if i4 not in iface.inet4 :\\n                    iface.append_inet4 (i4)\\n            wl_if = None\\n            for iface in pyk.itervalues (interfaces) :\\n                if iface.is_wlan :\\n                    if wl_if :\\n                        m = \"Duplicate wlan: %s/%s\" % (iface.name, wl_if.name)\\n                        raise ValueError (m)\\n                    wl_if = iface\\n            \\n            n  = \\'unknown\\'\\n            i4 = Inet4 (self.request [\\'ip\\'], None, None, iface = n)\\n            if i4 not in ips :\\n                assert n not in interfaces\\n                iface = interfaces [n] = Interface (count, n, None)\\n                iface.append_inet4 (i4)\\n                iface.is_wlan = False\\n                if not wl_if and st.wlans :\\n                    iface.is_wlan   = True\\n                    iface.wlan_info = st.wlans [0]\\n                ips [i4] = True\\n\\n            self.request [\\'ips\\']        = ips\\n            self.request [\\'interfaces\\'] = interfaces\\n            self.request [\\'version\\']    = st.version\\n    \\n\\n\\n', 'summary': 'This Python code defines several classes to parse and process data from web pages related to a Freifunk network, which is a decentralized mesh networking system. The main functionalities include:\\n\\n1. **Status Class**: Parses the status page of a Freifunk node. It extracts information about wireless networks (WLANs) and routing tables. It uses `Page_Tree` for parsing HTML and `Version_Mixin` to handle versioning.\\n\\n2. **Table_Iter Class**: A base class for iterating over tables in HTML pages. It finds the main content div and iterates over table rows, extracting text data from each row.\\n\\n3. **OLSR_Connections Class**: Parses the OLSR (Optimized Link State Routing) connections page. It extracts information about network neighbors and their IP addresses along with link quality metrics.\\n\\n4. **OLSR_Routes Class**: Parses the OLSR routes page. It extracts routing table information, mapping gateways to interfaces.\\n\\n5. **OpenWRT Class**: This class integrates all the above functionalities. It initializes instances of `Status`, `OLSR_Connections`, and `OLSR_Routes` to gather data from different pages. It then processes this data to create a structured representation of network interfaces, their IP addresses, and wireless information.\\n\\nThe code uses various utilities like `pyk` for dictionary operations, `rsclib.HTML_Parse` for HTML parsing, and custom classes like `Interface`, `Inet4`, and `WLAN_Config` to represent different aspects of the network configuration. The `autosuper` decorator is used to simplify class inheritance.\\n\\nOverall, this code provides a comprehensive solution for extracting and processing network data from Freifunk nodes, which can be useful for monitoring and management purposes.'}\n",
            "Summary: This Python code defines several classes to parse and process data from web pages related to a Freifunk network, which is a decentralized mesh networking system. The main functionalities include:\n",
            "\n",
            "1. **Status Class**: Parses the status page of a Freifunk node. It extracts information about wireless networks (WLANs) and routing tables. It uses `Page_Tree` for parsing HTML and `Version_Mixin` to handle versioning.\n",
            "\n",
            "2. **Table_Iter Class**: A base class for iterating over tables in HTML pages. It finds the main content div and iterates over table rows, extracting text data from each row.\n",
            "\n",
            "3. **OLSR_Connections Class**: Parses the OLSR (Optimized Link State Routing) connections page. It extracts information about network neighbors and their IP addresses along with link quality metrics.\n",
            "\n",
            "4. **OLSR_Routes Class**: Parses the OLSR routes page. It extracts routing table information, mapping gateways to interfaces.\n",
            "\n",
            "5. **OpenWRT Class**: This class integrates all the above functionalities. It initializes instances of `Status`, `OLSR_Connections`, and `OLSR_Routes` to gather data from different pages. It then processes this data to create a structured representation of network interfaces, their IP addresses, and wireless information.\n",
            "\n",
            "The code uses various utilities like `pyk` for dictionary operations, `rsclib.HTML_Parse` for HTML parsing, and custom classes like `Interface`, `Inet4`, and `WLAN_Config` to represent different aspects of the network configuration. The `autosuper` decorator is used to simplify class inheritance.\n",
            "\n",
            "Overall, this code provides a comprehensive solution for extracting and processing network data from Freifunk nodes, which can be useful for monitoring and management purposes.\n",
            "\n",
            "\n",
            "ID: 1\n",
            "Entry: {'code': \"from PIL import Image\\nimport cv2\\nimport imagehash\\nimport math\\nimport numpy as np\\n\\nDIFF_THRES = 20\\nLIMIT = 2\\nRESIZE = 1000\\n\\n\\ndef calc_hash(img):\\n    \\n    \\n    img = resize(img)\\n    return imagehash.whash(Image.fromarray(img))\\n\\n\\ndef compare(hash1, hash2):\\n    \\n    return hash1 - hash2\\n\\n\\ndef limit(img, std_hash, count):\\n    \\n    \\n    cmp_hash = calc_hash(img)\\n\\n    \\n    diff = compare(std_hash, cmp_hash)\\n\\n    \\n    if diff <= DIFF_THRES:\\n        \\n        if count >= LIMIT:\\n            return 'remove'\\n\\n    \\n    else:\\n        \\n        return 'update_std'\\n\\n    \\n    return 'continue'\\n\\n\\ndef resize(img):\\n    \\n    \\n    width = np.shape(img)[1]\\n    height = np.shape(img)[0]\\n\\n    \\n    if width > RESIZE:\\n        \\n        scale = RESIZE / width\\n        resized_img = cv2.resize(\\n            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\\n        \\n        return resized_img\\n\\n    \\n    return img\\n\\n\\ndef set_standard(images, filename):\\n    \\n    return filename, calc_hash(images[filename]), 0\\n\", 'summary': \"This Python code is designed to process images and determine whether they should be updated or removed based on their similarity to a standard image. Here's a summary of the key components:\\n\\n1. **Imports**: The code imports necessary libraries including PIL for image processing, cv2 for computer vision tasks, imagehash for hashing images, math for mathematical operations, and numpy for numerical computations.\\n\\n2. **Constants**:\\n   - `DIFF_THRES`: A threshold value (20) used to compare the difference between hashes.\\n   - `LIMIT`: A limit on how many times an image can be updated before it is removed (2).\\n   - `RESIZE`: The maximum width of images after resizing (1000 pixels).\\n\\n3. **Functions**:\\n   - **`calc_hash(img)`**: Resizes the image and calculates its hash using the Wavelet Hashing method.\\n   - **`compare(hash1, hash2)`**: Compares two hashes by subtracting one from the other.\\n   - **`limit(img, std_hash, count)`**: Determines whether to update the standard image, remove it, or continue processing based on the difference between the current image's hash and the standard hash. It also checks if the image has been updated too many times.\\n   - **`resize(img)`**: Resizes an image to a maximum width of 1000 pixels while maintaining the aspect ratio.\\n   - **`set_standard(images, filename)`**: Sets up the standard image by calculating its hash and initializing a count.\\n\\n4. **Usage**:\\n   - The code is intended to be used in a larger system where images are processed and compared against a standard image. It helps in managing image versions and deciding whether to keep or remove them based on their similarity.\\n\\nThis code provides a basic framework for image version control and can be extended with additional functionality such as handling multiple images, saving the state of images, and integrating with other systems for image management.\"}\n",
            "Summary: This Python code is designed to process images and determine whether they should be updated or removed based on their similarity to a standard image. Here's a summary of the key components:\n",
            "\n",
            "1. **Imports**: The code imports necessary libraries including PIL for image processing, cv2 for computer vision tasks, imagehash for hashing images, math for mathematical operations, and numpy for numerical computations.\n",
            "\n",
            "2. **Constants**:\n",
            "   - `DIFF_THRES`: A threshold value (20) used to compare the difference between hashes.\n",
            "   - `LIMIT`: A limit on how many times an image can be updated before it is removed (2).\n",
            "   - `RESIZE`: The maximum width of images after resizing (1000 pixels).\n",
            "\n",
            "3. **Functions**:\n",
            "   - **`calc_hash(img)`**: Resizes the image and calculates its hash using the Wavelet Hashing method.\n",
            "   - **`compare(hash1, hash2)`**: Compares two hashes by subtracting one from the other.\n",
            "   - **`limit(img, std_hash, count)`**: Determines whether to update the standard image, remove it, or continue processing based on the difference between the current image's hash and the standard hash. It also checks if the image has been updated too many times.\n",
            "   - **`resize(img)`**: Resizes an image to a maximum width of 1000 pixels while maintaining the aspect ratio.\n",
            "   - **`set_standard(images, filename)`**: Sets up the standard image by calculating its hash and initializing a count.\n",
            "\n",
            "4. **Usage**:\n",
            "   - The code is intended to be used in a larger system where images are processed and compared against a standard image. It helps in managing image versions and deciding whether to keep or remove them based on their similarity.\n",
            "\n",
            "This code provides a basic framework for image version control and can be extended with additional functionality such as handling multiple images, saving the state of images, and integrating with other systems for image management.\n",
            "\n",
            "\n",
            "ID: 2\n",
            "Entry: {'code': \"from .cli.cli import main\\n\\n\\n\\n\\n\\nif __name__ == '__main__':\\n    main()\\n\", 'summary': 'This Python script is designed to run a command-line interface (CLI) application. Here\\'s a breakdown of what it does:\\n\\n1. **Import Statement**:\\n   ```python\\n   from .cli.cli import main\\n   ```\\n   This line imports the `main` function from the `cli.py` module located in the `cli` subdirectory relative to the current script.\\n\\n2. **Main Guard**:\\n   ```python\\n   if __name__ == \\'__main__\\':\\n       main()\\n   ```\\n   This is a common Python idiom known as the \"main guard\" or \"entry point\". It checks whether the script is being run directly (i.e., not imported as a module in another script). If it is being run directly, it calls the `main` function.\\n\\n### Summary\\n- The script imports a `main` function from a subdirectory.\\n- It includes a guard to ensure that the `main` function is only called when the script is executed directly, not when imported as a module.'}\n",
            "Summary: This Python script is designed to run a command-line interface (CLI) application. Here's a breakdown of what it does:\n",
            "\n",
            "1. **Import Statement**:\n",
            "   ```python\n",
            "   from .cli.cli import main\n",
            "   ```\n",
            "   This line imports the `main` function from the `cli.py` module located in the `cli` subdirectory relative to the current script.\n",
            "\n",
            "2. **Main Guard**:\n",
            "   ```python\n",
            "   if __name__ == '__main__':\n",
            "       main()\n",
            "   ```\n",
            "   This is a common Python idiom known as the \"main guard\" or \"entry point\". It checks whether the script is being run directly (i.e., not imported as a module in another script). If it is being run directly, it calls the `main` function.\n",
            "\n",
            "### Summary\n",
            "- The script imports a `main` function from a subdirectory.\n",
            "- It includes a guard to ensure that the `main` function is only called when the script is executed directly, not when imported as a module.\n",
            "\n",
            "\n",
            "ID: 3\n",
            "Entry: {'code': 'import time\\n\\nfrom PyQt5 import QtGui, QtCore\\n\\nfrom ui.room_item import Ui_Form\\nfrom PyQt5.QtWidgets import QWidget\\n\\nclass Room_Item(QWidget,Ui_Form):\\n    def __init__(self,parent=None,room_data=None):\\n        super(Room_Item,self).__init__(parent)\\n        self.setupUi(self)\\n        self.data = room_data\\n        self.setRoomInfo()\\n\\n    def setRoomInfo(self):\\n        self.room_name.setText(\\'{}({})\\'.format(self.data[\\'naturalName\\'], self.data[\\'roomName\\']))\\n        self.description.setText(\"<a style=\\'color:\\n        timeStamp = int(self.data[\\'creationDate\\']) / 1000\\n        timeArray = time.localtime(timeStamp)\\n        otherStyleTime = time.strftime(\"%Y-%m-%d\", timeArray)\\n        self.create_time.setText(\"<a style=\\'color:\\n        members = len(self.data[\\'owners\\']) + len(self.data[\\'admins\\']) + len(self.data[\\'members\\'])\\n        memberCounter = \"<a style=\\'color:\\n        self.member.setText(memberCounter)', 'summary': \"This Python code defines a class `Room_Item` that inherits from both `QWidget` and `Ui_Form`. The class is designed to display information about a room in a graphical user interface (GUI). Here's a summary of the key components:\\n\\n1. **Imports**:\\n   - The code imports necessary modules, including `time`, `PyQt5.QtGui`, `PyQt5.QtCore`, and custom UI elements from `ui.room_item`.\\n\\n2. **Class Definition**:\\n   - `Room_Item` is a subclass of `QWidget` and `Ui_Form`. This allows it to use both the widget functionality and the UI layout defined in `Ui_Form`.\\n\\n3. **Constructor (`__init__`)**:\\n   - The constructor initializes the `Room_Item` object.\\n   - It calls the superclass constructors using `super(Room_Item, self).__init__(parent)`.\\n   - It sets up the user interface by calling `self.setupUi(self)`.\\n   - It stores the room data passed as an argument and calls `self.setRoomInfo()` to populate the UI with this data.\\n\\n4. **Method (`setRoomInfo`)**:\\n   - This method updates the UI elements based on the room data.\\n   - It sets the text of a label (`room_name`) to display both the natural name and the room name of the room.\\n   - It converts a timestamp (presumably in milliseconds) from the room data into a human-readable date format and displays it.\\n   - It calculates the total number of members (owners, admins, and regular members) and updates another label (`member`) with this count.\\n\\nThe code is structured to be used within a PyQt5 application, where `Room_Item` would typically be instantiated and added to a layout in a main window or dialog.\"}\n",
            "Summary: This Python code defines a class `Room_Item` that inherits from both `QWidget` and `Ui_Form`. The class is designed to display information about a room in a graphical user interface (GUI). Here's a summary of the key components:\n",
            "\n",
            "1. **Imports**:\n",
            "   - The code imports necessary modules, including `time`, `PyQt5.QtGui`, `PyQt5.QtCore`, and custom UI elements from `ui.room_item`.\n",
            "\n",
            "2. **Class Definition**:\n",
            "   - `Room_Item` is a subclass of `QWidget` and `Ui_Form`. This allows it to use both the widget functionality and the UI layout defined in `Ui_Form`.\n",
            "\n",
            "3. **Constructor (`__init__`)**:\n",
            "   - The constructor initializes the `Room_Item` object.\n",
            "   - It calls the superclass constructors using `super(Room_Item, self).__init__(parent)`.\n",
            "   - It sets up the user interface by calling `self.setupUi(self)`.\n",
            "   - It stores the room data passed as an argument and calls `self.setRoomInfo()` to populate the UI with this data.\n",
            "\n",
            "4. **Method (`setRoomInfo`)**:\n",
            "   - This method updates the UI elements based on the room data.\n",
            "   - It sets the text of a label (`room_name`) to display both the natural name and the room name of the room.\n",
            "   - It converts a timestamp (presumably in milliseconds) from the room data into a human-readable date format and displays it.\n",
            "   - It calculates the total number of members (owners, admins, and regular members) and updates another label (`member`) with this count.\n",
            "\n",
            "The code is structured to be used within a PyQt5 application, where `Room_Item` would typically be instantiated and added to a layout in a main window or dialog.\n",
            "\n",
            "\n",
            "ID: 4\n",
            "Entry: {'code': 'import asyncio\\nimport re\\nimport sys\\nimport traceback\\n\\nimport toga\\nfrom toga import Key\\nfrom .keys import toga_to_winforms_key\\n\\nfrom .libs import Threading, WinForms, shcore, user32, win_version\\nfrom .libs.proactor import WinformsProactorEventLoop\\nfrom .window import Window\\n\\n\\nclass MainWindow(Window):\\n    def winforms_FormClosing(self, sender, event):\\n        if not self.interface.app._impl._is_exiting:\\n            event.Cancel = not self.interface.app.exit()\\n\\n\\nclass App:\\n    _MAIN_WINDOW_CLASS = MainWindow\\n\\n    def __init__(self, interface):\\n        self.interface = interface\\n        self.interface._impl = self\\n\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        self._is_exiting = False\\n\\n        self.loop = WinformsProactorEventLoop()\\n        asyncio.set_event_loop(self.loop)\\n\\n    def create(self):\\n        self.native = WinForms.Application\\n        self.app_context = WinForms.ApplicationContext()\\n\\n        \\n        \\n        \\n        \\n        if win_version.Major >= 6:  \\n            \\n            \\n            if ((win_version.Major == 6 and win_version.Minor == 3) or\\n                    (win_version.Major == 10 and win_version.Build < 15063)):\\n                shcore.SetProcessDpiAwareness(True)\\n            \\n            \\n            elif win_version.Major == 10 and win_version.Build >= 15063:\\n                user32.SetProcessDpiAwarenessContext(-2)\\n            \\n            else:\\n                user32.SetProcessDPIAware()\\n\\n        self.native.EnableVisualStyles()\\n        self.native.SetCompatibleTextRenderingDefault(False)\\n\\n        self.interface.commands.add(\\n            toga.Command(\\n                lambda _: self.interface.about(),\\n                \\'About {}\\'.format(self.interface.name),\\n                group=toga.Group.HELP\\n            ),\\n            toga.Command(None, \\'Preferences\\', group=toga.Group.FILE),\\n            \\n            toga.Command(\\n                lambda _: self.interface.exit(),\\n                \\'Exit \\' + self.interface.name,\\n                shortcut=Key.MOD_1 + \\'q\\',\\n                group=toga.Group.FILE,\\n                section=sys.maxsize\\n            ),\\n            toga.Command(\\n                lambda _: self.interface.visit_homepage(),\\n                \\'Visit homepage\\',\\n                enabled=self.interface.home_page is not None,\\n                group=toga.Group.HELP\\n            )\\n        )\\n        self._create_app_commands()\\n\\n        \\n        self.interface.startup()\\n        self.create_menus()\\n        self.interface.icon.bind(self.interface.factory)\\n        self.interface.main_window._impl.set_app(self)\\n\\n    def create_menus(self):\\n        self._menu_items = {}\\n        self._menu_groups = {}\\n\\n        toga.Group.FILE.order = 0\\n        menubar = WinForms.MenuStrip()\\n        submenu = None\\n        for cmd in self.interface.commands:\\n            if cmd == toga.GROUP_BREAK:\\n                submenu = None\\n            elif cmd == toga.SECTION_BREAK:\\n                submenu.DropDownItems.Add(\\'-\\')\\n            else:\\n                submenu = self._submenu(cmd.group, menubar)\\n\\n                item = WinForms.ToolStripMenuItem(cmd.label)\\n\\n                if cmd.action:\\n                    item.Click += cmd._impl.as_handler()\\n                item.Enabled = cmd.enabled\\n\\n                if cmd.shortcut is not None:\\n                    shortcut_keys = toga_to_winforms_key(cmd.shortcut)\\n                    item.ShortcutKeys = shortcut_keys\\n                    item.ShowShortcutKeys = True\\n\\n                cmd._impl.native.append(item)\\n\\n                self._menu_items[item] = cmd\\n                submenu.DropDownItems.Add(item)\\n\\n        self.interface.main_window._impl.native.Controls.Add(menubar)\\n        self.interface.main_window._impl.native.MainMenuStrip = menubar\\n        self.interface.main_window.content.refresh()\\n\\n    def _submenu(self, group, menubar):\\n        try:\\n            return self._menu_groups[group]\\n        except KeyError:\\n            if group is None:\\n                submenu = menubar\\n            else:\\n                parent_menu = self._submenu(group.parent, menubar)\\n\\n                submenu = WinForms.ToolStripMenuItem(group.label)\\n\\n                \\n                if group.parent is None:\\n                    parent_menu.Items.Add(submenu)\\n                else:\\n                    parent_menu.DropDownItems.Add(submenu)\\n\\n            self._menu_groups[group] = submenu\\n        return submenu\\n\\n    def _create_app_commands(self):\\n        \\n        pass\\n\\n    def open_document(self, fileURL):\\n        \\n        print(\"STUB: If you want to handle opening documents, implement App.open_document(fileURL)\")\\n\\n    def winforms_thread_exception(self, sender, winforms_exc):\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        print(\"Traceback (most recent call last):\")\\n        py_exc = winforms_exc.get_Exception()\\n        full_stack_trace = py_exc.StackTrace\\n        regex = re.compile(\\n            r\"^\\\\[(?:\\'(.*?)\\', )*(?:\\'(.*?)\\')\\\\]   (?:.*?) Python\\\\.Runtime\",\\n            re.DOTALL | re.UNICODE\\n        )\\n\\n        stacktrace_relevant_lines = regex.findall(full_stack_trace)\\n        if len(stacktrace_relevant_lines) == 0:\\n            self.print_stack_trace(full_stack_trace)\\n        else:\\n            for lines in stacktrace_relevant_lines:\\n                for line in lines:\\n                    self.print_stack_trace(line)\\n        print(py_exc.Message)\\n\\n    @classmethod\\n    def print_stack_trace(cls, stack_trace_line):\\n        for level in stack_trace_line.split(\"\\', \\'\"):\\n            for line in level.split(\"\\\\\\\\n\"):\\n                if line:\\n                    print(line)\\n\\n    def run_app(self):\\n        try:\\n            self.create()\\n\\n            self.native.ThreadException += self.winforms_thread_exception\\n\\n            self.loop.run_forever(self.app_context)\\n        except:  \\n            traceback.print_exc()\\n\\n    def main_loop(self):\\n        thread = Threading.Thread(Threading.ThreadStart(self.run_app))\\n        thread.SetApartmentState(Threading.ApartmentState.STA)\\n        thread.Start()\\n        thread.Join()\\n\\n    def show_about_dialog(self):\\n        message_parts = []\\n        if self.interface.name is not None:\\n            if self.interface.version is not None:\\n                message_parts.append(\\n                    \"{name} v{version}\".format(\\n                        name=self.interface.name,\\n                        version=self.interface.version,\\n                    )\\n                )\\n            else:\\n                message_parts.append(\\n                    \"{name}\".format(name=self.interface.name)\\n                )\\n        elif self.interface.version is not None:\\n            message_parts.append(\\n                \"v{version}\".format(version=self.interface.version)\\n            )\\n\\n        if self.interface.author is not None:\\n            message_parts.append(\\n                \"Author: {author}\".format(author=self.interface.author)\\n            )\\n        if self.interface.description is not None:\\n            message_parts.append(\\n                \"\\\\n{description}\".format(\\n                    description=self.interface.description\\n                )\\n            )\\n        self.interface.main_window.info_dialog(\\n            \\'About {}\\'.format(self.interface.name), \"\\\\n\".join(message_parts)\\n        )\\n\\n    def exit(self):\\n        self._is_exiting = True\\n        self.native.Exit()\\n\\n    def set_main_window(self, window):\\n        self.app_context.MainForm = window._impl.native\\n\\n    def set_on_exit(self, value):\\n        pass\\n\\n    def current_window(self):\\n        self.interface.factory.not_implemented(\\'App.current_window()\\')\\n\\n    def enter_full_screen(self, windows):\\n        self.interface.factory.not_implemented(\\'App.enter_full_screen()\\')\\n\\n    def exit_full_screen(self, windows):\\n        self.interface.factory.not_implemented(\\'App.exit_full_screen()\\')\\n\\n    def set_cursor(self, value):\\n        self.interface.factory.not_implemented(\\'App.set_cursor()\\')\\n\\n    def show_cursor(self):\\n        self.interface.factory.not_implemented(\\'App.show_cursor()\\')\\n\\n    def hide_cursor(self):\\n        self.interface.factory.not_implemented(\\'App.hide_cursor()\\')\\n\\n    def add_background_task(self, handler):\\n        self.loop.call_soon(handler, self)\\n\\n\\nclass DocumentApp(App):\\n    def _create_app_commands(self):\\n        self.interface.commands.add(\\n            toga.Command(\\n                lambda w: self.open_file,\\n                label=\\'Open...\\',\\n                shortcut=Key.MOD_1 + \\'o\\',\\n                group=toga.Group.FILE,\\n                section=0\\n            ),\\n        )\\n\\n    def open_document(self, fileURL):\\n        \\n        self.interface.factory.not_implemented(\\'DocumentApp.open_document()\\')\\n', 'summary': 'This Python code defines a class `App` that represents the main application logic for a Toga-based GUI application running on Windows using WinForms. The class includes methods to create and manage the application window, handle commands, create menus, and manage the event loop.\\n\\nKey functionalities include:\\n- Initializing the application with an interface.\\n- Creating the main window and setting up the event loop.\\n- Handling menu creation and command execution.\\n- Managing document opening.\\n- Running the application in a separate thread to avoid blocking the UI.\\n- Providing methods for showing about dialogs, exiting the application, and managing cursor visibility.\\n\\nThe `DocumentApp` class extends `App` and adds specific functionality for handling documents, including an \"Open...\" menu item.'}\n",
            "Summary: This Python code defines a class `App` that represents the main application logic for a Toga-based GUI application running on Windows using WinForms. The class includes methods to create and manage the application window, handle commands, create menus, and manage the event loop.\n",
            "\n",
            "Key functionalities include:\n",
            "- Initializing the application with an interface.\n",
            "- Creating the main window and setting up the event loop.\n",
            "- Handling menu creation and command execution.\n",
            "- Managing document opening.\n",
            "- Running the application in a separate thread to avoid blocking the UI.\n",
            "- Providing methods for showing about dialogs, exiting the application, and managing cursor visibility.\n",
            "\n",
            "The `DocumentApp` class extends `App` and adds specific functionality for handling documents, including an \"Open...\" menu item.\n",
            "\n",
            "\n",
            "ID: 5\n",
            "Entry: {'code': '__version__ = \"0.4.0\"\\n\\n\\ndef classFactory(iface):  \\n    \\n    \\n    from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner\\n    return SimplePhotogrammetryRoutePlanner(iface)\\n', 'summary': 'This Python code defines a module with a version number and a function to create an instance of a specific class. Here\\'s a summary:\\n\\n1. **Version Information**:\\n   - The `__version__` variable is set to `\"0.4.0\"`, indicating the version of this module.\\n\\n2. **Class Factory Function**:\\n   - The `classFactory` function takes one parameter, `iface`.\\n   - Inside the function, it imports a class named `SimplePhotogrammetryRoutePlanner` from a relative module (`from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner`).\\n   - It then returns an instance of `SimplePhotogrammetryRoutePlanner`, passing the `iface` parameter to its constructor.\\n\\n### Purpose\\nThis code is likely part of a larger system where different route planning algorithms or tools are dynamically loaded and instantiated based on some configuration or interface. The `classFactory` function serves as a factory method to create instances of the `SimplePhotogrammetryRoutePlanner` class, which presumably implements specific functionality for photogrammetry-based route planning.\\n\\n### Usage\\nTo use this code:\\n1. Ensure that the relative module (`SimplePhotogrammetryRoutePlanner.py`) is in the same directory or correctly referenced.\\n2. Call the `classFactory` function with an appropriate `iface` parameter to create an instance of `SimplePhotogrammetryRoutePlanner`.\\n\\nExample usage:\\n```python\\nfrom . import classFactory\\n\\n# Assuming \\'iface\\' is already defined and suitable for the route planner\\nroute_planner = classFactory(iface)\\n```\\n\\nThis would create an instance of `SimplePhotogrammetryRoutePlanner` with the provided `iface`.'}\n",
            "Summary: This Python code defines a module with a version number and a function to create an instance of a specific class. Here's a summary:\n",
            "\n",
            "1. **Version Information**:\n",
            "   - The `__version__` variable is set to `\"0.4.0\"`, indicating the version of this module.\n",
            "\n",
            "2. **Class Factory Function**:\n",
            "   - The `classFactory` function takes one parameter, `iface`.\n",
            "   - Inside the function, it imports a class named `SimplePhotogrammetryRoutePlanner` from a relative module (`from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner`).\n",
            "   - It then returns an instance of `SimplePhotogrammetryRoutePlanner`, passing the `iface` parameter to its constructor.\n",
            "\n",
            "### Purpose\n",
            "This code is likely part of a larger system where different route planning algorithms or tools are dynamically loaded and instantiated based on some configuration or interface. The `classFactory` function serves as a factory method to create instances of the `SimplePhotogrammetryRoutePlanner` class, which presumably implements specific functionality for photogrammetry-based route planning.\n",
            "\n",
            "### Usage\n",
            "To use this code:\n",
            "1. Ensure that the relative module (`SimplePhotogrammetryRoutePlanner.py`) is in the same directory or correctly referenced.\n",
            "2. Call the `classFactory` function with an appropriate `iface` parameter to create an instance of `SimplePhotogrammetryRoutePlanner`.\n",
            "\n",
            "Example usage:\n",
            "```python\n",
            "from . import classFactory\n",
            "\n",
            "# Assuming 'iface' is already defined and suitable for the route planner\n",
            "route_planner = classFactory(iface)\n",
            "```\n",
            "\n",
            "This would create an instance of `SimplePhotogrammetryRoutePlanner` with the provided `iface`.\n",
            "\n",
            "\n",
            "ID: 6\n",
            "Entry: {'code': 'from sklearn.feature_selection import VarianceThreshold\\nimport numpy as np\\n\\nnp.random.seed(1)\\nX = np.random.randn(100, 10)\\nX = np.hstack([X, np.zeros([100, 5])])\\n\\n\\n\\ndef featureSelection_variance(X, thrd):\\n    sel = VarianceThreshold(threshold=thrd)\\n    X_selected = sel.fit_transform(X)\\n    mask = sel.get_support()\\n    return X_selected, mask\\n\\n\\nX = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\\nselector = VarianceThreshold()\\nselector.fit_transform(X)\\nselector.variances_\\n', 'summary': \"The provided Python code demonstrates how to use the `VarianceThreshold` class from the `sklearn.feature_selection` module for feature selection based on variance. Here's a summary of the code:\\n\\n1. **Importing Libraries**:\\n   - The code imports `VarianceThreshold` from `sklearn.feature_selection` and `numpy` as `np`.\\n\\n2. **Setting Random Seed and Creating Data**:\\n   - A random seed is set to 1 for reproducibility.\\n   - A matrix `X` of shape (100, 10) is created with normally distributed random numbers.\\n   - Additional columns of zeros are appended to `X`, making it a total of 15 columns.\\n\\n3. **Defining the Feature Selection Function**:\\n   - The function `featureSelection_variance` takes two parameters: `X` (the data matrix) and `thrd` (the threshold for variance).\\n   - It creates an instance of `VarianceThreshold` with the specified threshold.\\n   - The function fits the selector to `X` and transforms it, selecting features based on their variance being greater than or equal to the threshold.\\n   - It returns the transformed data matrix `X_selected` and a boolean mask indicating which features were selected.\\n\\n4. **Example Usage of Feature Selection Function**:\\n   - A small example dataset `X` is defined with three rows and four columns.\\n   - An instance of `VarianceThreshold` is created without specifying a threshold, so it uses the default threshold (0).\\n   - The function `fit_transform` is called on this selector with the example data, which selects features based on their variance.\\n   - The variances of all features in the dataset are printed.\\n\\nIn summary, the code provides a basic implementation of feature selection using variance as a criterion. It includes both a general-purpose function for applying variance thresholding to any dataset and an example demonstrating its use with a small dataset.\"}\n",
            "Summary: The provided Python code demonstrates how to use the `VarianceThreshold` class from the `sklearn.feature_selection` module for feature selection based on variance. Here's a summary of the code:\n",
            "\n",
            "1. **Importing Libraries**:\n",
            "   - The code imports `VarianceThreshold` from `sklearn.feature_selection` and `numpy` as `np`.\n",
            "\n",
            "2. **Setting Random Seed and Creating Data**:\n",
            "   - A random seed is set to 1 for reproducibility.\n",
            "   - A matrix `X` of shape (100, 10) is created with normally distributed random numbers.\n",
            "   - Additional columns of zeros are appended to `X`, making it a total of 15 columns.\n",
            "\n",
            "3. **Defining the Feature Selection Function**:\n",
            "   - The function `featureSelection_variance` takes two parameters: `X` (the data matrix) and `thrd` (the threshold for variance).\n",
            "   - It creates an instance of `VarianceThreshold` with the specified threshold.\n",
            "   - The function fits the selector to `X` and transforms it, selecting features based on their variance being greater than or equal to the threshold.\n",
            "   - It returns the transformed data matrix `X_selected` and a boolean mask indicating which features were selected.\n",
            "\n",
            "4. **Example Usage of Feature Selection Function**:\n",
            "   - A small example dataset `X` is defined with three rows and four columns.\n",
            "   - An instance of `VarianceThreshold` is created without specifying a threshold, so it uses the default threshold (0).\n",
            "   - The function `fit_transform` is called on this selector with the example data, which selects features based on their variance.\n",
            "   - The variances of all features in the dataset are printed.\n",
            "\n",
            "In summary, the code provides a basic implementation of feature selection using variance as a criterion. It includes both a general-purpose function for applying variance thresholding to any dataset and an example demonstrating its use with a small dataset.\n",
            "\n",
            "\n",
            "ID: 7\n",
            "Entry: {'code': \"from my_multi_main3 import main\\nimport numpy as np\\nimport argparse\\nimport time\\n\\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\\n                    help='input batch size for training (default: 64)')\\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\\n                    help='input batch size for testing (default: 1000)')\\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\\n                    help='number of epochs to train (default: 10)')\\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\\n                    help='learning rate (default: 0.01)')\\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\\n                    help='SGD momentum (default: 0.5)')\\nparser.add_argument('--no-cuda', action='store_true', default=False,\\n                    help='disables CUDA training')\\nparser.add_argument('--seed', type=int, default=1, metavar='S',\\n                    help='random seed (default: 1)')\\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\\n                    help='how many batches to wait before logging training status')\\nparser.add_argument('--save-model', action='store_true', default=False,\\n                    help='For Saving the current Model')\\nparser.add_argument('--norm-flag', type=bool, default=False,\\n                    help='Triggering the Layer Normalization flag for attention scores')\\nparser.add_argument('--gamma', type=float, default=None,\\n                    help='Controlling the sparisty of gfusedmax/sparsemax, the smaller, the more sparse')\\nparser.add_argument('--lam', type=float, default=1.0,\\n                    help='Lambda: Controlling the smoothness of gfusedmax, the larger, the smoother')\\nparser.add_argument('--max-type', type=str, default='softmax',choices=['softmax','sparsemax','gfusedmax'],\\n                    help='mapping function in attention')\\nparser.add_argument('--optim-type', type=str, default='SGD',choices=['SGD','Adam'],\\n                    help='mapping function in attention')\\nparser.add_argument('--head-cnt', type=int, default=2, metavar='S', choices=[1,2,4,5,10],\\n                    help='Number of heads for attention (default: 1)')\\n\\nargs = parser.parse_args()\\n\\nhyperparameter_choices = {\\n    'lr':list(10**np.arange(-4,-1,0.5)),\\n    'norm_flag': [True,False],\\n    'gamma':list(10**np.arange(-1,3,0.5))+[None,],\\n    'lam':list(10**np.arange(-2,2,0.5)),\\n    'max_type':['softmax','sparsemax','gfusedmax'],\\n    \\n    'optim_type':['SGD','Adam'],\\n    'head_cnt':[1,2,4,5,10,20]\\n}\\n\\nparam_num = 25\\nrecord = np.zeros([param_num,len(hyperparameter_choices)+1])\\nrecord_name = 'record3_multi_%s.csv'%time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime())\\nfor n in range(param_num):\\n    for param_index,(k,v) in enumerate(hyperparameter_choices.items()):\\n        print(param_index,k)\\n        value_index = np.random.choice(len(v))\\n        if isinstance(v[value_index],str) or isinstance(v[value_index],bool) or v[value_index] is None:\\n            record[n,param_index] = value_index\\n        else:\\n            record[n,param_index] = v[value_index]\\n        setattr(args,k,v[value_index])\\n    record[n,-1] = main(args)\\n    np.savetxt(record_name, record, delimiter=',')\\n\\n\\n\\n\", 'summary': \"This Python script is designed to perform hyperparameter tuning for a machine learning model using the MNIST dataset. Here's a summary of its functionality:\\n\\n1. **Argument Parsing**: The script uses `argparse` to define and parse command-line arguments that control various aspects of the training process, such as batch size, number of epochs, learning rate, etc.\\n\\n2. **Hyperparameter Choices**: A dictionary named `hyperparameter_choices` is defined, containing lists of possible values for each hyperparameter. These include learning rates, normalization flags, sparsity controls, optimization types, and more.\\n\\n3. **Record Initialization**: An array `record` is initialized to store the results of different hyperparameter combinations along with their corresponding performance metrics.\\n\\n4. **Hyperparameter Sampling**: The script iterates over a specified number of trials (`param_num`). For each trial:\\n   - It randomly selects a value for each hyperparameter from its respective list.\\n   - These values are stored in the `record` array.\\n   - The selected hyperparameters are applied to the `args` object, which is used to configure the model and training process.\\n\\n5. **Model Training**: For each set of hyperparameters, the script calls the `main` function from `my_multi_main3.py`, passing the configured `args` object. This function likely handles the actual training of the model using the specified hyperparameters.\\n\\n6. **Performance Recording**: The performance metric (likely accuracy or loss) returned by the `main` function is recorded in the `record` array along with the corresponding hyperparameter values.\\n\\n7. **Saving Results**: After all trials are completed, the script saves the entire `record` array to a CSV file named according to the current date and time. This allows for later analysis of which hyperparameter combinations performed best.\\n\\nOverall, this script automates the process of exploring different sets of hyperparameters to find the optimal configuration for training a machine learning model on the MNIST dataset.\"}\n",
            "Summary: This Python script is designed to perform hyperparameter tuning for a machine learning model using the MNIST dataset. Here's a summary of its functionality:\n",
            "\n",
            "1. **Argument Parsing**: The script uses `argparse` to define and parse command-line arguments that control various aspects of the training process, such as batch size, number of epochs, learning rate, etc.\n",
            "\n",
            "2. **Hyperparameter Choices**: A dictionary named `hyperparameter_choices` is defined, containing lists of possible values for each hyperparameter. These include learning rates, normalization flags, sparsity controls, optimization types, and more.\n",
            "\n",
            "3. **Record Initialization**: An array `record` is initialized to store the results of different hyperparameter combinations along with their corresponding performance metrics.\n",
            "\n",
            "4. **Hyperparameter Sampling**: The script iterates over a specified number of trials (`param_num`). For each trial:\n",
            "   - It randomly selects a value for each hyperparameter from its respective list.\n",
            "   - These values are stored in the `record` array.\n",
            "   - The selected hyperparameters are applied to the `args` object, which is used to configure the model and training process.\n",
            "\n",
            "5. **Model Training**: For each set of hyperparameters, the script calls the `main` function from `my_multi_main3.py`, passing the configured `args` object. This function likely handles the actual training of the model using the specified hyperparameters.\n",
            "\n",
            "6. **Performance Recording**: The performance metric (likely accuracy or loss) returned by the `main` function is recorded in the `record` array along with the corresponding hyperparameter values.\n",
            "\n",
            "7. **Saving Results**: After all trials are completed, the script saves the entire `record` array to a CSV file named according to the current date and time. This allows for later analysis of which hyperparameter combinations performed best.\n",
            "\n",
            "Overall, this script automates the process of exploring different sets of hyperparameters to find the optimal configuration for training a machine learning model on the MNIST dataset.\n",
            "\n",
            "\n",
            "ID: 8\n",
            "Entry: {'code': 'from __future__ import print_function, absolute_import\\n\\nimport h5py\\n\\nfrom spiker import log\\n\\nlogger = log.get_logger(\"data-hdf5\", log.DEBUG)\\n\\n\\ndef init_hdf5(file_path, mode=\"w\", cam_type=\"davis\"):\\n    \\n    if mode == \"w\":\\n        dataset = h5py.File(file_path, mode=mode)\\n        dataset.create_group(\"dvs\")\\n        dataset.create_group(\"extra\")\\n        if cam_type == \"davis\":\\n            dataset.create_group(\"aps\")\\n            dataset.create_group(\"imu\")\\n    elif mode == \"r\":\\n        dataset = h5py.File(file_path, mode=mode)\\n\\n    return dataset\\n', 'summary': 'This Python code defines a function `init_hdf5` that initializes an HDF5 file for storing data. The function takes three parameters: `file_path`, `mode`, and `cam_type`. \\n\\n- `file_path`: The path to the HDF5 file.\\n- `mode`: The mode in which the file is opened, either \"w\" (write mode) or \"r\" (read mode).\\n- `cam_type`: A string indicating the type of camera, defaulting to \"davis\".\\n\\nThe function uses the `h5py` library to handle HDF5 files. It also imports a logger from the `spiker.log` module.\\n\\nHere\\'s what happens in the function:\\n\\n1. If the mode is \"w\" (write mode):\\n   - The function opens an HDF5 file at the specified path.\\n   - It creates three groups: \"dvs\", \"extra\", and \"aps\" if the camera type is \"davis\".\\n   - It also creates another group called \"imu\".\\n\\n2. If the mode is \"r\" (read mode):\\n   - The function opens an HDF5 file at the specified path in read mode.\\n\\nThe function returns the dataset object, which can be used to interact with the HDF5 file.\\n\\nThis setup is typically used for storing data from a camera system, where different types of data (like DVS events, extra information, and sensor data) are organized into separate groups within the HDF5 file.'}\n",
            "Summary: This Python code defines a function `init_hdf5` that initializes an HDF5 file for storing data. The function takes three parameters: `file_path`, `mode`, and `cam_type`. \n",
            "\n",
            "- `file_path`: The path to the HDF5 file.\n",
            "- `mode`: The mode in which the file is opened, either \"w\" (write mode) or \"r\" (read mode).\n",
            "- `cam_type`: A string indicating the type of camera, defaulting to \"davis\".\n",
            "\n",
            "The function uses the `h5py` library to handle HDF5 files. It also imports a logger from the `spiker.log` module.\n",
            "\n",
            "Here's what happens in the function:\n",
            "\n",
            "1. If the mode is \"w\" (write mode):\n",
            "   - The function opens an HDF5 file at the specified path.\n",
            "   - It creates three groups: \"dvs\", \"extra\", and \"aps\" if the camera type is \"davis\".\n",
            "   - It also creates another group called \"imu\".\n",
            "\n",
            "2. If the mode is \"r\" (read mode):\n",
            "   - The function opens an HDF5 file at the specified path in read mode.\n",
            "\n",
            "The function returns the dataset object, which can be used to interact with the HDF5 file.\n",
            "\n",
            "This setup is typically used for storing data from a camera system, where different types of data (like DVS events, extra information, and sensor data) are organized into separate groups within the HDF5 file.\n",
            "\n",
            "\n",
            "ID: 9\n",
            "Entry: {'code': \"import flatbuffers\\n\\nclass FloatingPoint(object):\\n    __slots__ = ['_tab']\\n\\n    @classmethod\\n    def GetRootAsFloatingPoint(cls, buf, offset):\\n        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)\\n        x = FloatingPoint()\\n        x.Init(buf, n + offset)\\n        return x\\n\\n    \\n    def Init(self, buf, pos):\\n        self._tab = flatbuffers.table.Table(buf, pos)\\n\\n    \\n    def Precision(self):\\n        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))\\n        if o != 0:\\n            return self._tab.Get(flatbuffers.number_types.Int16Flags, o + self._tab.Pos)\\n        return 0\\n\\ndef FloatingPointStart(builder): builder.StartObject(1)\\ndef FloatingPointAddPrecision(builder, precision): builder.PrependInt16Slot(0, precision, 0)\\ndef FloatingPointEnd(builder): return builder.EndObject()\\n\", 'summary': \"This Python code defines a class `FloatingPoint` that represents a floating-point number with a specific precision. It uses the FlatBuffers library to serialize and deserialize the data efficiently.\\n\\nHere's a breakdown of the key components:\\n\\n1. **Class Definition**:\\n   - The `FloatingPoint` class has a single attribute `_tab`, which is used to store the table data from FlatBuffers.\\n\\n2. **Class Methods**:\\n   - `GetRootAsFloatingPoint`: This method takes a buffer and an offset, decodes the buffer into a `FloatingPoint` object, and returns it.\\n   - `Init`: This method initializes the `_tab` attribute with the provided buffer and position.\\n\\n3. **Attribute Accessors**:\\n   - `Precision`: This method retrieves the precision of the floating-point number from the table. If the offset is not zero, it reads the int16 value at that offset; otherwise, it returns 0.\\n\\n4. **FlatBuffers Builder Methods**:\\n   - `FloatingPointStart`, `FloatingPointAddPrecision`, and `FloatingPointEnd`: These methods are used to construct a `FloatingPoint` object using the FlatBuffers builder API.\\n     - `FloatingPointStart`: Starts building a new `FloatingPoint` object.\\n     - `FloatingPointAddPrecision`: Adds a precision value to the `FloatingPoint` object being built.\\n     - `FloatingPointEnd`: Completes the construction of the `FloatingPoint` object and returns its offset.\\n\\nThis class is useful for handling floating-point numbers with specific precision in applications that require efficient serialization and deserialization, such as network protocols or data storage systems.\"}\n",
            "Summary: This Python code defines a class `FloatingPoint` that represents a floating-point number with a specific precision. It uses the FlatBuffers library to serialize and deserialize the data efficiently.\n",
            "\n",
            "Here's a breakdown of the key components:\n",
            "\n",
            "1. **Class Definition**:\n",
            "   - The `FloatingPoint` class has a single attribute `_tab`, which is used to store the table data from FlatBuffers.\n",
            "\n",
            "2. **Class Methods**:\n",
            "   - `GetRootAsFloatingPoint`: This method takes a buffer and an offset, decodes the buffer into a `FloatingPoint` object, and returns it.\n",
            "   - `Init`: This method initializes the `_tab` attribute with the provided buffer and position.\n",
            "\n",
            "3. **Attribute Accessors**:\n",
            "   - `Precision`: This method retrieves the precision of the floating-point number from the table. If the offset is not zero, it reads the int16 value at that offset; otherwise, it returns 0.\n",
            "\n",
            "4. **FlatBuffers Builder Methods**:\n",
            "   - `FloatingPointStart`, `FloatingPointAddPrecision`, and `FloatingPointEnd`: These methods are used to construct a `FloatingPoint` object using the FlatBuffers builder API.\n",
            "     - `FloatingPointStart`: Starts building a new `FloatingPoint` object.\n",
            "     - `FloatingPointAddPrecision`: Adds a precision value to the `FloatingPoint` object being built.\n",
            "     - `FloatingPointEnd`: Completes the construction of the `FloatingPoint` object and returns its offset.\n",
            "\n",
            "This class is useful for handling floating-point numbers with specific precision in applications that require efficient serialization and deserialization, such as network protocols or data storage systems.\n",
            "\n",
            "\n",
            "Summaries added and saved to summarized_code_test.json\n"
          ]
        }
      ],
      "source": [
        "# Proof of concept\n",
        "\n",
        "testdf = df[\"content\"].head(10)\n",
        "\n",
        "cleaned_test = testdf.apply(clean_code)\n",
        "\n",
        "cleaned_data_list_test = cleaned_test.tolist()\n",
        "\n",
        "formatted_data_test = [{\"code\": item} for item in cleaned_data_list_test]\n",
        "\n",
        "payload_test = json.dumps(formatted_data_test, ensure_ascii=False).encode(\"utf-8\")\n",
        "\n",
        "output_filename = \"cleaned_data_test.json\"\n",
        "\n",
        "with open(output_filename, \"w\") as f:\n",
        "    json.dump(formatted_data_test, f, indent=4)\n",
        "\n",
        "print(f\"Data saved to {output_filename}\")\n",
        "\n",
        "add_summaries_to_json(\"cleaned_data_test.json\", \"summarized_code_test.json\")\n",
        "\n",
        "print(\"Summaries added and saved to summarized_code_test.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_summaries_to_json(\"cleaned_data.json\", \"summarized_code.json\")\n",
        "\n",
        "print(\"Summaries added and saved to summarized_code.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC5HnUvkAVBj"
      },
      "source": [
        "Imports and other things to start the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from fastparquet) (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from fastparquet) (2.1.3)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.9.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: fsspec in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\robbi\\appdata\\roaming\\python\\python311\\site-packages (from fastparquet) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\robbi\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\robbi\\documents\\code\\youtube_video_summarizer\\.conda\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\robbi\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl (671 kB)\n",
            "   ---------------------------------------- 0.0/671.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 671.0/671.0 kB 13.2 MB/s eta 0:00:00\n",
            "Downloading cramjam-2.9.1-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.1/2.1 MB 14.6 MB/s eta 0:00:00\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.9.1 fastparquet-2024.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vCbQXGK1AVrY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import psutil\n",
        "import json\n",
        "import urllib.request\n",
        "import fastparquet\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMg6fMnm_8ri"
      },
      "source": [
        "In order to properly use this data, we must start by importing it and then preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPQiszpK9qqe",
        "outputId": "6c9e4387-adfc-4998-b0d9-ae7e19eb814f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          hexsha   size ext    lang  \\\n",
            "0       f70001f658d4dfaa72dd4f0d1b3176492f6658bb   6442  py  Python   \n",
            "1       f7000273e22d5a0f2d5b40c38a0ed8511d1b8995   2250  py  Python   \n",
            "2       f70002926d1d600b4b068459c9dd40ebf3aef47d    757  py  Python   \n",
            "3       f7000327daf9ff11a381ce6d5de401ff007d1323   1094  py  Python   \n",
            "4       f7000371f0315cd55c0b14b33e7e8e56697cfc2e  10498  py  Python   \n",
            "...                                          ...    ...  ..     ...   \n",
            "117540  793e7c8154dde86884b9669622b32aeea1185d21   1853  py  Python   \n",
            "117541  793e7d1ab6c0471710bdbffc3c1b2a68e0aa3516    948  py  Python   \n",
            "117542  793e7e0a68202e76b818772ff6d01655ca87546e   2485  py  Python   \n",
            "117543  793e7ea61a6d183a0434da1b893d3870cec79aba   1406  py  Python   \n",
            "117544  793e7fc5c6f5a39a1fb0909ab5a3e5ce33f87ab8  25955  py  Python   \n",
            "\n",
            "                                      max_stars_repo_path  \\\n",
            "0                                       spider/openwrt.py   \n",
            "1                                        utils/compare.py   \n",
            "2                              sdk/python/kfp/__main__.py   \n",
            "3                        TestProject/app/view/RoomItem.py   \n",
            "4                       src/winforms/toga_winforms/app.py   \n",
            "...                                                   ...   \n",
            "117540                    tests/test_common_workaround.py   \n",
            "117541  www/app/Personal_development/album/migrations/...   \n",
            "117542                                    SessionState.py   \n",
            "117543                                             o3d.py   \n",
            "117544  venv/Lib/site-packages/sqlalchemy/sql/visitors.py   \n",
            "\n",
            "                       max_stars_repo_name  \\\n",
            "0                                CNDB/CNDB   \n",
            "1                              adcrn/knest   \n",
            "2                     ConverJens/pipelines   \n",
            "3                      ChinSing00/ChatChat   \n",
            "4                                holg/toga   \n",
            "...                                    ...   \n",
            "117540                  janEbert/pytorch3d   \n",
            "117541              yohei4/Django-Scraping   \n",
            "117542  VijaySingh-GSLab/venue_recommender   \n",
            "117543                  knei-knurow/AnyNet   \n",
            "117544                     MWildFire/IPCam   \n",
            "\n",
            "                      max_stars_repo_head_hexsha max_stars_repo_licenses  \\\n",
            "0       2e3a41111f604cf2f4f22a7c9370bb3f753e3e88          [BSD-3-Clause]   \n",
            "1       a274dc9ddb642cc30f837e225f000bf33430eb43          [BSD-3-Clause]   \n",
            "2       a1d453af214ec9eebad73fb05845dd3499d60d00            [Apache-2.0]   \n",
            "3       48654e2e125298c00a558449353e38d0cec06d03                   [MIT]   \n",
            "4       9dd766e749c6cf29cdb1127c7637150381ac396d          [BSD-3-Clause]   \n",
            "...                                          ...                     ...   \n",
            "117540  accdac80fb29e82f72d4e8e73135ba8fd790b6c0     [MIT, BSD-3-Clause]   \n",
            "117541  1ac72b414025e703c21076d044b5b9b421f95049                   [MIT]   \n",
            "117542  3c3bddc19c2f3be71833b85c5a1de2522771f0b3                   [MIT]   \n",
            "117543  0f726822eded48956eea6a7c9c76ae1490e8725a                   [MIT]   \n",
            "117544  7012f991a028843df8288824124f6f4b2369f155                   [MIT]   \n",
            "\n",
            "        max_stars_count max_stars_repo_stars_event_min_datetime  ...  \\\n",
            "0                   NaN                                    None  ...   \n",
            "1                   8.0                2018-03-15T23:42:51.000Z  ...   \n",
            "2                   6.0                2020-05-19T02:35:11.000Z  ...   \n",
            "3                   NaN                                    None  ...   \n",
            "4                   1.0                2020-07-16T00:46:24.000Z  ...   \n",
            "...                 ...                                     ...  ...   \n",
            "117540              1.0                2022-01-24T20:51:16.000Z  ...   \n",
            "117541              1.0                2021-09-05T02:45:59.000Z  ...   \n",
            "117542              NaN                                    None  ...   \n",
            "117543              NaN                                    None  ...   \n",
            "117544              1.0                2021-05-14T01:38:21.000Z  ...   \n",
            "\n",
            "                       max_forks_repo_name  \\\n",
            "0                                CNDB/CNDB   \n",
            "1                              adcrn/knest   \n",
            "2                     ConverJens/pipelines   \n",
            "3                      ChinSing00/ChatChat   \n",
            "4                                holg/toga   \n",
            "...                                    ...   \n",
            "117540                  janEbert/pytorch3d   \n",
            "117541              yohei4/Django-Scraping   \n",
            "117542  VijaySingh-GSLab/venue_recommender   \n",
            "117543                  knei-knurow/AnyNet   \n",
            "117544                     MWildFire/IPCam   \n",
            "\n",
            "                      max_forks_repo_head_hexsha max_forks_repo_licenses  \\\n",
            "0       2e3a41111f604cf2f4f22a7c9370bb3f753e3e88          [BSD-3-Clause]   \n",
            "1       a274dc9ddb642cc30f837e225f000bf33430eb43          [BSD-3-Clause]   \n",
            "2       a1d453af214ec9eebad73fb05845dd3499d60d00            [Apache-2.0]   \n",
            "3       48654e2e125298c00a558449353e38d0cec06d03                   [MIT]   \n",
            "4       9dd766e749c6cf29cdb1127c7637150381ac396d          [BSD-3-Clause]   \n",
            "...                                          ...                     ...   \n",
            "117540  accdac80fb29e82f72d4e8e73135ba8fd790b6c0     [MIT, BSD-3-Clause]   \n",
            "117541  1ac72b414025e703c21076d044b5b9b421f95049                   [MIT]   \n",
            "117542  3c3bddc19c2f3be71833b85c5a1de2522771f0b3                   [MIT]   \n",
            "117543  0f726822eded48956eea6a7c9c76ae1490e8725a                   [MIT]   \n",
            "117544  7012f991a028843df8288824124f6f4b2369f155                   [MIT]   \n",
            "\n",
            "       max_forks_count max_forks_repo_forks_event_min_datetime  \\\n",
            "0                  NaN                                    None   \n",
            "1                  NaN                                    None   \n",
            "2                 11.0                2020-05-19T22:26:41.000Z   \n",
            "3                  NaN                                    None   \n",
            "4                  NaN                                    None   \n",
            "...                ...                                     ...   \n",
            "117540             1.0                2022-03-29T04:29:06.000Z   \n",
            "117541             NaN                                    None   \n",
            "117542             2.0                2021-05-10T10:59:55.000Z   \n",
            "117543             NaN                                    None   \n",
            "117544             2.0                2021-05-23T16:46:31.000Z   \n",
            "\n",
            "        max_forks_repo_forks_event_max_datetime  \\\n",
            "0                                          None   \n",
            "1                                          None   \n",
            "2                      2021-01-25T09:56:21.000Z   \n",
            "3                                          None   \n",
            "4                                          None   \n",
            "...                                         ...   \n",
            "117540                 2022-03-29T04:29:06.000Z   \n",
            "117541                                     None   \n",
            "117542                 2021-05-10T11:09:11.000Z   \n",
            "117543                                     None   \n",
            "117544                 2021-05-26T23:51:09.000Z   \n",
            "\n",
            "                                                  content avg_line_length  \\\n",
            "0       #!/usr/bin/python\\n# -*- coding: utf-8 -*-\\n# ...       34.449198   \n",
            "1       # UCF Senior Design 2017-18\\n# Group 38\\n\\nfro...       24.725275   \n",
            "2       # Copyright 2018 Google LLC\\n#\\n# Licensed und...       32.913043   \n",
            "3       import time\\n\\nfrom PyQt5 import QtGui, QtCore...       45.583333   \n",
            "4       import asyncio\\nimport re\\nimport sys\\nimport ...       35.952055   \n",
            "...                                                   ...             ...   \n",
            "117540  # Copyright (c) Meta Platforms, Inc. and affil...       32.508772   \n",
            "117541  # Generated by Django 3.2.4 on 2021-07-10 18:0...       32.689655   \n",
            "117542  \\n# https://gist.github.com/FranzDiebold/89839...       29.939759   \n",
            "117543  from __future__ import (absolute_import, divis...       36.051282   \n",
            "117544  # sql/visitors.py\\n# Copyright (C) 2005-2021 t...       31.885749   \n",
            "\n",
            "       max_line_length alphanum_fraction  \n",
            "0                   78          0.472369  \n",
            "1                   78          0.646667  \n",
            "2                   74          0.749009  \n",
            "3                  138          0.659049  \n",
            "4                  101          0.597638  \n",
            "...                ...               ...  \n",
            "117540              88          0.618996  \n",
            "117541             141          0.644515  \n",
            "117542              80          0.665996  \n",
            "117543              98          0.690612  \n",
            "117544              79          0.663957  \n",
            "\n",
            "[117545 rows x 29 columns]\n",
            "#!/usr/bin/python\n",
            "# -*- coding: utf-8 -*-\n",
            "# #*** <License> ************************************************************#\n",
            "# This module is part of the repository CNDB.\n",
            "#\n",
            "# This module is licensed under the terms of the BSD 3-Clause License\n",
            "# <http://www.c-tanzer.at/license/bsd_3c.html>.\n",
            "# #*** </License> ***********************************************************#\n",
            "\n",
            "from   _TFL.pyk           import pyk\n",
            "\n",
            "from   rsclib.HTML_Parse  import tag, Page_Tree\n",
            "from   rsclib.autosuper   import autosuper\n",
            "from   spider.common      import Interface, Inet4, Inet6, unroutable\n",
            "from   spider.common      import WLAN_Config\n",
            "from   spider.luci        import Version_Mixin\n",
            "\n",
            "class Status (Page_Tree, Version_Mixin) :\n",
            "    url          = 'cgi-bin/luci/freifunk/status/status'\n",
            "    retries      = 2\n",
            "    timeout      = 10\n",
            "    html_charset = 'utf-8' # force utf-8 encoding\n",
            "\n",
            "    wl_names = dict \\\n",
            "        ( ssid    = 'ssid'\n",
            "        , _bsiid  = 'bssid'\n",
            "        , channel = 'channel'\n",
            "        , mode    = 'mode'\n",
            "        )\n",
            "\n",
            "    def parse (self) :\n",
            "        root  = self.tree.getroot ()\n",
            "        self.wlans  = []\n",
            "        self.routes = {}\n",
            "        for div in root.findall (\".//%s\" % tag (\"div\")) :\n",
            "            id = div.get ('id')\n",
            "            if id == 'cbi-wireless' :\n",
            "                wlan_div = div\n",
            "            elif id == 'cbi-routes' :\n",
            "                route_div = div\n",
            "            self.try_get_version (div)\n",
            "        for d in self.tbl_iter (wlan_div) :\n",
            "            for k, newkey in pyk.iteritems (self.wl_names) :\n",
            "                if k in d :\n",
            "                    d [newkey] = d [k]\n",
            "            wl = WLAN_Config (** d)\n",
            "            self.wlans.append (wl)\n",
            "        for d in self.tbl_iter (route_div) :\n",
            "            iface = d.get ('iface')\n",
            "            gw    = d.get ('gateway')\n",
            "            if iface and gw :\n",
            "                self.routes [iface] = gw\n",
            "        self.set_version (root)\n",
            "    # end def parse\n",
            "\n",
            "    def tbl_iter (self, div) :\n",
            "        tbl = div.find (\".//%s\" % tag (\"table\"))\n",
            "        assert tbl.get ('class') == 'cbi-section-table'\n",
            "        d = {}\n",
            "        for tr in tbl :\n",
            "            if 'cbi-section-table-row' not in tr.get ('class').split () :\n",
            "                continue\n",
            "            for input in tr.findall (\".//%s\" % tag ('input')) :\n",
            "                name = input.get ('id').split ('.') [-1]\n",
            "                val  = input.get ('value')\n",
            "                d [name] = val\n",
            "            if not d :\n",
            "                continue\n",
            "            yield d\n",
            "    # end def tbl_iter\n",
            "\n",
            "# end class Status\n",
            "\n",
            "class Table_Iter (Page_Tree) :\n",
            "\n",
            "    def table_iter (self) :\n",
            "        root  = self.tree.getroot ()\n",
            "        for div in root.findall (\".//%s\" % tag (\"div\")) :\n",
            "            if div.get ('id') == 'maincontent' :\n",
            "                break\n",
            "        tbl = div.find (\".//%s\" % tag (\"table\"))\n",
            "        if tbl is None :\n",
            "            return\n",
            "        for tr in tbl :\n",
            "            if tr [0].tag == tag ('th') :\n",
            "                continue\n",
            "            yield (self.tree.get_text (x) for x in tr)\n",
            "    # end def table_iter\n",
            "\n",
            "# end class Table_Iter\n",
            "\n",
            "class OLSR_Connections (Table_Iter) :\n",
            "    url          = 'cgi-bin/luci/freifunk/olsr/'\n",
            "    retries      = 2\n",
            "    timeout      = 10\n",
            "    html_charset = 'utf-8' # force utf-8 encoding\n",
            "\n",
            "    def parse (self) :\n",
            "        self.neighbors = {}\n",
            "        for l in self.table_iter () :\n",
            "            neighbor, ip, lq, nlq, etx = l\n",
            "            lq, nlq, etx = (float (x) for x in (lq, nlq, etx))\n",
            "            self.neighbors [neighbor] = [ip, lq, nlq, etx]\n",
            "    # end def parse\n",
            "\n",
            "# end class OLSR_Connections\n",
            "\n",
            "class OLSR_Routes (Table_Iter) :\n",
            "    url          = 'cgi-bin/luci/freifunk/olsr/routes'\n",
            "    retries      = 2\n",
            "    timeout      = 10\n",
            "    html_charset = 'utf-8' # force utf-8 encoding\n",
            "\n",
            "    def parse (self) :\n",
            "        self.iface_by_gw = {}\n",
            "        for l in self.table_iter () :\n",
            "            announced, gw, iface, metric, etx = l\n",
            "            if gw in self.iface_by_gw :\n",
            "                assert iface == self.iface_by_gw [gw]\n",
            "            else :\n",
            "                self.iface_by_gw [gw] = iface\n",
            "    # end def parse\n",
            "\n",
            "# end class OLSR_Routes\n",
            "\n",
            "class OpenWRT (autosuper) :\n",
            "\n",
            "    def __init__ (self, site, request) :\n",
            "        self.site    = site\n",
            "        self.request = request\n",
            "        if 'interfaces' in self.request or 'ips' in self.request :\n",
            "            st    = Status           (site = site)\n",
            "            conn  = OLSR_Connections (site = site)\n",
            "            route = OLSR_Routes      (site = site)\n",
            "            self.version = st.version\n",
            "            assert len (st.wlans) <= 1\n",
            "            interfaces   = {}\n",
            "            ips          = {}\n",
            "            count = 0\n",
            "            for gw, ifname in pyk.iteritems (route.iface_by_gw) :\n",
            "                ip, lq, nlq, etx  = conn.neighbors [gw]\n",
            "                i4 = Inet4 (ip, None, None, iface = ifname)\n",
            "                ips [i4] = 1\n",
            "                is_wlan = True\n",
            "                if lq == nlq == etx == 1.0 :\n",
            "                    is_wlan = False\n",
            "                if ifname in interfaces :\n",
            "                    iface = interfaces [ifname]\n",
            "                    if not iface.is_wlan and is_wlan :\n",
            "                        iface.is_wlan   = True\n",
            "                        iface.wlan_info = st.wlans [0]\n",
            "                else :\n",
            "                    iface = Interface (count, ifname, None)\n",
            "                    iface.is_wlan = is_wlan\n",
            "                    if is_wlan :\n",
            "                        iface.wlan_info = st.wlans [0]\n",
            "                    count += 1\n",
            "                    interfaces [ifname] = iface\n",
            "                if i4 not in iface.inet4 :\n",
            "                    iface.append_inet4 (i4)\n",
            "            wl_if = None\n",
            "            for iface in pyk.itervalues (interfaces) :\n",
            "                if iface.is_wlan :\n",
            "                    if wl_if :\n",
            "                        m = \"Duplicate wlan: %s/%s\" % (iface.name, wl_if.name)\n",
            "                        raise ValueError (m)\n",
            "                    wl_if = iface\n",
            "            # check own ip\n",
            "            n  = 'unknown'\n",
            "            i4 = Inet4 (self.request ['ip'], None, None, iface = n)\n",
            "            if i4 not in ips :\n",
            "                assert n not in interfaces\n",
            "                iface = interfaces [n] = Interface (count, n, None)\n",
            "                iface.append_inet4 (i4)\n",
            "                iface.is_wlan = False\n",
            "                if not wl_if and st.wlans :\n",
            "                    iface.is_wlan   = True\n",
            "                    iface.wlan_info = st.wlans [0]\n",
            "                ips [i4] = True\n",
            "\n",
            "            self.request ['ips']        = ips\n",
            "            self.request ['interfaces'] = interfaces\n",
            "            self.request ['version']    = st.version\n",
            "    # end def __init__\n",
            "\n",
            "# end class OpenWRT\n",
            "\n",
            "import os\n",
            "import json\n",
            "\n",
            "Environ = os._Environ\n",
            "\n",
            "\n",
            "def is_on_cloudfoundry(env: Environ=os.environ) -> bool:\n",
            "    return 'VCAP_SERVICES' in env\n",
            "\n",
            "\n",
            "def load_cups_from_vcap_services(name: str, env: Environ=os.environ) -> None:\n",
            "    '''\n",
            "    Detects if VCAP_SERVICES exists in the environment; if so, parses\n",
            "    it and imports all the credentials from the given custom\n",
            "    user-provided service (CUPS) as strings into the environment.\n",
            "    For more details on CUPS, see:\n",
            "    https://docs.cloudfoundry.org/devguide/services/user-provided.html\n",
            "    '''\n",
            "\n",
            "    if not is_on_cloudfoundry(env):\n",
            "        return\n",
            "\n",
            "    vcap = json.loads(env['VCAP_SERVICES'])\n",
            "\n",
            "    for entry in vcap.get('user-provided', []):\n",
            "        if entry['name'] == name:\n",
            "            for key, value in entry['credentials'].items():\n",
            "                env[key] = value\n",
            "\n",
            "\n",
            "def load_database_url_from_vcap_services(name: str, service: str,\n",
            "                                         env: Environ=os.environ) -> str:\n",
            "    \"\"\"\n",
            "    Sets os.environ[DATABASE_URL] from a service entry in VCAP_SERVICES.\n",
            "    \"\"\"\n",
            "    if not is_on_cloudfoundry(env):\n",
            "        return\n",
            "\n",
            "    # FIXME: this'll break if there are multiple databases. Not an issue right\n",
            "    # now, but could be in the future. Keep an eye on it.\n",
            "    vcap = json.loads(env['VCAP_SERVICES'])\n",
            "    env['DATABASE_URL'] = vcap[service][0][\"credentials\"][\"uri\"]\n",
            "\n",
            "#name_scan \"d/yourdomain\" 1\n",
            "import sys, os\n",
            "#sys.path.append('/home/khal/sources/nmcontrol/lib/')\n",
            "import DNS\n",
            "import rpcClient\n",
            "import struct, listdns, base64, types, json, random\n",
            "#from jsonrpc import ServiceProxy\n",
            "from utils import *\n",
            "from common import *\n",
            "\n",
            "class Source(object):\n",
            "    #def __init__(self):\n",
            "        #self.servers = app['services']['dns'].conf['resolver'].split(',')\n",
            "        #self.reqobj = DNS.Request()\n",
            "        #jsonfile = open(\"config.json\", \"r\")\n",
            "        #data = json.loads(jsonfile.read())\n",
            "        #jsonfile.close()\n",
            "        #username = str(data[u\"username\"])\n",
            "        #port = data[u\"port\"]\n",
            "        #password = str(data[u\"password\"])\n",
            "        #self.sp = ServiceProxy(\"http://%(user)s:%(passwd)s@127.0.0.1:%(port)d\" % dict(user=username, passwd=password, port=port))\n",
            "        #elf.sp = rpcClient.rpcClientNamecoin('127.0.0.1', port, username, password)\n",
            "        #self.sp = app['plugins']['domain']\n",
            "\n",
            "#    def _parse_file(self):\n",
            "#        f = open(self._filename, \"r\")\n",
            "#        for line in f.readlines():\n",
            "#            line = line.strip()\n",
            "#            if line and line[0] != '#':\n",
            "#                question, type, value = line.split()\n",
            "#                question = question.lower()\n",
            "#                type = type.upper()\n",
            "#                if question == '@':\n",
            "#                    question = ''\n",
            "#                if type == 'A':\n",
            "#                    answer = struct.pack(\"!I\", ipstr2int(value))\n",
            "#                    qtype = 1\n",
            "#                if type == 'NS':\n",
            "#                    answer = labels2str(value.split(\".\"))\n",
            "#                    qtype = 2\n",
            "#                elif type == 'CNAME':\n",
            "#                    answer = labels2str(value.split(\".\"))\n",
            "#                    qtype = 5\n",
            "#                elif type == 'TXT':\n",
            "#                    answer = label2str(value)\n",
            "#                    qtype = 16\n",
            "#                elif type == 'MX':\n",
            "#                    preference, domain = value.split(\":\")\n",
            "#                    answer = struct.pack(\"!H\", int(preference))\n",
            "#                    answer += labels2str(domain.split(\".\"))\n",
            "#                    qtype = 15\n",
            "#                self._answers.setdefault(question, {}).setdefault(qtype, []).append(answer)\n",
            "#        f.close()\n",
            "\n",
            "    def isIP(self, host) :\n",
            "        parts = host.split(\".\")\n",
            "        if len(parts) != 4:\n",
            "            return False\n",
            "        try :\n",
            "            valid = False\n",
            "            for part in parts :\n",
            "                intpart = int(part)\n",
            "                if intpart <= 255 and intpart >= 0 :\n",
            "                    valid = True\n",
            "                else : return False\n",
            "            if valid :\n",
            "                return True\n",
            "            return False\n",
            "        except : return False\n",
            "    def get_response(self, query, domain, qtype, qclass, src_addr):\n",
            "        #print query\n",
            "        #print domain\n",
            "        #print qtype\n",
            "        #print qclass\n",
            "        #print src_addr\n",
            "        if qtype == 1:\n",
            "            #answer = struct.pack(\"!I\", ipstr2int(value))\n",
            "            reqtype = \"A\"\n",
            "        if qtype == 2:\n",
            "            #answer = labels2str(value.split(\".\"))\n",
            "            reqtype = \"NS\"\n",
            "        elif qtype == 5:\n",
            "            #answer = labels2str(value.split(\".\"))\n",
            "            reqtype = \"CNAME\"\n",
            "        elif qtype == 16:\n",
            "            #answer = label2str(value)\n",
            "            reqtype = \"TXT\"\n",
            "        elif qtype == 15:\n",
            "            #preference, domain = value.split(\":\")\n",
            "            #nswer = struct.pack(\"!H\", int(preference))\n",
            "            #answer += labels2str(domain.split(\".\"))\n",
            "            reqtype = \"MX\"\n",
            "        elif qtype == 28:\n",
            "            #answer = struct.pack(\"!I\", ipstr2int(value))\n",
            "            reqtype = \"AAAA\"\n",
            "        elif qtype == 52:\n",
            "            reqtype = \"TLSA\"\n",
            "        else : reqtype = None\n",
            "        answers = app['services']['dns'].lookup({\"query\":query, \"domain\":domain, \"qtype\":qtype, \"qclass\":qclass, \"src_addr\":src_addr})\n",
            "        #print 'domain:', domain\n",
            "        #print 'answers:', answers\n",
            "        if domain.endswith(\".bit\") or domain.endswith(\".tor\") :\n",
            "            #response = listdns.lookup(self.sp, {\"query\":query, \"domain\":domain, \"qtype\":qtype, \"qclass\":qclass, \"src_addr\":src_addr})\n",
            "            #response = self.sp.lookup({\"query\":query, \"domain\":domain, \"qtype\":qtype, \"qclass\":qclass, \"src_addr\":src_addr})\n",
            "            response = answers\n",
            "            results = []\n",
            "            if type(response) == types.DictType :\n",
            "                tempresults = {\"qtype\":response[\"type\"], \"qclass\":response[\"class\"], \"ttl\":response[\"ttl\"]}\n",
            "                if response[\"type\"] == 1 :\n",
            "                    #if answers == [] :\n",
            "                    #    return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "                    tempresults[\"rdata\"] = struct.pack(\"!I\", ipstr2int(response[\"data\"]))\n",
            "                elif response[\"type\"] == 2 or response[\"type\"] == 5:\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"].split(\".\"))\n",
            "                elif response[\"type\"] == 16 :\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"])\n",
            "                elif response[\"type\"] == 15 :\n",
            "                    tempresult = struct.pack(\"!H\", response[\"data\"][0])\n",
            "                    tempresult += labels2str(response[\"data\"][1].split(\".\"))\n",
            "                    tempresults[\"rdata\"] = tempresult\n",
            "                elif response[\"type\"] == 28 :\n",
            "                    tempresults[\"rdata\"] = response[\"data\"]\n",
            "                elif response[\"type\"] == 52 :\n",
            "                    tempresult = '\\x03\\x00'\n",
            "                    tempresult += chr(int(response[\"data\"][0][0]))\n",
            "                    tempresult += bytearray.fromhex(response[\"data\"][0][1])\n",
            "                    tempresults[\"rdata\"] = tempresult\n",
            "                #else : return 3, []\n",
            "                results.append(tempresults)\n",
            "                return 0, results\n",
            "            if type(response) == types.StringType :\n",
            "                if self.isIP(response) :\n",
            "                    return 0, [{\"qtype\":1, \"qclass\":qclass, \"ttl\":300, \"rdata\":struct.pack(\"!I\", ipstr2int(response))}]\n",
            "            return 3, []\n",
            "            #if query not in self._answers:\n",
            "                #return 3, []\n",
            "            #if qtype in self._answers[query]:\n",
            "            #if domain == \"sonicrules.bit\":\n",
            "            #    results = [{'qtype': 1, 'qclass':qclass, 'ttl': 300, 'rdata': struct.pack(\"!I\", ipstr2int(self.reqobj.req(\"sonicrules.org\", qtype=1).answers[0][\"data\"]))}]\n",
            "            #    return 0, results\n",
            "            #elif qtype == 1:\n",
            "                # if they asked for an A record and we didn't find one, check for a CNAME\n",
            "                #return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "        else:\n",
            "            #server = self.servers[random.randrange(0, len(self.servers)-1)]\n",
            "            #answers = self.reqobj.req(name=domain, qtype=qtype, server=server).answers\n",
            "            results = []\n",
            "            for response in answers :\n",
            "                tempresults = {\"qtype\":response[\"type\"], \"qclass\":response[\"class\"], \"ttl\":response[\"ttl\"]}\n",
            "                if response[\"type\"] == 1 :\n",
            "                    if answers == [] :\n",
            "                        return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "                    tempresults[\"rdata\"] = struct.pack(\"!I\", ipstr2int(response[\"data\"]))\n",
            "                elif response[\"type\"] == 2 or response[\"type\"] == 5:\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"].split(\".\"))\n",
            "                elif response[\"type\"] == 16 :\n",
            "                    tempresults[\"rdata\"] = labels2str(response[\"data\"])\n",
            "                elif response[\"type\"] == 15 :\n",
            "                    tempresult = struct.pack(\"!H\", response[\"data\"][0])\n",
            "                    tempresult += labels2str(response[\"data\"][1].split(\".\"))\n",
            "                    tempresults[\"rdata\"] = tempresult\n",
            "                elif response[\"type\"] == 28 :\n",
            "                    if answers == [] :\n",
            "                        return self.get_response(query, domain, 5, qclass, src_addr)\n",
            "                    #tempresults[\"rdata\"] = struct.pack(\"!I\", ipstr2int(response[\"data\"]))\n",
            "                    tempresults[\"rdata\"] = response[\"data\"]\n",
            "                elif response[\"type\"] == 52 :\n",
            "                    tempresults[\"rdata\"] = response[\"data\"]\n",
            "                #else : return 3, []\n",
            "                results.append(tempresults)\n",
            "            return 0, results\n",
            "        return 3, []\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = \"train-00000-of-00206.parquet\"\n",
        "\n",
        "df = pd.read_parquet(file_path, engine = \"fastparquet\")\n",
        "\n",
        "first_entry_code = df.iloc[0][\"content\"]\n",
        "second_entry_code = df.iloc[100][\"content\"]\n",
        "third_entry_code = df.iloc[1000][\"content\"]\n",
        "\n",
        "print(df)\n",
        "print(first_entry_code)\n",
        "print(second_entry_code)\n",
        "print(third_entry_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zznu8S8AjDF",
        "outputId": "67152646-3282-48a6-fc83-fc8274e5d343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# UCF Senior Design 2017-18\n",
            "# Group 38\n",
            "\n",
            "from PIL import Image\n",
            "import cv2\n",
            "import imagehash\n",
            "import math\n",
            "import numpy as np\n",
            "\n",
            "DIFF_THRES = 20\n",
            "LIMIT = 2\n",
            "RESIZE = 1000\n",
            "\n",
            "\n",
            "def calc_hash(img):\n",
            "    \"\"\"\n",
            "    Calculate the wavelet hash of the image\n",
            "        img: (ndarray) image file\n",
            "    \"\"\"\n",
            "    # resize image if height > 1000\n",
            "    img = resize(img)\n",
            "    return imagehash.whash(Image.fromarray(img))\n",
            "\n",
            "\n",
            "def compare(hash1, hash2):\n",
            "    \"\"\"\n",
            "    Calculate the difference between two images\n",
            "        hash1: (array) first wavelet hash\n",
            "        hash2: (array) second wavelet hash\n",
            "    \"\"\"\n",
            "    return hash1 - hash2\n",
            "\n",
            "\n",
            "def limit(img, std_hash, count):\n",
            "    \"\"\"\n",
            "    Determine whether image should be removed from image dictionary in main.py\n",
            "        img: (ndarray) image file\n",
            "        std_hash: (array) wavelet hash of comparison standard\n",
            "        count: (int) global count of images similar to comparison standard\n",
            "    \"\"\"\n",
            "    # calculate hash for given image\n",
            "    cmp_hash = calc_hash(img)\n",
            "\n",
            "    # compare to standard\n",
            "    diff = compare(std_hash, cmp_hash)\n",
            "\n",
            "    # image is similar to standard\n",
            "    if diff <= DIFF_THRES:\n",
            "        # if there are 3 similar images already, remove image\n",
            "        if count >= LIMIT:\n",
            "            return 'remove'\n",
            "\n",
            "    # non-similar image found\n",
            "    else:\n",
            "        # update comparison standard\n",
            "        return 'update_std'\n",
            "\n",
            "    # else continue reading images with same standard\n",
            "    return 'continue'\n",
            "\n",
            "\n",
            "def resize(img):\n",
            "    \"\"\"\n",
            "    Resize an image\n",
            "        img: (ndarray) RGB color image\n",
            "    \"\"\"\n",
            "    # get dimensions of image\n",
            "    width = np.shape(img)[1]\n",
            "    height = np.shape(img)[0]\n",
            "\n",
            "    # if height of image is greater than 1000, resize it to 1000\n",
            "    if width > RESIZE:\n",
            "        # keep resize proportional\n",
            "        scale = RESIZE / width\n",
            "        resized_img = cv2.resize(\n",
            "            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\n",
            "        # return resized image\n",
            "        return resized_img\n",
            "\n",
            "    # if height of image is less than 1000, return image unresized\n",
            "    return img\n",
            "\n",
            "\n",
            "def set_standard(images, filename):\n",
            "    \"\"\"\n",
            "    Set new comparison standard and update information\n",
            "        images: (dictionary) dictionary containing all the image data\n",
            "        filename: (String) name of the image file\n",
            "    \"\"\"\n",
            "    return filename, calc_hash(images[filename]), 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get only the code\n",
        "\n",
        "code_series = df[\"content\"].head(1000)\n",
        "print(code_series[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXvHaSwNBgIE"
      },
      "outputs": [],
      "source": [
        "# Preprocess\n",
        "\n",
        "def clean_code(code):\n",
        "    # Remove multiline docstrings \n",
        "    code = re.sub(r'\"\"\"[\\s\\S]*?\"\"\"', '', code)\n",
        "    code = re.sub(r\"'''[\\s\\S]*?'''\", '', code)\n",
        "\n",
        "    # Remove single-line comments \n",
        "    code = re.sub(r'#.*', '', code)\n",
        "\n",
        "    # Remove blank lines\n",
        "    code = re.sub(r'^\\s*\\n', '', code)\n",
        "\n",
        "    return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlXp8hYhB51I",
        "outputId": "670c599f-8dd8-4648-9ce5-d1f6e6377a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "from PIL import Image\n",
            "import cv2\n",
            "import imagehash\n",
            "import math\n",
            "import numpy as np\n",
            "\n",
            "DIFF_THRES = 20\n",
            "LIMIT = 2\n",
            "RESIZE = 1000\n",
            "\n",
            "\n",
            "def calc_hash(img):\n",
            "    \n",
            "    \n",
            "    img = resize(img)\n",
            "    return imagehash.whash(Image.fromarray(img))\n",
            "\n",
            "\n",
            "def compare(hash1, hash2):\n",
            "    \n",
            "    return hash1 - hash2\n",
            "\n",
            "\n",
            "def limit(img, std_hash, count):\n",
            "    \n",
            "    \n",
            "    cmp_hash = calc_hash(img)\n",
            "\n",
            "    \n",
            "    diff = compare(std_hash, cmp_hash)\n",
            "\n",
            "    \n",
            "    if diff <= DIFF_THRES:\n",
            "        \n",
            "        if count >= LIMIT:\n",
            "            return 'remove'\n",
            "\n",
            "    \n",
            "    else:\n",
            "        \n",
            "        return 'update_std'\n",
            "\n",
            "    \n",
            "    return 'continue'\n",
            "\n",
            "\n",
            "def resize(img):\n",
            "    \n",
            "    \n",
            "    width = np.shape(img)[1]\n",
            "    height = np.shape(img)[0]\n",
            "\n",
            "    \n",
            "    if width > RESIZE:\n",
            "        \n",
            "        scale = RESIZE / width\n",
            "        resized_img = cv2.resize(\n",
            "            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\n",
            "        \n",
            "        return resized_img\n",
            "\n",
            "    \n",
            "    return img\n",
            "\n",
            "\n",
            "def set_standard(images, filename):\n",
            "    \n",
            "    return filename, calc_hash(images[filename]), 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cleaned_data = code_series.apply(clean_code)\n",
        "\n",
        "print(cleaned_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfySHxBQESho",
        "outputId": "e1a3edcc-c8cd-44b1-d3b0-2132fcc77b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to cleaned_data.json\n"
          ]
        }
      ],
      "source": [
        "#Save as json\n",
        "cleaned_data_list = cleaned_data.tolist()\n",
        "\n",
        "formatted_data = [{\"code\": item} for item in cleaned_data_list]\n",
        "\n",
        "payload = json.dumps(formatted_data, ensure_ascii=False).encode(\"utf-8\")\n",
        "\n",
        "output_filename = \"cleaned_data.json\"\n",
        "\n",
        "with open(output_filename, \"w\") as f:\n",
        "    json.dump(formatted_data, f, indent=4)\n",
        "\n",
        "print(f\"Data saved to {output_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkfXqCaDKEI"
      },
      "source": [
        "Generate summaries for data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "atojrnWiDMtv",
        "outputId": "c1d5a900-f702-4da5-858e-78ca97bb25a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "#Check ollama\n",
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAxWz-z2DOOg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llamas primarily eat grasses and hay. They are herbivores and have a digestive system that allows them to digest cellulose, which is found in plant material. In the wild, llamas graze on grasses, leaves, and bark from trees and bushes. In captivity or when kept as pets, they are usually fed commercial llama pellets, supplemented with fresh grass and hay.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"qwen2.5-coder:7b\",\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    \n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     \n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "   \n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        \n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "\n",
        "model = \"qwen2.5-coder:7b\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uOpuMeqEQMj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSyLt2cFDj34"
      },
      "outputs": [],
      "source": [
        "def add_summaries_to_json(input_json_filename, output_json_filename):\n",
        "    with open(input_json_filename, \"r\") as infile:\n",
        "        code_data = json.load(infile)\n",
        "    \n",
        "    if not isinstance(code_data, list):\n",
        "        raise ValueError(\"Expected a list of dictionaries but got a different format.\")\n",
        "    \n",
        "    \n",
        "    id = 0\n",
        "    for entry in code_data:\n",
        "        if not isinstance(entry, dict) or \"code\" not in entry:\n",
        "            raise ValueError(f\"Invalid entry format: {entry}\")\n",
        "        \n",
        "        prompt = f\"Summarize the following Python code:\\n{entry['code']}\"\n",
        "        summary = query_model(prompt)\n",
        "        entry[\"summary\"] = summary\n",
        "        print(f\"ID: {id}\")\n",
        "        print(f\"Entry: {entry}\")\n",
        "        print(\"Summary: \" + summary)\n",
        "        print()\n",
        "        print()\n",
        "        id = id + 1\n",
        "\n",
        "   \n",
        "    with open(output_json_filename, \"w\") as outfile:\n",
        "        json.dump(code_data, outfile, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to cleaned_data_test.json\n",
            "ID: 0\n",
            "Entry: {'code': 'from   _TFL.pyk           import pyk\\n\\nfrom   rsclib.HTML_Parse  import tag, Page_Tree\\nfrom   rsclib.autosuper   import autosuper\\nfrom   spider.common      import Interface, Inet4, Inet6, unroutable\\nfrom   spider.common      import WLAN_Config\\nfrom   spider.luci        import Version_Mixin\\n\\nclass Status (Page_Tree, Version_Mixin) :\\n    url          = \\'cgi-bin/luci/freifunk/status/status\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    wl_names = dict \\\\\\n        ( ssid    = \\'ssid\\'\\n        , _bsiid  = \\'bssid\\'\\n        , channel = \\'channel\\'\\n        , mode    = \\'mode\\'\\n        )\\n\\n    def parse (self) :\\n        root  = self.tree.getroot ()\\n        self.wlans  = []\\n        self.routes = {}\\n        for div in root.findall (\".//%s\" % tag (\"div\")) :\\n            id = div.get (\\'id\\')\\n            if id == \\'cbi-wireless\\' :\\n                wlan_div = div\\n            elif id == \\'cbi-routes\\' :\\n                route_div = div\\n            self.try_get_version (div)\\n        for d in self.tbl_iter (wlan_div) :\\n            for k, newkey in pyk.iteritems (self.wl_names) :\\n                if k in d :\\n                    d [newkey] = d [k]\\n            wl = WLAN_Config (** d)\\n            self.wlans.append (wl)\\n        for d in self.tbl_iter (route_div) :\\n            iface = d.get (\\'iface\\')\\n            gw    = d.get (\\'gateway\\')\\n            if iface and gw :\\n                self.routes [iface] = gw\\n        self.set_version (root)\\n    \\n\\n    def tbl_iter (self, div) :\\n        tbl = div.find (\".//%s\" % tag (\"table\"))\\n        assert tbl.get (\\'class\\') == \\'cbi-section-table\\'\\n        d = {}\\n        for tr in tbl :\\n            if \\'cbi-section-table-row\\' not in tr.get (\\'class\\').split () :\\n                continue\\n            for input in tr.findall (\".//%s\" % tag (\\'input\\')) :\\n                name = input.get (\\'id\\').split (\\'.\\') [-1]\\n                val  = input.get (\\'value\\')\\n                d [name] = val\\n            if not d :\\n                continue\\n            yield d\\n    \\n\\n\\n\\nclass Table_Iter (Page_Tree) :\\n\\n    def table_iter (self) :\\n        root  = self.tree.getroot ()\\n        for div in root.findall (\".//%s\" % tag (\"div\")) :\\n            if div.get (\\'id\\') == \\'maincontent\\' :\\n                break\\n        tbl = div.find (\".//%s\" % tag (\"table\"))\\n        if tbl is None :\\n            return\\n        for tr in tbl :\\n            if tr [0].tag == tag (\\'th\\') :\\n                continue\\n            yield (self.tree.get_text (x) for x in tr)\\n    \\n\\n\\n\\nclass OLSR_Connections (Table_Iter) :\\n    url          = \\'cgi-bin/luci/freifunk/olsr/\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    def parse (self) :\\n        self.neighbors = {}\\n        for l in self.table_iter () :\\n            neighbor, ip, lq, nlq, etx = l\\n            lq, nlq, etx = (float (x) for x in (lq, nlq, etx))\\n            self.neighbors [neighbor] = [ip, lq, nlq, etx]\\n    \\n\\n\\n\\nclass OLSR_Routes (Table_Iter) :\\n    url          = \\'cgi-bin/luci/freifunk/olsr/routes\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    def parse (self) :\\n        self.iface_by_gw = {}\\n        for l in self.table_iter () :\\n            announced, gw, iface, metric, etx = l\\n            if gw in self.iface_by_gw :\\n                assert iface == self.iface_by_gw [gw]\\n            else :\\n                self.iface_by_gw [gw] = iface\\n    \\n\\n\\n\\nclass OpenWRT (autosuper) :\\n\\n    def __init__ (self, site, request) :\\n        self.site    = site\\n        self.request = request\\n        if \\'interfaces\\' in self.request or \\'ips\\' in self.request :\\n            st    = Status           (site = site)\\n            conn  = OLSR_Connections (site = site)\\n            route = OLSR_Routes      (site = site)\\n            self.version = st.version\\n            assert len (st.wlans) <= 1\\n            interfaces   = {}\\n            ips          = {}\\n            count = 0\\n            for gw, ifname in pyk.iteritems (route.iface_by_gw) :\\n                ip, lq, nlq, etx  = conn.neighbors [gw]\\n                i4 = Inet4 (ip, None, None, iface = ifname)\\n                ips [i4] = 1\\n                is_wlan = True\\n                if lq == nlq == etx == 1.0 :\\n                    is_wlan = False\\n                if ifname in interfaces :\\n                    iface = interfaces [ifname]\\n                    if not iface.is_wlan and is_wlan :\\n                        iface.is_wlan   = True\\n                        iface.wlan_info = st.wlans [0]\\n                else :\\n                    iface = Interface (count, ifname, None)\\n                    iface.is_wlan = is_wlan\\n                    if is_wlan :\\n                        iface.wlan_info = st.wlans [0]\\n                    count += 1\\n                    interfaces [ifname] = iface\\n                if i4 not in iface.inet4 :\\n                    iface.append_inet4 (i4)\\n            wl_if = None\\n            for iface in pyk.itervalues (interfaces) :\\n                if iface.is_wlan :\\n                    if wl_if :\\n                        m = \"Duplicate wlan: %s/%s\" % (iface.name, wl_if.name)\\n                        raise ValueError (m)\\n                    wl_if = iface\\n            \\n            n  = \\'unknown\\'\\n            i4 = Inet4 (self.request [\\'ip\\'], None, None, iface = n)\\n            if i4 not in ips :\\n                assert n not in interfaces\\n                iface = interfaces [n] = Interface (count, n, None)\\n                iface.append_inet4 (i4)\\n                iface.is_wlan = False\\n                if not wl_if and st.wlans :\\n                    iface.is_wlan   = True\\n                    iface.wlan_info = st.wlans [0]\\n                ips [i4] = True\\n\\n            self.request [\\'ips\\']        = ips\\n            self.request [\\'interfaces\\'] = interfaces\\n            self.request [\\'version\\']    = st.version\\n    \\n\\n\\n', 'summary': 'This Python code defines several classes to parse and process data from web pages related to a Freifunk network, which is a decentralized mesh networking system. The main functionalities include:\\n\\n1. **Status Class**: Parses the status page of a Freifunk node. It extracts information about wireless networks (WLANs) and routing tables. It uses `Page_Tree` for parsing HTML and `Version_Mixin` to handle versioning.\\n\\n2. **Table_Iter Class**: A base class for iterating over tables in HTML pages. It finds the main content div and iterates over table rows, extracting text data from each row.\\n\\n3. **OLSR_Connections Class**: Parses the OLSR (Optimized Link State Routing) connections page. It extracts information about network neighbors and their IP addresses along with link quality metrics.\\n\\n4. **OLSR_Routes Class**: Parses the OLSR routes page. It extracts routing table information, mapping gateways to interfaces.\\n\\n5. **OpenWRT Class**: This class integrates all the above functionalities. It initializes instances of `Status`, `OLSR_Connections`, and `OLSR_Routes` to gather data from different pages. It then processes this data to create a structured representation of network interfaces, their IP addresses, and wireless information.\\n\\nThe code uses various utilities like `pyk` for dictionary operations, `rsclib.HTML_Parse` for HTML parsing, and custom classes like `Interface`, `Inet4`, and `WLAN_Config` to represent different aspects of the network configuration. The `autosuper` decorator is used to simplify class inheritance.\\n\\nOverall, this code provides a comprehensive solution for extracting and processing network data from Freifunk nodes, which can be useful for monitoring and management purposes.'}\n",
            "Summary: This Python code defines several classes to parse and process data from web pages related to a Freifunk network, which is a decentralized mesh networking system. The main functionalities include:\n",
            "\n",
            "1. **Status Class**: Parses the status page of a Freifunk node. It extracts information about wireless networks (WLANs) and routing tables. It uses `Page_Tree` for parsing HTML and `Version_Mixin` to handle versioning.\n",
            "\n",
            "2. **Table_Iter Class**: A base class for iterating over tables in HTML pages. It finds the main content div and iterates over table rows, extracting text data from each row.\n",
            "\n",
            "3. **OLSR_Connections Class**: Parses the OLSR (Optimized Link State Routing) connections page. It extracts information about network neighbors and their IP addresses along with link quality metrics.\n",
            "\n",
            "4. **OLSR_Routes Class**: Parses the OLSR routes page. It extracts routing table information, mapping gateways to interfaces.\n",
            "\n",
            "5. **OpenWRT Class**: This class integrates all the above functionalities. It initializes instances of `Status`, `OLSR_Connections`, and `OLSR_Routes` to gather data from different pages. It then processes this data to create a structured representation of network interfaces, their IP addresses, and wireless information.\n",
            "\n",
            "The code uses various utilities like `pyk` for dictionary operations, `rsclib.HTML_Parse` for HTML parsing, and custom classes like `Interface`, `Inet4`, and `WLAN_Config` to represent different aspects of the network configuration. The `autosuper` decorator is used to simplify class inheritance.\n",
            "\n",
            "Overall, this code provides a comprehensive solution for extracting and processing network data from Freifunk nodes, which can be useful for monitoring and management purposes.\n",
            "\n",
            "\n",
            "ID: 1\n",
            "Entry: {'code': \"from PIL import Image\\nimport cv2\\nimport imagehash\\nimport math\\nimport numpy as np\\n\\nDIFF_THRES = 20\\nLIMIT = 2\\nRESIZE = 1000\\n\\n\\ndef calc_hash(img):\\n    \\n    \\n    img = resize(img)\\n    return imagehash.whash(Image.fromarray(img))\\n\\n\\ndef compare(hash1, hash2):\\n    \\n    return hash1 - hash2\\n\\n\\ndef limit(img, std_hash, count):\\n    \\n    \\n    cmp_hash = calc_hash(img)\\n\\n    \\n    diff = compare(std_hash, cmp_hash)\\n\\n    \\n    if diff <= DIFF_THRES:\\n        \\n        if count >= LIMIT:\\n            return 'remove'\\n\\n    \\n    else:\\n        \\n        return 'update_std'\\n\\n    \\n    return 'continue'\\n\\n\\ndef resize(img):\\n    \\n    \\n    width = np.shape(img)[1]\\n    height = np.shape(img)[0]\\n\\n    \\n    if width > RESIZE:\\n        \\n        scale = RESIZE / width\\n        resized_img = cv2.resize(\\n            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\\n        \\n        return resized_img\\n\\n    \\n    return img\\n\\n\\ndef set_standard(images, filename):\\n    \\n    return filename, calc_hash(images[filename]), 0\\n\", 'summary': \"This Python code is designed to process images and determine whether they should be updated or removed based on their similarity to a standard image. Here's a summary of the key components:\\n\\n1. **Imports**: The code imports necessary libraries including PIL for image processing, cv2 for computer vision tasks, imagehash for hashing images, math for mathematical operations, and numpy for numerical computations.\\n\\n2. **Constants**:\\n   - `DIFF_THRES`: A threshold value (20) used to compare the difference between hashes.\\n   - `LIMIT`: A limit on how many times an image can be updated before it is removed (2).\\n   - `RESIZE`: The maximum width of images after resizing (1000 pixels).\\n\\n3. **Functions**:\\n   - **`calc_hash(img)`**: Resizes the image and calculates its hash using the Wavelet Hashing method.\\n   - **`compare(hash1, hash2)`**: Compares two hashes by subtracting one from the other.\\n   - **`limit(img, std_hash, count)`**: Determines whether to update the standard image, remove it, or continue processing based on the difference between the current image's hash and the standard hash. It also checks if the image has been updated too many times.\\n   - **`resize(img)`**: Resizes an image to a maximum width of 1000 pixels while maintaining the aspect ratio.\\n   - **`set_standard(images, filename)`**: Sets up the standard image by calculating its hash and initializing a count.\\n\\n4. **Usage**:\\n   - The code is intended to be used in a larger system where images are processed and compared against a standard image. It helps in managing image versions and deciding whether to keep or remove them based on their similarity.\\n\\nThis code provides a basic framework for image version control and can be extended with additional functionality such as handling multiple images, saving the state of images, and integrating with other systems for image management.\"}\n",
            "Summary: This Python code is designed to process images and determine whether they should be updated or removed based on their similarity to a standard image. Here's a summary of the key components:\n",
            "\n",
            "1. **Imports**: The code imports necessary libraries including PIL for image processing, cv2 for computer vision tasks, imagehash for hashing images, math for mathematical operations, and numpy for numerical computations.\n",
            "\n",
            "2. **Constants**:\n",
            "   - `DIFF_THRES`: A threshold value (20) used to compare the difference between hashes.\n",
            "   - `LIMIT`: A limit on how many times an image can be updated before it is removed (2).\n",
            "   - `RESIZE`: The maximum width of images after resizing (1000 pixels).\n",
            "\n",
            "3. **Functions**:\n",
            "   - **`calc_hash(img)`**: Resizes the image and calculates its hash using the Wavelet Hashing method.\n",
            "   - **`compare(hash1, hash2)`**: Compares two hashes by subtracting one from the other.\n",
            "   - **`limit(img, std_hash, count)`**: Determines whether to update the standard image, remove it, or continue processing based on the difference between the current image's hash and the standard hash. It also checks if the image has been updated too many times.\n",
            "   - **`resize(img)`**: Resizes an image to a maximum width of 1000 pixels while maintaining the aspect ratio.\n",
            "   - **`set_standard(images, filename)`**: Sets up the standard image by calculating its hash and initializing a count.\n",
            "\n",
            "4. **Usage**:\n",
            "   - The code is intended to be used in a larger system where images are processed and compared against a standard image. It helps in managing image versions and deciding whether to keep or remove them based on their similarity.\n",
            "\n",
            "This code provides a basic framework for image version control and can be extended with additional functionality such as handling multiple images, saving the state of images, and integrating with other systems for image management.\n",
            "\n",
            "\n",
            "ID: 2\n",
            "Entry: {'code': \"from .cli.cli import main\\n\\n\\n\\n\\n\\nif __name__ == '__main__':\\n    main()\\n\", 'summary': 'This Python script is designed to run a command-line interface (CLI) application. Here\\'s a breakdown of what it does:\\n\\n1. **Import Statement**:\\n   ```python\\n   from .cli.cli import main\\n   ```\\n   This line imports the `main` function from the `cli.py` module located in the `cli` subdirectory relative to the current script.\\n\\n2. **Main Guard**:\\n   ```python\\n   if __name__ == \\'__main__\\':\\n       main()\\n   ```\\n   This is a common Python idiom known as the \"main guard\" or \"entry point\". It checks whether the script is being run directly (i.e., not imported as a module in another script). If it is being run directly, it calls the `main` function.\\n\\n### Summary\\n- The script imports a `main` function from a subdirectory.\\n- It includes a guard to ensure that the `main` function is only called when the script is executed directly, not when imported as a module.'}\n",
            "Summary: This Python script is designed to run a command-line interface (CLI) application. Here's a breakdown of what it does:\n",
            "\n",
            "1. **Import Statement**:\n",
            "   ```python\n",
            "   from .cli.cli import main\n",
            "   ```\n",
            "   This line imports the `main` function from the `cli.py` module located in the `cli` subdirectory relative to the current script.\n",
            "\n",
            "2. **Main Guard**:\n",
            "   ```python\n",
            "   if __name__ == '__main__':\n",
            "       main()\n",
            "   ```\n",
            "   This is a common Python idiom known as the \"main guard\" or \"entry point\". It checks whether the script is being run directly (i.e., not imported as a module in another script). If it is being run directly, it calls the `main` function.\n",
            "\n",
            "### Summary\n",
            "- The script imports a `main` function from a subdirectory.\n",
            "- It includes a guard to ensure that the `main` function is only called when the script is executed directly, not when imported as a module.\n",
            "\n",
            "\n",
            "ID: 3\n",
            "Entry: {'code': 'import time\\n\\nfrom PyQt5 import QtGui, QtCore\\n\\nfrom ui.room_item import Ui_Form\\nfrom PyQt5.QtWidgets import QWidget\\n\\nclass Room_Item(QWidget,Ui_Form):\\n    def __init__(self,parent=None,room_data=None):\\n        super(Room_Item,self).__init__(parent)\\n        self.setupUi(self)\\n        self.data = room_data\\n        self.setRoomInfo()\\n\\n    def setRoomInfo(self):\\n        self.room_name.setText(\\'{}({})\\'.format(self.data[\\'naturalName\\'], self.data[\\'roomName\\']))\\n        self.description.setText(\"<a style=\\'color:\\n        timeStamp = int(self.data[\\'creationDate\\']) / 1000\\n        timeArray = time.localtime(timeStamp)\\n        otherStyleTime = time.strftime(\"%Y-%m-%d\", timeArray)\\n        self.create_time.setText(\"<a style=\\'color:\\n        members = len(self.data[\\'owners\\']) + len(self.data[\\'admins\\']) + len(self.data[\\'members\\'])\\n        memberCounter = \"<a style=\\'color:\\n        self.member.setText(memberCounter)', 'summary': \"This Python code defines a class `Room_Item` that inherits from both `QWidget` and `Ui_Form`. The class is designed to display information about a room in a graphical user interface (GUI). Here's a summary of the key components:\\n\\n1. **Imports**:\\n   - The code imports necessary modules, including `time`, `PyQt5.QtGui`, `PyQt5.QtCore`, and custom UI elements from `ui.room_item`.\\n\\n2. **Class Definition**:\\n   - `Room_Item` is a subclass of `QWidget` and `Ui_Form`. This allows it to use both the widget functionality and the UI layout defined in `Ui_Form`.\\n\\n3. **Constructor (`__init__`)**:\\n   - The constructor initializes the `Room_Item` object.\\n   - It calls the superclass constructors using `super(Room_Item, self).__init__(parent)`.\\n   - It sets up the user interface by calling `self.setupUi(self)`.\\n   - It stores the room data passed as an argument and calls `self.setRoomInfo()` to populate the UI with this data.\\n\\n4. **Method (`setRoomInfo`)**:\\n   - This method updates the UI elements based on the room data.\\n   - It sets the text of a label (`room_name`) to display both the natural name and the room name of the room.\\n   - It converts a timestamp (presumably in milliseconds) from the room data into a human-readable date format and displays it.\\n   - It calculates the total number of members (owners, admins, and regular members) and updates another label (`member`) with this count.\\n\\nThe code is structured to be used within a PyQt5 application, where `Room_Item` would typically be instantiated and added to a layout in a main window or dialog.\"}\n",
            "Summary: This Python code defines a class `Room_Item` that inherits from both `QWidget` and `Ui_Form`. The class is designed to display information about a room in a graphical user interface (GUI). Here's a summary of the key components:\n",
            "\n",
            "1. **Imports**:\n",
            "   - The code imports necessary modules, including `time`, `PyQt5.QtGui`, `PyQt5.QtCore`, and custom UI elements from `ui.room_item`.\n",
            "\n",
            "2. **Class Definition**:\n",
            "   - `Room_Item` is a subclass of `QWidget` and `Ui_Form`. This allows it to use both the widget functionality and the UI layout defined in `Ui_Form`.\n",
            "\n",
            "3. **Constructor (`__init__`)**:\n",
            "   - The constructor initializes the `Room_Item` object.\n",
            "   - It calls the superclass constructors using `super(Room_Item, self).__init__(parent)`.\n",
            "   - It sets up the user interface by calling `self.setupUi(self)`.\n",
            "   - It stores the room data passed as an argument and calls `self.setRoomInfo()` to populate the UI with this data.\n",
            "\n",
            "4. **Method (`setRoomInfo`)**:\n",
            "   - This method updates the UI elements based on the room data.\n",
            "   - It sets the text of a label (`room_name`) to display both the natural name and the room name of the room.\n",
            "   - It converts a timestamp (presumably in milliseconds) from the room data into a human-readable date format and displays it.\n",
            "   - It calculates the total number of members (owners, admins, and regular members) and updates another label (`member`) with this count.\n",
            "\n",
            "The code is structured to be used within a PyQt5 application, where `Room_Item` would typically be instantiated and added to a layout in a main window or dialog.\n",
            "\n",
            "\n",
            "ID: 4\n",
            "Entry: {'code': 'import asyncio\\nimport re\\nimport sys\\nimport traceback\\n\\nimport toga\\nfrom toga import Key\\nfrom .keys import toga_to_winforms_key\\n\\nfrom .libs import Threading, WinForms, shcore, user32, win_version\\nfrom .libs.proactor import WinformsProactorEventLoop\\nfrom .window import Window\\n\\n\\nclass MainWindow(Window):\\n    def winforms_FormClosing(self, sender, event):\\n        if not self.interface.app._impl._is_exiting:\\n            event.Cancel = not self.interface.app.exit()\\n\\n\\nclass App:\\n    _MAIN_WINDOW_CLASS = MainWindow\\n\\n    def __init__(self, interface):\\n        self.interface = interface\\n        self.interface._impl = self\\n\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        self._is_exiting = False\\n\\n        self.loop = WinformsProactorEventLoop()\\n        asyncio.set_event_loop(self.loop)\\n\\n    def create(self):\\n        self.native = WinForms.Application\\n        self.app_context = WinForms.ApplicationContext()\\n\\n        \\n        \\n        \\n        \\n        if win_version.Major >= 6:  \\n            \\n            \\n            if ((win_version.Major == 6 and win_version.Minor == 3) or\\n                    (win_version.Major == 10 and win_version.Build < 15063)):\\n                shcore.SetProcessDpiAwareness(True)\\n            \\n            \\n            elif win_version.Major == 10 and win_version.Build >= 15063:\\n                user32.SetProcessDpiAwarenessContext(-2)\\n            \\n            else:\\n                user32.SetProcessDPIAware()\\n\\n        self.native.EnableVisualStyles()\\n        self.native.SetCompatibleTextRenderingDefault(False)\\n\\n        self.interface.commands.add(\\n            toga.Command(\\n                lambda _: self.interface.about(),\\n                \\'About {}\\'.format(self.interface.name),\\n                group=toga.Group.HELP\\n            ),\\n            toga.Command(None, \\'Preferences\\', group=toga.Group.FILE),\\n            \\n            toga.Command(\\n                lambda _: self.interface.exit(),\\n                \\'Exit \\' + self.interface.name,\\n                shortcut=Key.MOD_1 + \\'q\\',\\n                group=toga.Group.FILE,\\n                section=sys.maxsize\\n            ),\\n            toga.Command(\\n                lambda _: self.interface.visit_homepage(),\\n                \\'Visit homepage\\',\\n                enabled=self.interface.home_page is not None,\\n                group=toga.Group.HELP\\n            )\\n        )\\n        self._create_app_commands()\\n\\n        \\n        self.interface.startup()\\n        self.create_menus()\\n        self.interface.icon.bind(self.interface.factory)\\n        self.interface.main_window._impl.set_app(self)\\n\\n    def create_menus(self):\\n        self._menu_items = {}\\n        self._menu_groups = {}\\n\\n        toga.Group.FILE.order = 0\\n        menubar = WinForms.MenuStrip()\\n        submenu = None\\n        for cmd in self.interface.commands:\\n            if cmd == toga.GROUP_BREAK:\\n                submenu = None\\n            elif cmd == toga.SECTION_BREAK:\\n                submenu.DropDownItems.Add(\\'-\\')\\n            else:\\n                submenu = self._submenu(cmd.group, menubar)\\n\\n                item = WinForms.ToolStripMenuItem(cmd.label)\\n\\n                if cmd.action:\\n                    item.Click += cmd._impl.as_handler()\\n                item.Enabled = cmd.enabled\\n\\n                if cmd.shortcut is not None:\\n                    shortcut_keys = toga_to_winforms_key(cmd.shortcut)\\n                    item.ShortcutKeys = shortcut_keys\\n                    item.ShowShortcutKeys = True\\n\\n                cmd._impl.native.append(item)\\n\\n                self._menu_items[item] = cmd\\n                submenu.DropDownItems.Add(item)\\n\\n        self.interface.main_window._impl.native.Controls.Add(menubar)\\n        self.interface.main_window._impl.native.MainMenuStrip = menubar\\n        self.interface.main_window.content.refresh()\\n\\n    def _submenu(self, group, menubar):\\n        try:\\n            return self._menu_groups[group]\\n        except KeyError:\\n            if group is None:\\n                submenu = menubar\\n            else:\\n                parent_menu = self._submenu(group.parent, menubar)\\n\\n                submenu = WinForms.ToolStripMenuItem(group.label)\\n\\n                \\n                if group.parent is None:\\n                    parent_menu.Items.Add(submenu)\\n                else:\\n                    parent_menu.DropDownItems.Add(submenu)\\n\\n            self._menu_groups[group] = submenu\\n        return submenu\\n\\n    def _create_app_commands(self):\\n        \\n        pass\\n\\n    def open_document(self, fileURL):\\n        \\n        print(\"STUB: If you want to handle opening documents, implement App.open_document(fileURL)\")\\n\\n    def winforms_thread_exception(self, sender, winforms_exc):\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        print(\"Traceback (most recent call last):\")\\n        py_exc = winforms_exc.get_Exception()\\n        full_stack_trace = py_exc.StackTrace\\n        regex = re.compile(\\n            r\"^\\\\[(?:\\'(.*?)\\', )*(?:\\'(.*?)\\')\\\\]   (?:.*?) Python\\\\.Runtime\",\\n            re.DOTALL | re.UNICODE\\n        )\\n\\n        stacktrace_relevant_lines = regex.findall(full_stack_trace)\\n        if len(stacktrace_relevant_lines) == 0:\\n            self.print_stack_trace(full_stack_trace)\\n        else:\\n            for lines in stacktrace_relevant_lines:\\n                for line in lines:\\n                    self.print_stack_trace(line)\\n        print(py_exc.Message)\\n\\n    @classmethod\\n    def print_stack_trace(cls, stack_trace_line):\\n        for level in stack_trace_line.split(\"\\', \\'\"):\\n            for line in level.split(\"\\\\\\\\n\"):\\n                if line:\\n                    print(line)\\n\\n    def run_app(self):\\n        try:\\n            self.create()\\n\\n            self.native.ThreadException += self.winforms_thread_exception\\n\\n            self.loop.run_forever(self.app_context)\\n        except:  \\n            traceback.print_exc()\\n\\n    def main_loop(self):\\n        thread = Threading.Thread(Threading.ThreadStart(self.run_app))\\n        thread.SetApartmentState(Threading.ApartmentState.STA)\\n        thread.Start()\\n        thread.Join()\\n\\n    def show_about_dialog(self):\\n        message_parts = []\\n        if self.interface.name is not None:\\n            if self.interface.version is not None:\\n                message_parts.append(\\n                    \"{name} v{version}\".format(\\n                        name=self.interface.name,\\n                        version=self.interface.version,\\n                    )\\n                )\\n            else:\\n                message_parts.append(\\n                    \"{name}\".format(name=self.interface.name)\\n                )\\n        elif self.interface.version is not None:\\n            message_parts.append(\\n                \"v{version}\".format(version=self.interface.version)\\n            )\\n\\n        if self.interface.author is not None:\\n            message_parts.append(\\n                \"Author: {author}\".format(author=self.interface.author)\\n            )\\n        if self.interface.description is not None:\\n            message_parts.append(\\n                \"\\\\n{description}\".format(\\n                    description=self.interface.description\\n                )\\n            )\\n        self.interface.main_window.info_dialog(\\n            \\'About {}\\'.format(self.interface.name), \"\\\\n\".join(message_parts)\\n        )\\n\\n    def exit(self):\\n        self._is_exiting = True\\n        self.native.Exit()\\n\\n    def set_main_window(self, window):\\n        self.app_context.MainForm = window._impl.native\\n\\n    def set_on_exit(self, value):\\n        pass\\n\\n    def current_window(self):\\n        self.interface.factory.not_implemented(\\'App.current_window()\\')\\n\\n    def enter_full_screen(self, windows):\\n        self.interface.factory.not_implemented(\\'App.enter_full_screen()\\')\\n\\n    def exit_full_screen(self, windows):\\n        self.interface.factory.not_implemented(\\'App.exit_full_screen()\\')\\n\\n    def set_cursor(self, value):\\n        self.interface.factory.not_implemented(\\'App.set_cursor()\\')\\n\\n    def show_cursor(self):\\n        self.interface.factory.not_implemented(\\'App.show_cursor()\\')\\n\\n    def hide_cursor(self):\\n        self.interface.factory.not_implemented(\\'App.hide_cursor()\\')\\n\\n    def add_background_task(self, handler):\\n        self.loop.call_soon(handler, self)\\n\\n\\nclass DocumentApp(App):\\n    def _create_app_commands(self):\\n        self.interface.commands.add(\\n            toga.Command(\\n                lambda w: self.open_file,\\n                label=\\'Open...\\',\\n                shortcut=Key.MOD_1 + \\'o\\',\\n                group=toga.Group.FILE,\\n                section=0\\n            ),\\n        )\\n\\n    def open_document(self, fileURL):\\n        \\n        self.interface.factory.not_implemented(\\'DocumentApp.open_document()\\')\\n', 'summary': 'This Python code defines a class `App` that represents the main application logic for a Toga-based GUI application running on Windows using WinForms. The class includes methods to create and manage the application window, handle commands, create menus, and manage the event loop.\\n\\nKey functionalities include:\\n- Initializing the application with an interface.\\n- Creating the main window and setting up the event loop.\\n- Handling menu creation and command execution.\\n- Managing document opening.\\n- Running the application in a separate thread to avoid blocking the UI.\\n- Providing methods for showing about dialogs, exiting the application, and managing cursor visibility.\\n\\nThe `DocumentApp` class extends `App` and adds specific functionality for handling documents, including an \"Open...\" menu item.'}\n",
            "Summary: This Python code defines a class `App` that represents the main application logic for a Toga-based GUI application running on Windows using WinForms. The class includes methods to create and manage the application window, handle commands, create menus, and manage the event loop.\n",
            "\n",
            "Key functionalities include:\n",
            "- Initializing the application with an interface.\n",
            "- Creating the main window and setting up the event loop.\n",
            "- Handling menu creation and command execution.\n",
            "- Managing document opening.\n",
            "- Running the application in a separate thread to avoid blocking the UI.\n",
            "- Providing methods for showing about dialogs, exiting the application, and managing cursor visibility.\n",
            "\n",
            "The `DocumentApp` class extends `App` and adds specific functionality for handling documents, including an \"Open...\" menu item.\n",
            "\n",
            "\n",
            "ID: 5\n",
            "Entry: {'code': '__version__ = \"0.4.0\"\\n\\n\\ndef classFactory(iface):  \\n    \\n    \\n    from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner\\n    return SimplePhotogrammetryRoutePlanner(iface)\\n', 'summary': 'This Python code defines a module with a version number and a function to create an instance of a specific class. Here\\'s a summary:\\n\\n1. **Version Information**:\\n   - The `__version__` variable is set to `\"0.4.0\"`, indicating the version of this module.\\n\\n2. **Class Factory Function**:\\n   - The `classFactory` function takes one parameter, `iface`.\\n   - Inside the function, it imports a class named `SimplePhotogrammetryRoutePlanner` from a relative module (`from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner`).\\n   - It then returns an instance of `SimplePhotogrammetryRoutePlanner`, passing the `iface` parameter to its constructor.\\n\\n### Purpose\\nThis code is likely part of a larger system where different route planning algorithms or tools are dynamically loaded and instantiated based on some configuration or interface. The `classFactory` function serves as a factory method to create instances of the `SimplePhotogrammetryRoutePlanner` class, which presumably implements specific functionality for photogrammetry-based route planning.\\n\\n### Usage\\nTo use this code:\\n1. Ensure that the relative module (`SimplePhotogrammetryRoutePlanner.py`) is in the same directory or correctly referenced.\\n2. Call the `classFactory` function with an appropriate `iface` parameter to create an instance of `SimplePhotogrammetryRoutePlanner`.\\n\\nExample usage:\\n```python\\nfrom . import classFactory\\n\\n# Assuming \\'iface\\' is already defined and suitable for the route planner\\nroute_planner = classFactory(iface)\\n```\\n\\nThis would create an instance of `SimplePhotogrammetryRoutePlanner` with the provided `iface`.'}\n",
            "Summary: This Python code defines a module with a version number and a function to create an instance of a specific class. Here's a summary:\n",
            "\n",
            "1. **Version Information**:\n",
            "   - The `__version__` variable is set to `\"0.4.0\"`, indicating the version of this module.\n",
            "\n",
            "2. **Class Factory Function**:\n",
            "   - The `classFactory` function takes one parameter, `iface`.\n",
            "   - Inside the function, it imports a class named `SimplePhotogrammetryRoutePlanner` from a relative module (`from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner`).\n",
            "   - It then returns an instance of `SimplePhotogrammetryRoutePlanner`, passing the `iface` parameter to its constructor.\n",
            "\n",
            "### Purpose\n",
            "This code is likely part of a larger system where different route planning algorithms or tools are dynamically loaded and instantiated based on some configuration or interface. The `classFactory` function serves as a factory method to create instances of the `SimplePhotogrammetryRoutePlanner` class, which presumably implements specific functionality for photogrammetry-based route planning.\n",
            "\n",
            "### Usage\n",
            "To use this code:\n",
            "1. Ensure that the relative module (`SimplePhotogrammetryRoutePlanner.py`) is in the same directory or correctly referenced.\n",
            "2. Call the `classFactory` function with an appropriate `iface` parameter to create an instance of `SimplePhotogrammetryRoutePlanner`.\n",
            "\n",
            "Example usage:\n",
            "```python\n",
            "from . import classFactory\n",
            "\n",
            "# Assuming 'iface' is already defined and suitable for the route planner\n",
            "route_planner = classFactory(iface)\n",
            "```\n",
            "\n",
            "This would create an instance of `SimplePhotogrammetryRoutePlanner` with the provided `iface`.\n",
            "\n",
            "\n",
            "ID: 6\n",
            "Entry: {'code': 'from sklearn.feature_selection import VarianceThreshold\\nimport numpy as np\\n\\nnp.random.seed(1)\\nX = np.random.randn(100, 10)\\nX = np.hstack([X, np.zeros([100, 5])])\\n\\n\\n\\ndef featureSelection_variance(X, thrd):\\n    sel = VarianceThreshold(threshold=thrd)\\n    X_selected = sel.fit_transform(X)\\n    mask = sel.get_support()\\n    return X_selected, mask\\n\\n\\nX = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\\nselector = VarianceThreshold()\\nselector.fit_transform(X)\\nselector.variances_\\n', 'summary': \"The provided Python code demonstrates how to use the `VarianceThreshold` class from the `sklearn.feature_selection` module for feature selection based on variance. Here's a summary of the code:\\n\\n1. **Importing Libraries**:\\n   - The code imports `VarianceThreshold` from `sklearn.feature_selection` and `numpy` as `np`.\\n\\n2. **Setting Random Seed and Creating Data**:\\n   - A random seed is set to 1 for reproducibility.\\n   - A matrix `X` of shape (100, 10) is created with normally distributed random numbers.\\n   - Additional columns of zeros are appended to `X`, making it a total of 15 columns.\\n\\n3. **Defining the Feature Selection Function**:\\n   - The function `featureSelection_variance` takes two parameters: `X` (the data matrix) and `thrd` (the threshold for variance).\\n   - It creates an instance of `VarianceThreshold` with the specified threshold.\\n   - The function fits the selector to `X` and transforms it, selecting features based on their variance being greater than or equal to the threshold.\\n   - It returns the transformed data matrix `X_selected` and a boolean mask indicating which features were selected.\\n\\n4. **Example Usage of Feature Selection Function**:\\n   - A small example dataset `X` is defined with three rows and four columns.\\n   - An instance of `VarianceThreshold` is created without specifying a threshold, so it uses the default threshold (0).\\n   - The function `fit_transform` is called on this selector with the example data, which selects features based on their variance.\\n   - The variances of all features in the dataset are printed.\\n\\nIn summary, the code provides a basic implementation of feature selection using variance as a criterion. It includes both a general-purpose function for applying variance thresholding to any dataset and an example demonstrating its use with a small dataset.\"}\n",
            "Summary: The provided Python code demonstrates how to use the `VarianceThreshold` class from the `sklearn.feature_selection` module for feature selection based on variance. Here's a summary of the code:\n",
            "\n",
            "1. **Importing Libraries**:\n",
            "   - The code imports `VarianceThreshold` from `sklearn.feature_selection` and `numpy` as `np`.\n",
            "\n",
            "2. **Setting Random Seed and Creating Data**:\n",
            "   - A random seed is set to 1 for reproducibility.\n",
            "   - A matrix `X` of shape (100, 10) is created with normally distributed random numbers.\n",
            "   - Additional columns of zeros are appended to `X`, making it a total of 15 columns.\n",
            "\n",
            "3. **Defining the Feature Selection Function**:\n",
            "   - The function `featureSelection_variance` takes two parameters: `X` (the data matrix) and `thrd` (the threshold for variance).\n",
            "   - It creates an instance of `VarianceThreshold` with the specified threshold.\n",
            "   - The function fits the selector to `X` and transforms it, selecting features based on their variance being greater than or equal to the threshold.\n",
            "   - It returns the transformed data matrix `X_selected` and a boolean mask indicating which features were selected.\n",
            "\n",
            "4. **Example Usage of Feature Selection Function**:\n",
            "   - A small example dataset `X` is defined with three rows and four columns.\n",
            "   - An instance of `VarianceThreshold` is created without specifying a threshold, so it uses the default threshold (0).\n",
            "   - The function `fit_transform` is called on this selector with the example data, which selects features based on their variance.\n",
            "   - The variances of all features in the dataset are printed.\n",
            "\n",
            "In summary, the code provides a basic implementation of feature selection using variance as a criterion. It includes both a general-purpose function for applying variance thresholding to any dataset and an example demonstrating its use with a small dataset.\n",
            "\n",
            "\n",
            "ID: 7\n",
            "Entry: {'code': \"from my_multi_main3 import main\\nimport numpy as np\\nimport argparse\\nimport time\\n\\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\\n                    help='input batch size for training (default: 64)')\\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\\n                    help='input batch size for testing (default: 1000)')\\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\\n                    help='number of epochs to train (default: 10)')\\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\\n                    help='learning rate (default: 0.01)')\\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\\n                    help='SGD momentum (default: 0.5)')\\nparser.add_argument('--no-cuda', action='store_true', default=False,\\n                    help='disables CUDA training')\\nparser.add_argument('--seed', type=int, default=1, metavar='S',\\n                    help='random seed (default: 1)')\\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\\n                    help='how many batches to wait before logging training status')\\nparser.add_argument('--save-model', action='store_true', default=False,\\n                    help='For Saving the current Model')\\nparser.add_argument('--norm-flag', type=bool, default=False,\\n                    help='Triggering the Layer Normalization flag for attention scores')\\nparser.add_argument('--gamma', type=float, default=None,\\n                    help='Controlling the sparisty of gfusedmax/sparsemax, the smaller, the more sparse')\\nparser.add_argument('--lam', type=float, default=1.0,\\n                    help='Lambda: Controlling the smoothness of gfusedmax, the larger, the smoother')\\nparser.add_argument('--max-type', type=str, default='softmax',choices=['softmax','sparsemax','gfusedmax'],\\n                    help='mapping function in attention')\\nparser.add_argument('--optim-type', type=str, default='SGD',choices=['SGD','Adam'],\\n                    help='mapping function in attention')\\nparser.add_argument('--head-cnt', type=int, default=2, metavar='S', choices=[1,2,4,5,10],\\n                    help='Number of heads for attention (default: 1)')\\n\\nargs = parser.parse_args()\\n\\nhyperparameter_choices = {\\n    'lr':list(10**np.arange(-4,-1,0.5)),\\n    'norm_flag': [True,False],\\n    'gamma':list(10**np.arange(-1,3,0.5))+[None,],\\n    'lam':list(10**np.arange(-2,2,0.5)),\\n    'max_type':['softmax','sparsemax','gfusedmax'],\\n    \\n    'optim_type':['SGD','Adam'],\\n    'head_cnt':[1,2,4,5,10,20]\\n}\\n\\nparam_num = 25\\nrecord = np.zeros([param_num,len(hyperparameter_choices)+1])\\nrecord_name = 'record3_multi_%s.csv'%time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime())\\nfor n in range(param_num):\\n    for param_index,(k,v) in enumerate(hyperparameter_choices.items()):\\n        print(param_index,k)\\n        value_index = np.random.choice(len(v))\\n        if isinstance(v[value_index],str) or isinstance(v[value_index],bool) or v[value_index] is None:\\n            record[n,param_index] = value_index\\n        else:\\n            record[n,param_index] = v[value_index]\\n        setattr(args,k,v[value_index])\\n    record[n,-1] = main(args)\\n    np.savetxt(record_name, record, delimiter=',')\\n\\n\\n\\n\", 'summary': \"This Python script is designed to perform hyperparameter tuning for a machine learning model using the MNIST dataset. Here's a summary of its functionality:\\n\\n1. **Argument Parsing**: The script uses `argparse` to define and parse command-line arguments that control various aspects of the training process, such as batch size, number of epochs, learning rate, etc.\\n\\n2. **Hyperparameter Choices**: A dictionary named `hyperparameter_choices` is defined, containing lists of possible values for each hyperparameter. These include learning rates, normalization flags, sparsity controls, optimization types, and more.\\n\\n3. **Record Initialization**: An array `record` is initialized to store the results of different hyperparameter combinations along with their corresponding performance metrics.\\n\\n4. **Hyperparameter Sampling**: The script iterates over a specified number of trials (`param_num`). For each trial:\\n   - It randomly selects a value for each hyperparameter from its respective list.\\n   - These values are stored in the `record` array.\\n   - The selected hyperparameters are applied to the `args` object, which is used to configure the model and training process.\\n\\n5. **Model Training**: For each set of hyperparameters, the script calls the `main` function from `my_multi_main3.py`, passing the configured `args` object. This function likely handles the actual training of the model using the specified hyperparameters.\\n\\n6. **Performance Recording**: The performance metric (likely accuracy or loss) returned by the `main` function is recorded in the `record` array along with the corresponding hyperparameter values.\\n\\n7. **Saving Results**: After all trials are completed, the script saves the entire `record` array to a CSV file named according to the current date and time. This allows for later analysis of which hyperparameter combinations performed best.\\n\\nOverall, this script automates the process of exploring different sets of hyperparameters to find the optimal configuration for training a machine learning model on the MNIST dataset.\"}\n",
            "Summary: This Python script is designed to perform hyperparameter tuning for a machine learning model using the MNIST dataset. Here's a summary of its functionality:\n",
            "\n",
            "1. **Argument Parsing**: The script uses `argparse` to define and parse command-line arguments that control various aspects of the training process, such as batch size, number of epochs, learning rate, etc.\n",
            "\n",
            "2. **Hyperparameter Choices**: A dictionary named `hyperparameter_choices` is defined, containing lists of possible values for each hyperparameter. These include learning rates, normalization flags, sparsity controls, optimization types, and more.\n",
            "\n",
            "3. **Record Initialization**: An array `record` is initialized to store the results of different hyperparameter combinations along with their corresponding performance metrics.\n",
            "\n",
            "4. **Hyperparameter Sampling**: The script iterates over a specified number of trials (`param_num`). For each trial:\n",
            "   - It randomly selects a value for each hyperparameter from its respective list.\n",
            "   - These values are stored in the `record` array.\n",
            "   - The selected hyperparameters are applied to the `args` object, which is used to configure the model and training process.\n",
            "\n",
            "5. **Model Training**: For each set of hyperparameters, the script calls the `main` function from `my_multi_main3.py`, passing the configured `args` object. This function likely handles the actual training of the model using the specified hyperparameters.\n",
            "\n",
            "6. **Performance Recording**: The performance metric (likely accuracy or loss) returned by the `main` function is recorded in the `record` array along with the corresponding hyperparameter values.\n",
            "\n",
            "7. **Saving Results**: After all trials are completed, the script saves the entire `record` array to a CSV file named according to the current date and time. This allows for later analysis of which hyperparameter combinations performed best.\n",
            "\n",
            "Overall, this script automates the process of exploring different sets of hyperparameters to find the optimal configuration for training a machine learning model on the MNIST dataset.\n",
            "\n",
            "\n",
            "ID: 8\n",
            "Entry: {'code': 'from __future__ import print_function, absolute_import\\n\\nimport h5py\\n\\nfrom spiker import log\\n\\nlogger = log.get_logger(\"data-hdf5\", log.DEBUG)\\n\\n\\ndef init_hdf5(file_path, mode=\"w\", cam_type=\"davis\"):\\n    \\n    if mode == \"w\":\\n        dataset = h5py.File(file_path, mode=mode)\\n        dataset.create_group(\"dvs\")\\n        dataset.create_group(\"extra\")\\n        if cam_type == \"davis\":\\n            dataset.create_group(\"aps\")\\n            dataset.create_group(\"imu\")\\n    elif mode == \"r\":\\n        dataset = h5py.File(file_path, mode=mode)\\n\\n    return dataset\\n', 'summary': 'This Python code defines a function `init_hdf5` that initializes an HDF5 file for storing data. The function takes three parameters: `file_path`, `mode`, and `cam_type`. \\n\\n- `file_path`: The path to the HDF5 file.\\n- `mode`: The mode in which the file is opened, either \"w\" (write mode) or \"r\" (read mode).\\n- `cam_type`: A string indicating the type of camera, defaulting to \"davis\".\\n\\nThe function uses the `h5py` library to handle HDF5 files. It also imports a logger from the `spiker.log` module.\\n\\nHere\\'s what happens in the function:\\n\\n1. If the mode is \"w\" (write mode):\\n   - The function opens an HDF5 file at the specified path.\\n   - It creates three groups: \"dvs\", \"extra\", and \"aps\" if the camera type is \"davis\".\\n   - It also creates another group called \"imu\".\\n\\n2. If the mode is \"r\" (read mode):\\n   - The function opens an HDF5 file at the specified path in read mode.\\n\\nThe function returns the dataset object, which can be used to interact with the HDF5 file.\\n\\nThis setup is typically used for storing data from a camera system, where different types of data (like DVS events, extra information, and sensor data) are organized into separate groups within the HDF5 file.'}\n",
            "Summary: This Python code defines a function `init_hdf5` that initializes an HDF5 file for storing data. The function takes three parameters: `file_path`, `mode`, and `cam_type`. \n",
            "\n",
            "- `file_path`: The path to the HDF5 file.\n",
            "- `mode`: The mode in which the file is opened, either \"w\" (write mode) or \"r\" (read mode).\n",
            "- `cam_type`: A string indicating the type of camera, defaulting to \"davis\".\n",
            "\n",
            "The function uses the `h5py` library to handle HDF5 files. It also imports a logger from the `spiker.log` module.\n",
            "\n",
            "Here's what happens in the function:\n",
            "\n",
            "1. If the mode is \"w\" (write mode):\n",
            "   - The function opens an HDF5 file at the specified path.\n",
            "   - It creates three groups: \"dvs\", \"extra\", and \"aps\" if the camera type is \"davis\".\n",
            "   - It also creates another group called \"imu\".\n",
            "\n",
            "2. If the mode is \"r\" (read mode):\n",
            "   - The function opens an HDF5 file at the specified path in read mode.\n",
            "\n",
            "The function returns the dataset object, which can be used to interact with the HDF5 file.\n",
            "\n",
            "This setup is typically used for storing data from a camera system, where different types of data (like DVS events, extra information, and sensor data) are organized into separate groups within the HDF5 file.\n",
            "\n",
            "\n",
            "ID: 9\n",
            "Entry: {'code': \"import flatbuffers\\n\\nclass FloatingPoint(object):\\n    __slots__ = ['_tab']\\n\\n    @classmethod\\n    def GetRootAsFloatingPoint(cls, buf, offset):\\n        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)\\n        x = FloatingPoint()\\n        x.Init(buf, n + offset)\\n        return x\\n\\n    \\n    def Init(self, buf, pos):\\n        self._tab = flatbuffers.table.Table(buf, pos)\\n\\n    \\n    def Precision(self):\\n        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))\\n        if o != 0:\\n            return self._tab.Get(flatbuffers.number_types.Int16Flags, o + self._tab.Pos)\\n        return 0\\n\\ndef FloatingPointStart(builder): builder.StartObject(1)\\ndef FloatingPointAddPrecision(builder, precision): builder.PrependInt16Slot(0, precision, 0)\\ndef FloatingPointEnd(builder): return builder.EndObject()\\n\", 'summary': \"This Python code defines a class `FloatingPoint` that represents a floating-point number with a specific precision. It uses the FlatBuffers library to serialize and deserialize the data efficiently.\\n\\nHere's a breakdown of the key components:\\n\\n1. **Class Definition**:\\n   - The `FloatingPoint` class has a single attribute `_tab`, which is used to store the table data from FlatBuffers.\\n\\n2. **Class Methods**:\\n   - `GetRootAsFloatingPoint`: This method takes a buffer and an offset, decodes the buffer into a `FloatingPoint` object, and returns it.\\n   - `Init`: This method initializes the `_tab` attribute with the provided buffer and position.\\n\\n3. **Attribute Accessors**:\\n   - `Precision`: This method retrieves the precision of the floating-point number from the table. If the offset is not zero, it reads the int16 value at that offset; otherwise, it returns 0.\\n\\n4. **FlatBuffers Builder Methods**:\\n   - `FloatingPointStart`, `FloatingPointAddPrecision`, and `FloatingPointEnd`: These methods are used to construct a `FloatingPoint` object using the FlatBuffers builder API.\\n     - `FloatingPointStart`: Starts building a new `FloatingPoint` object.\\n     - `FloatingPointAddPrecision`: Adds a precision value to the `FloatingPoint` object being built.\\n     - `FloatingPointEnd`: Completes the construction of the `FloatingPoint` object and returns its offset.\\n\\nThis class is useful for handling floating-point numbers with specific precision in applications that require efficient serialization and deserialization, such as network protocols or data storage systems.\"}\n",
            "Summary: This Python code defines a class `FloatingPoint` that represents a floating-point number with a specific precision. It uses the FlatBuffers library to serialize and deserialize the data efficiently.\n",
            "\n",
            "Here's a breakdown of the key components:\n",
            "\n",
            "1. **Class Definition**:\n",
            "   - The `FloatingPoint` class has a single attribute `_tab`, which is used to store the table data from FlatBuffers.\n",
            "\n",
            "2. **Class Methods**:\n",
            "   - `GetRootAsFloatingPoint`: This method takes a buffer and an offset, decodes the buffer into a `FloatingPoint` object, and returns it.\n",
            "   - `Init`: This method initializes the `_tab` attribute with the provided buffer and position.\n",
            "\n",
            "3. **Attribute Accessors**:\n",
            "   - `Precision`: This method retrieves the precision of the floating-point number from the table. If the offset is not zero, it reads the int16 value at that offset; otherwise, it returns 0.\n",
            "\n",
            "4. **FlatBuffers Builder Methods**:\n",
            "   - `FloatingPointStart`, `FloatingPointAddPrecision`, and `FloatingPointEnd`: These methods are used to construct a `FloatingPoint` object using the FlatBuffers builder API.\n",
            "     - `FloatingPointStart`: Starts building a new `FloatingPoint` object.\n",
            "     - `FloatingPointAddPrecision`: Adds a precision value to the `FloatingPoint` object being built.\n",
            "     - `FloatingPointEnd`: Completes the construction of the `FloatingPoint` object and returns its offset.\n",
            "\n",
            "This class is useful for handling floating-point numbers with specific precision in applications that require efficient serialization and deserialization, such as network protocols or data storage systems.\n",
            "\n",
            "\n",
            "Summaries added and saved to summarized_code_test.json\n"
          ]
        }
      ],
      "source": [
        "# Proof of concept\n",
        "\n",
        "testdf = df[\"content\"].head(10)\n",
        "\n",
        "cleaned_test = testdf.apply(clean_code)\n",
        "\n",
        "cleaned_data_list_test = cleaned_test.tolist()\n",
        "\n",
        "formatted_data_test = [{\"code\": item} for item in cleaned_data_list_test]\n",
        "\n",
        "payload_test = json.dumps(formatted_data_test, ensure_ascii=False).encode(\"utf-8\")\n",
        "\n",
        "output_filename = \"cleaned_data_test.json\"\n",
        "\n",
        "with open(output_filename, \"w\") as f:\n",
        "    json.dump(formatted_data_test, f, indent=4)\n",
        "\n",
        "print(f\"Data saved to {output_filename}\")\n",
        "\n",
        "add_summaries_to_json(\"cleaned_data_test.json\", \"summarized_code_test.json\")\n",
        "\n",
        "print(\"Summaries added and saved to summarized_code_test.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batching summarization\n",
        "\n",
        "def split_json_into_batches(input_json_filename, output_dir=\"batches\", batch_size=10):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    with open(input_json_filename, \"r\") as infile:\n",
        "        code_data = json.load(infile)\n",
        "    \n",
        "    if not isinstance(code_data, list):\n",
        "        raise ValueError(\"Expected a list of dictionaries but got a different format.\")\n",
        "    \n",
        "    batch_filenames = []\n",
        "    for i in range(0, len(code_data), batch_size):\n",
        "        batch_data = code_data[i:i+batch_size]\n",
        "        batch_filename = f\"{output_dir}/batch_{i//batch_size}.json\"\n",
        "        \n",
        "        with open(batch_filename, \"w\") as batch_file:\n",
        "            json.dump(batch_data, batch_file, indent=4)\n",
        "        \n",
        "        batch_filenames.append(batch_filename)\n",
        "    \n",
        "    print(f\"Split {input_json_filename} into {len(batch_filenames)} batches in {output_dir}/\")\n",
        "    return batch_filenames\n",
        "\n",
        "def process_batch_file(input_batch_filename, output_batch_filename=None):\n",
        "    if output_batch_filename is None:\n",
        "        base, ext = os.path.splitext(input_batch_filename)\n",
        "        output_batch_filename = f\"{base}_processed{ext}\"\n",
        "    \n",
        "    with open(input_batch_filename, \"r\") as infile:\n",
        "        batch_data = json.load(infile)\n",
        "    \n",
        "    for id, entry in enumerate(batch_data):\n",
        "        if not isinstance(entry, dict) or \"code\" not in entry:\n",
        "            raise ValueError(f\"Invalid entry format: {entry}\")\n",
        "        \n",
        "        prompt = f\"Summarize the following Python code:\\n{entry['code']}\"\n",
        "        summary = query_model(prompt)\n",
        "        entry[\"summary\"] = summary\n",
        "        print(f\"Processing batch {os.path.basename(input_batch_filename)}, entry ID: {id}\")\n",
        "        print(f\"Entry: {entry}\")\n",
        "        print(\"Summary: \" + summary)\n",
        "        print()\n",
        "    \n",
        "    with open(output_batch_filename, \"w\") as outfile:\n",
        "        json.dump(batch_data, outfile, indent=4)\n",
        "    \n",
        "    print(f\"Processed batch written to {output_batch_filename}\")\n",
        "    return output_batch_filename\n",
        "\n",
        "def combine_processed_batches(processed_batch_pattern, output_json_filename):\n",
        "    processed_files = sorted(glob.glob(processed_batch_pattern))\n",
        "    \n",
        "    if not processed_files:\n",
        "        raise ValueError(f\"No files found matching pattern: {processed_batch_pattern}\")\n",
        "    \n",
        "    combined_data = []\n",
        "    \n",
        "    for filename in processed_files:\n",
        "        with open(filename, \"r\") as f:\n",
        "            batch_data = json.load(f)\n",
        "            combined_data.extend(batch_data)\n",
        "    \n",
        "    with open(output_json_filename, \"w\") as outfile:\n",
        "        json.dump(combined_data, outfile, indent=4)\n",
        "    \n",
        "    print(f\"Combined {len(processed_files)} batches with {len(combined_data)} total entries\")\n",
        "    print(f\"Output written to {output_json_filename}\")\n",
        "    \n",
        "    return len(combined_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split cleaned_data.json into 100 batches in batches/\n"
          ]
        }
      ],
      "source": [
        "# Use batching for summarization\n",
        "\n",
        "batch_files = split_json_into_batches(\"cleaned_data.json\", batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 0\n",
            "Processing batch batch_0.json, entry ID: 0\n",
            "Entry: {'code': 'from   _TFL.pyk           import pyk\\n\\nfrom   rsclib.HTML_Parse  import tag, Page_Tree\\nfrom   rsclib.autosuper   import autosuper\\nfrom   spider.common      import Interface, Inet4, Inet6, unroutable\\nfrom   spider.common      import WLAN_Config\\nfrom   spider.luci        import Version_Mixin\\n\\nclass Status (Page_Tree, Version_Mixin) :\\n    url          = \\'cgi-bin/luci/freifunk/status/status\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    wl_names = dict \\\\\\n        ( ssid    = \\'ssid\\'\\n        , _bsiid  = \\'bssid\\'\\n        , channel = \\'channel\\'\\n        , mode    = \\'mode\\'\\n        )\\n\\n    def parse (self) :\\n        root  = self.tree.getroot ()\\n        self.wlans  = []\\n        self.routes = {}\\n        for div in root.findall (\".//%s\" % tag (\"div\")) :\\n            id = div.get (\\'id\\')\\n            if id == \\'cbi-wireless\\' :\\n                wlan_div = div\\n            elif id == \\'cbi-routes\\' :\\n                route_div = div\\n            self.try_get_version (div)\\n        for d in self.tbl_iter (wlan_div) :\\n            for k, newkey in pyk.iteritems (self.wl_names) :\\n                if k in d :\\n                    d [newkey] = d [k]\\n            wl = WLAN_Config (** d)\\n            self.wlans.append (wl)\\n        for d in self.tbl_iter (route_div) :\\n            iface = d.get (\\'iface\\')\\n            gw    = d.get (\\'gateway\\')\\n            if iface and gw :\\n                self.routes [iface] = gw\\n        self.set_version (root)\\n    \\n\\n    def tbl_iter (self, div) :\\n        tbl = div.find (\".//%s\" % tag (\"table\"))\\n        assert tbl.get (\\'class\\') == \\'cbi-section-table\\'\\n        d = {}\\n        for tr in tbl :\\n            if \\'cbi-section-table-row\\' not in tr.get (\\'class\\').split () :\\n                continue\\n            for input in tr.findall (\".//%s\" % tag (\\'input\\')) :\\n                name = input.get (\\'id\\').split (\\'.\\') [-1]\\n                val  = input.get (\\'value\\')\\n                d [name] = val\\n            if not d :\\n                continue\\n            yield d\\n    \\n\\n\\n\\nclass Table_Iter (Page_Tree) :\\n\\n    def table_iter (self) :\\n        root  = self.tree.getroot ()\\n        for div in root.findall (\".//%s\" % tag (\"div\")) :\\n            if div.get (\\'id\\') == \\'maincontent\\' :\\n                break\\n        tbl = div.find (\".//%s\" % tag (\"table\"))\\n        if tbl is None :\\n            return\\n        for tr in tbl :\\n            if tr [0].tag == tag (\\'th\\') :\\n                continue\\n            yield (self.tree.get_text (x) for x in tr)\\n    \\n\\n\\n\\nclass OLSR_Connections (Table_Iter) :\\n    url          = \\'cgi-bin/luci/freifunk/olsr/\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    def parse (self) :\\n        self.neighbors = {}\\n        for l in self.table_iter () :\\n            neighbor, ip, lq, nlq, etx = l\\n            lq, nlq, etx = (float (x) for x in (lq, nlq, etx))\\n            self.neighbors [neighbor] = [ip, lq, nlq, etx]\\n    \\n\\n\\n\\nclass OLSR_Routes (Table_Iter) :\\n    url          = \\'cgi-bin/luci/freifunk/olsr/routes\\'\\n    retries      = 2\\n    timeout      = 10\\n    html_charset = \\'utf-8\\' \\n\\n    def parse (self) :\\n        self.iface_by_gw = {}\\n        for l in self.table_iter () :\\n            announced, gw, iface, metric, etx = l\\n            if gw in self.iface_by_gw :\\n                assert iface == self.iface_by_gw [gw]\\n            else :\\n                self.iface_by_gw [gw] = iface\\n    \\n\\n\\n\\nclass OpenWRT (autosuper) :\\n\\n    def __init__ (self, site, request) :\\n        self.site    = site\\n        self.request = request\\n        if \\'interfaces\\' in self.request or \\'ips\\' in self.request :\\n            st    = Status           (site = site)\\n            conn  = OLSR_Connections (site = site)\\n            route = OLSR_Routes      (site = site)\\n            self.version = st.version\\n            assert len (st.wlans) <= 1\\n            interfaces   = {}\\n            ips          = {}\\n            count = 0\\n            for gw, ifname in pyk.iteritems (route.iface_by_gw) :\\n                ip, lq, nlq, etx  = conn.neighbors [gw]\\n                i4 = Inet4 (ip, None, None, iface = ifname)\\n                ips [i4] = 1\\n                is_wlan = True\\n                if lq == nlq == etx == 1.0 :\\n                    is_wlan = False\\n                if ifname in interfaces :\\n                    iface = interfaces [ifname]\\n                    if not iface.is_wlan and is_wlan :\\n                        iface.is_wlan   = True\\n                        iface.wlan_info = st.wlans [0]\\n                else :\\n                    iface = Interface (count, ifname, None)\\n                    iface.is_wlan = is_wlan\\n                    if is_wlan :\\n                        iface.wlan_info = st.wlans [0]\\n                    count += 1\\n                    interfaces [ifname] = iface\\n                if i4 not in iface.inet4 :\\n                    iface.append_inet4 (i4)\\n            wl_if = None\\n            for iface in pyk.itervalues (interfaces) :\\n                if iface.is_wlan :\\n                    if wl_if :\\n                        m = \"Duplicate wlan: %s/%s\" % (iface.name, wl_if.name)\\n                        raise ValueError (m)\\n                    wl_if = iface\\n            \\n            n  = \\'unknown\\'\\n            i4 = Inet4 (self.request [\\'ip\\'], None, None, iface = n)\\n            if i4 not in ips :\\n                assert n not in interfaces\\n                iface = interfaces [n] = Interface (count, n, None)\\n                iface.append_inet4 (i4)\\n                iface.is_wlan = False\\n                if not wl_if and st.wlans :\\n                    iface.is_wlan   = True\\n                    iface.wlan_info = st.wlans [0]\\n                ips [i4] = True\\n\\n            self.request [\\'ips\\']        = ips\\n            self.request [\\'interfaces\\'] = interfaces\\n            self.request [\\'version\\']    = st.version\\n    \\n\\n\\n', 'summary': 'This Python code defines several classes to parse and process data from web pages related to a Freifunk network, which is a decentralized mesh networking system. The main functionalities include:\\n\\n1. **Status Class**: Parses the status page of a Freifunk node to extract wireless network information (SSID, BSSID, channel, mode) and routing table entries.\\n\\n2. **Table_Iter Class**: A base class for parsing tables from web pages by iterating over rows and extracting data from input elements.\\n\\n3. **OLSR_Connections Class**: Parses the OLSR (Optimized Link State Routing) connections page to extract information about neighboring nodes, including IP addresses, link quality metrics, and other routing-related data.\\n\\n4. **OLSR_Routes Class**: Parses the OLSR routes page to extract information about network interfaces associated with gateway IPs.\\n\\n5. **OpenWRT Class**: Combines the functionality of the above classes to gather comprehensive network information for a Freifunk node. It initializes instances of `Status`, `OLSR_Connections`, and `OLSR_Routes` to fetch data from different web pages, processes this data to determine interface types (wlan or not), and organizes it into dictionaries of interfaces and IP addresses.\\n\\nThe code uses various utility functions and classes from modules like `_TFL.pyk`, `rsclib.HTML_Parse`, and `spider.common` to handle HTML parsing, network configuration, and other tasks. The `autosuper` class is used for multiple inheritance with a simplified syntax.'}\n",
            "Summary: This Python code defines several classes to parse and process data from web pages related to a Freifunk network, which is a decentralized mesh networking system. The main functionalities include:\n",
            "\n",
            "1. **Status Class**: Parses the status page of a Freifunk node to extract wireless network information (SSID, BSSID, channel, mode) and routing table entries.\n",
            "\n",
            "2. **Table_Iter Class**: A base class for parsing tables from web pages by iterating over rows and extracting data from input elements.\n",
            "\n",
            "3. **OLSR_Connections Class**: Parses the OLSR (Optimized Link State Routing) connections page to extract information about neighboring nodes, including IP addresses, link quality metrics, and other routing-related data.\n",
            "\n",
            "4. **OLSR_Routes Class**: Parses the OLSR routes page to extract information about network interfaces associated with gateway IPs.\n",
            "\n",
            "5. **OpenWRT Class**: Combines the functionality of the above classes to gather comprehensive network information for a Freifunk node. It initializes instances of `Status`, `OLSR_Connections`, and `OLSR_Routes` to fetch data from different web pages, processes this data to determine interface types (wlan or not), and organizes it into dictionaries of interfaces and IP addresses.\n",
            "\n",
            "The code uses various utility functions and classes from modules like `_TFL.pyk`, `rsclib.HTML_Parse`, and `spider.common` to handle HTML parsing, network configuration, and other tasks. The `autosuper` class is used for multiple inheritance with a simplified syntax.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 1\n",
            "Entry: {'code': \"from PIL import Image\\nimport cv2\\nimport imagehash\\nimport math\\nimport numpy as np\\n\\nDIFF_THRES = 20\\nLIMIT = 2\\nRESIZE = 1000\\n\\n\\ndef calc_hash(img):\\n    \\n    \\n    img = resize(img)\\n    return imagehash.whash(Image.fromarray(img))\\n\\n\\ndef compare(hash1, hash2):\\n    \\n    return hash1 - hash2\\n\\n\\ndef limit(img, std_hash, count):\\n    \\n    \\n    cmp_hash = calc_hash(img)\\n\\n    \\n    diff = compare(std_hash, cmp_hash)\\n\\n    \\n    if diff <= DIFF_THRES:\\n        \\n        if count >= LIMIT:\\n            return 'remove'\\n\\n    \\n    else:\\n        \\n        return 'update_std'\\n\\n    \\n    return 'continue'\\n\\n\\ndef resize(img):\\n    \\n    \\n    width = np.shape(img)[1]\\n    height = np.shape(img)[0]\\n\\n    \\n    if width > RESIZE:\\n        \\n        scale = RESIZE / width\\n        resized_img = cv2.resize(\\n            img, (RESIZE, math.floor(height / scale)), cv2.INTER_AREA)\\n        \\n        return resized_img\\n\\n    \\n    return img\\n\\n\\ndef set_standard(images, filename):\\n    \\n    return filename, calc_hash(images[filename]), 0\\n\", 'summary': \"This Python code is designed to process images and determine whether they should be updated or removed based on their similarity to a standard image. Here's a summary of the key components:\\n\\n1. **Imports**: The code imports necessary libraries including PIL for image processing, cv2 for computer vision tasks, imagehash for hashing images, math for mathematical operations, and numpy for numerical computations.\\n\\n2. **Constants**:\\n   - `DIFF_THRES`: A threshold value (20) used to compare the difference between hashes.\\n   - `LIMIT`: A limit on how many times an image can be updated before it is removed (2).\\n   - `RESIZE`: The maximum width of images after resizing (1000 pixels).\\n\\n3. **Functions**:\\n   - **`calc_hash(img)`**: Resizes the image and calculates its hash using the Wavelet Hashing method.\\n   - **`compare(hash1, hash2)`**: Compares two hashes by subtracting one from the other.\\n   - **`limit(img, std_hash, count)`**: Determines whether to update the standard image, remove it, or continue processing based on the difference between the current image's hash and the standard hash. It also checks if the image has been updated too many times.\\n   - **`resize(img)`**: Resizes an image to a maximum width of 1000 pixels while maintaining the aspect ratio.\\n   - **`set_standard(images, filename)`**: Sets up the standard image by calculating its hash and initializing a count.\\n\\n4. **Usage**:\\n   - The code is intended to be used in a larger system where images are processed and compared against a standard image. It helps in managing image versions and deciding whether to keep or remove them based on their similarity.\\n\\nThis code provides a basic framework for image version control and can be extended with additional functionality such as handling multiple images, saving the state of images, and integrating with other systems for image management.\"}\n",
            "Summary: This Python code is designed to process images and determine whether they should be updated or removed based on their similarity to a standard image. Here's a summary of the key components:\n",
            "\n",
            "1. **Imports**: The code imports necessary libraries including PIL for image processing, cv2 for computer vision tasks, imagehash for hashing images, math for mathematical operations, and numpy for numerical computations.\n",
            "\n",
            "2. **Constants**:\n",
            "   - `DIFF_THRES`: A threshold value (20) used to compare the difference between hashes.\n",
            "   - `LIMIT`: A limit on how many times an image can be updated before it is removed (2).\n",
            "   - `RESIZE`: The maximum width of images after resizing (1000 pixels).\n",
            "\n",
            "3. **Functions**:\n",
            "   - **`calc_hash(img)`**: Resizes the image and calculates its hash using the Wavelet Hashing method.\n",
            "   - **`compare(hash1, hash2)`**: Compares two hashes by subtracting one from the other.\n",
            "   - **`limit(img, std_hash, count)`**: Determines whether to update the standard image, remove it, or continue processing based on the difference between the current image's hash and the standard hash. It also checks if the image has been updated too many times.\n",
            "   - **`resize(img)`**: Resizes an image to a maximum width of 1000 pixels while maintaining the aspect ratio.\n",
            "   - **`set_standard(images, filename)`**: Sets up the standard image by calculating its hash and initializing a count.\n",
            "\n",
            "4. **Usage**:\n",
            "   - The code is intended to be used in a larger system where images are processed and compared against a standard image. It helps in managing image versions and deciding whether to keep or remove them based on their similarity.\n",
            "\n",
            "This code provides a basic framework for image version control and can be extended with additional functionality such as handling multiple images, saving the state of images, and integrating with other systems for image management.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 2\n",
            "Entry: {'code': \"from .cli.cli import main\\n\\n\\n\\n\\n\\nif __name__ == '__main__':\\n    main()\\n\", 'summary': 'This Python script is designed to run a command-line interface (CLI) application. Here\\'s a breakdown of what it does:\\n\\n1. **Import Statement**:\\n   ```python\\n   from .cli.cli import main\\n   ```\\n   This line imports the `main` function from the `cli.py` module located in the `cli` subdirectory relative to the current file.\\n\\n2. **Main Guard**:\\n   ```python\\n   if __name__ == \\'__main__\\':\\n       main()\\n   ```\\n   This is a common Python idiom known as the \"main guard\" or \"entry point\". It checks whether the script is being run directly (i.e., not imported as a module in another script). If it is being run directly, it calls the `main` function.\\n\\n### Summary\\n- The script imports a `main` function from a subdirectory.\\n- It includes a guard to ensure that the `main` function is only called when the script is executed directly, not when imported as a module.'}\n",
            "Summary: This Python script is designed to run a command-line interface (CLI) application. Here's a breakdown of what it does:\n",
            "\n",
            "1. **Import Statement**:\n",
            "   ```python\n",
            "   from .cli.cli import main\n",
            "   ```\n",
            "   This line imports the `main` function from the `cli.py` module located in the `cli` subdirectory relative to the current file.\n",
            "\n",
            "2. **Main Guard**:\n",
            "   ```python\n",
            "   if __name__ == '__main__':\n",
            "       main()\n",
            "   ```\n",
            "   This is a common Python idiom known as the \"main guard\" or \"entry point\". It checks whether the script is being run directly (i.e., not imported as a module in another script). If it is being run directly, it calls the `main` function.\n",
            "\n",
            "### Summary\n",
            "- The script imports a `main` function from a subdirectory.\n",
            "- It includes a guard to ensure that the `main` function is only called when the script is executed directly, not when imported as a module.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 3\n",
            "Entry: {'code': 'import time\\n\\nfrom PyQt5 import QtGui, QtCore\\n\\nfrom ui.room_item import Ui_Form\\nfrom PyQt5.QtWidgets import QWidget\\n\\nclass Room_Item(QWidget,Ui_Form):\\n    def __init__(self,parent=None,room_data=None):\\n        super(Room_Item,self).__init__(parent)\\n        self.setupUi(self)\\n        self.data = room_data\\n        self.setRoomInfo()\\n\\n    def setRoomInfo(self):\\n        self.room_name.setText(\\'{}({})\\'.format(self.data[\\'naturalName\\'], self.data[\\'roomName\\']))\\n        self.description.setText(\"<a style=\\'color:\\n        timeStamp = int(self.data[\\'creationDate\\']) / 1000\\n        timeArray = time.localtime(timeStamp)\\n        otherStyleTime = time.strftime(\"%Y-%m-%d\", timeArray)\\n        self.create_time.setText(\"<a style=\\'color:\\n        members = len(self.data[\\'owners\\']) + len(self.data[\\'admins\\']) + len(self.data[\\'members\\'])\\n        memberCounter = \"<a style=\\'color:\\n        self.member.setText(memberCounter)', 'summary': \"This Python code defines a class `Room_Item` that inherits from both `QWidget` and `Ui_Form`. The class is designed to display information about a room in a graphical user interface (GUI). Here's a summary of the key components:\\n\\n1. **Imports**:\\n   - The code imports necessary modules, including `time`, `PyQt5.QtGui`, `PyQt5.QtCore`, and custom UI elements from `ui.room_item`.\\n\\n2. **Class Definition**:\\n   - `Room_Item` is a subclass of `QWidget` and `Ui_Form`. This allows it to use both the widget functionality and the UI layout defined in `Ui_Form`.\\n\\n3. **Constructor (`__init__`)**:\\n   - The constructor initializes the `Room_Item` object.\\n   - It calls the superclass constructors using `super(Room_Item, self).__init__(parent)`.\\n   - It sets up the user interface by calling `self.setupUi(self)`.\\n   - It stores the room data passed as an argument and calls `self.setRoomInfo()` to populate the UI with this data.\\n\\n4. **Method (`setRoomInfo`)**:\\n   - This method updates the UI elements based on the room data.\\n   - It sets the text of a label (`room_name`) to display both the natural name and the room name of the room.\\n   - It converts a timestamp (presumably in milliseconds) from the room data into a human-readable date format and displays it.\\n   - It calculates the total number of members (owners, admins, and regular members) and updates another label (`member`) with this count.\\n\\nThe code is structured to be used within a PyQt5 application, where `Room_Item` would typically be instantiated and added to a layout in a main window or dialog.\"}\n",
            "Summary: This Python code defines a class `Room_Item` that inherits from both `QWidget` and `Ui_Form`. The class is designed to display information about a room in a graphical user interface (GUI). Here's a summary of the key components:\n",
            "\n",
            "1. **Imports**:\n",
            "   - The code imports necessary modules, including `time`, `PyQt5.QtGui`, `PyQt5.QtCore`, and custom UI elements from `ui.room_item`.\n",
            "\n",
            "2. **Class Definition**:\n",
            "   - `Room_Item` is a subclass of `QWidget` and `Ui_Form`. This allows it to use both the widget functionality and the UI layout defined in `Ui_Form`.\n",
            "\n",
            "3. **Constructor (`__init__`)**:\n",
            "   - The constructor initializes the `Room_Item` object.\n",
            "   - It calls the superclass constructors using `super(Room_Item, self).__init__(parent)`.\n",
            "   - It sets up the user interface by calling `self.setupUi(self)`.\n",
            "   - It stores the room data passed as an argument and calls `self.setRoomInfo()` to populate the UI with this data.\n",
            "\n",
            "4. **Method (`setRoomInfo`)**:\n",
            "   - This method updates the UI elements based on the room data.\n",
            "   - It sets the text of a label (`room_name`) to display both the natural name and the room name of the room.\n",
            "   - It converts a timestamp (presumably in milliseconds) from the room data into a human-readable date format and displays it.\n",
            "   - It calculates the total number of members (owners, admins, and regular members) and updates another label (`member`) with this count.\n",
            "\n",
            "The code is structured to be used within a PyQt5 application, where `Room_Item` would typically be instantiated and added to a layout in a main window or dialog.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 4\n",
            "Entry: {'code': 'import asyncio\\nimport re\\nimport sys\\nimport traceback\\n\\nimport toga\\nfrom toga import Key\\nfrom .keys import toga_to_winforms_key\\n\\nfrom .libs import Threading, WinForms, shcore, user32, win_version\\nfrom .libs.proactor import WinformsProactorEventLoop\\nfrom .window import Window\\n\\n\\nclass MainWindow(Window):\\n    def winforms_FormClosing(self, sender, event):\\n        if not self.interface.app._impl._is_exiting:\\n            event.Cancel = not self.interface.app.exit()\\n\\n\\nclass App:\\n    _MAIN_WINDOW_CLASS = MainWindow\\n\\n    def __init__(self, interface):\\n        self.interface = interface\\n        self.interface._impl = self\\n\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        self._is_exiting = False\\n\\n        self.loop = WinformsProactorEventLoop()\\n        asyncio.set_event_loop(self.loop)\\n\\n    def create(self):\\n        self.native = WinForms.Application\\n        self.app_context = WinForms.ApplicationContext()\\n\\n        \\n        \\n        \\n        \\n        if win_version.Major >= 6:  \\n            \\n            \\n            if ((win_version.Major == 6 and win_version.Minor == 3) or\\n                    (win_version.Major == 10 and win_version.Build < 15063)):\\n                shcore.SetProcessDpiAwareness(True)\\n            \\n            \\n            elif win_version.Major == 10 and win_version.Build >= 15063:\\n                user32.SetProcessDpiAwarenessContext(-2)\\n            \\n            else:\\n                user32.SetProcessDPIAware()\\n\\n        self.native.EnableVisualStyles()\\n        self.native.SetCompatibleTextRenderingDefault(False)\\n\\n        self.interface.commands.add(\\n            toga.Command(\\n                lambda _: self.interface.about(),\\n                \\'About {}\\'.format(self.interface.name),\\n                group=toga.Group.HELP\\n            ),\\n            toga.Command(None, \\'Preferences\\', group=toga.Group.FILE),\\n            \\n            toga.Command(\\n                lambda _: self.interface.exit(),\\n                \\'Exit \\' + self.interface.name,\\n                shortcut=Key.MOD_1 + \\'q\\',\\n                group=toga.Group.FILE,\\n                section=sys.maxsize\\n            ),\\n            toga.Command(\\n                lambda _: self.interface.visit_homepage(),\\n                \\'Visit homepage\\',\\n                enabled=self.interface.home_page is not None,\\n                group=toga.Group.HELP\\n            )\\n        )\\n        self._create_app_commands()\\n\\n        \\n        self.interface.startup()\\n        self.create_menus()\\n        self.interface.icon.bind(self.interface.factory)\\n        self.interface.main_window._impl.set_app(self)\\n\\n    def create_menus(self):\\n        self._menu_items = {}\\n        self._menu_groups = {}\\n\\n        toga.Group.FILE.order = 0\\n        menubar = WinForms.MenuStrip()\\n        submenu = None\\n        for cmd in self.interface.commands:\\n            if cmd == toga.GROUP_BREAK:\\n                submenu = None\\n            elif cmd == toga.SECTION_BREAK:\\n                submenu.DropDownItems.Add(\\'-\\')\\n            else:\\n                submenu = self._submenu(cmd.group, menubar)\\n\\n                item = WinForms.ToolStripMenuItem(cmd.label)\\n\\n                if cmd.action:\\n                    item.Click += cmd._impl.as_handler()\\n                item.Enabled = cmd.enabled\\n\\n                if cmd.shortcut is not None:\\n                    shortcut_keys = toga_to_winforms_key(cmd.shortcut)\\n                    item.ShortcutKeys = shortcut_keys\\n                    item.ShowShortcutKeys = True\\n\\n                cmd._impl.native.append(item)\\n\\n                self._menu_items[item] = cmd\\n                submenu.DropDownItems.Add(item)\\n\\n        self.interface.main_window._impl.native.Controls.Add(menubar)\\n        self.interface.main_window._impl.native.MainMenuStrip = menubar\\n        self.interface.main_window.content.refresh()\\n\\n    def _submenu(self, group, menubar):\\n        try:\\n            return self._menu_groups[group]\\n        except KeyError:\\n            if group is None:\\n                submenu = menubar\\n            else:\\n                parent_menu = self._submenu(group.parent, menubar)\\n\\n                submenu = WinForms.ToolStripMenuItem(group.label)\\n\\n                \\n                if group.parent is None:\\n                    parent_menu.Items.Add(submenu)\\n                else:\\n                    parent_menu.DropDownItems.Add(submenu)\\n\\n            self._menu_groups[group] = submenu\\n        return submenu\\n\\n    def _create_app_commands(self):\\n        \\n        pass\\n\\n    def open_document(self, fileURL):\\n        \\n        print(\"STUB: If you want to handle opening documents, implement App.open_document(fileURL)\")\\n\\n    def winforms_thread_exception(self, sender, winforms_exc):\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        print(\"Traceback (most recent call last):\")\\n        py_exc = winforms_exc.get_Exception()\\n        full_stack_trace = py_exc.StackTrace\\n        regex = re.compile(\\n            r\"^\\\\[(?:\\'(.*?)\\', )*(?:\\'(.*?)\\')\\\\]   (?:.*?) Python\\\\.Runtime\",\\n            re.DOTALL | re.UNICODE\\n        )\\n\\n        stacktrace_relevant_lines = regex.findall(full_stack_trace)\\n        if len(stacktrace_relevant_lines) == 0:\\n            self.print_stack_trace(full_stack_trace)\\n        else:\\n            for lines in stacktrace_relevant_lines:\\n                for line in lines:\\n                    self.print_stack_trace(line)\\n        print(py_exc.Message)\\n\\n    @classmethod\\n    def print_stack_trace(cls, stack_trace_line):\\n        for level in stack_trace_line.split(\"\\', \\'\"):\\n            for line in level.split(\"\\\\\\\\n\"):\\n                if line:\\n                    print(line)\\n\\n    def run_app(self):\\n        try:\\n            self.create()\\n\\n            self.native.ThreadException += self.winforms_thread_exception\\n\\n            self.loop.run_forever(self.app_context)\\n        except:  \\n            traceback.print_exc()\\n\\n    def main_loop(self):\\n        thread = Threading.Thread(Threading.ThreadStart(self.run_app))\\n        thread.SetApartmentState(Threading.ApartmentState.STA)\\n        thread.Start()\\n        thread.Join()\\n\\n    def show_about_dialog(self):\\n        message_parts = []\\n        if self.interface.name is not None:\\n            if self.interface.version is not None:\\n                message_parts.append(\\n                    \"{name} v{version}\".format(\\n                        name=self.interface.name,\\n                        version=self.interface.version,\\n                    )\\n                )\\n            else:\\n                message_parts.append(\\n                    \"{name}\".format(name=self.interface.name)\\n                )\\n        elif self.interface.version is not None:\\n            message_parts.append(\\n                \"v{version}\".format(version=self.interface.version)\\n            )\\n\\n        if self.interface.author is not None:\\n            message_parts.append(\\n                \"Author: {author}\".format(author=self.interface.author)\\n            )\\n        if self.interface.description is not None:\\n            message_parts.append(\\n                \"\\\\n{description}\".format(\\n                    description=self.interface.description\\n                )\\n            )\\n        self.interface.main_window.info_dialog(\\n            \\'About {}\\'.format(self.interface.name), \"\\\\n\".join(message_parts)\\n        )\\n\\n    def exit(self):\\n        self._is_exiting = True\\n        self.native.Exit()\\n\\n    def set_main_window(self, window):\\n        self.app_context.MainForm = window._impl.native\\n\\n    def set_on_exit(self, value):\\n        pass\\n\\n    def current_window(self):\\n        self.interface.factory.not_implemented(\\'App.current_window()\\')\\n\\n    def enter_full_screen(self, windows):\\n        self.interface.factory.not_implemented(\\'App.enter_full_screen()\\')\\n\\n    def exit_full_screen(self, windows):\\n        self.interface.factory.not_implemented(\\'App.exit_full_screen()\\')\\n\\n    def set_cursor(self, value):\\n        self.interface.factory.not_implemented(\\'App.set_cursor()\\')\\n\\n    def show_cursor(self):\\n        self.interface.factory.not_implemented(\\'App.show_cursor()\\')\\n\\n    def hide_cursor(self):\\n        self.interface.factory.not_implemented(\\'App.hide_cursor()\\')\\n\\n    def add_background_task(self, handler):\\n        self.loop.call_soon(handler, self)\\n\\n\\nclass DocumentApp(App):\\n    def _create_app_commands(self):\\n        self.interface.commands.add(\\n            toga.Command(\\n                lambda w: self.open_file,\\n                label=\\'Open...\\',\\n                shortcut=Key.MOD_1 + \\'o\\',\\n                group=toga.Group.FILE,\\n                section=0\\n            ),\\n        )\\n\\n    def open_document(self, fileURL):\\n        \\n        self.interface.factory.not_implemented(\\'DocumentApp.open_document()\\')\\n', 'summary': 'This Python code defines a class `App` that represents the main application logic for a Toga-based GUI application running on Windows using WinForms. The class includes methods to create and manage the application window, handle commands, set up menus, and manage the event loop.\\n\\nKey functionalities include:\\n- Creating the main window and setting up the application context.\\n- Handling menu creation and command execution.\\n- Managing the event loop with an asynchronous proactor event loop.\\n- Implementing a method to open documents (though it\\'s currently not implemented).\\n- Handling exceptions that occur in WinForms threads.\\n- Running the application and managing the main thread.\\n\\nThe `DocumentApp` class extends `App` and adds specific functionality for document-based applications, including adding an \"Open...\" command to the file menu.'}\n",
            "Summary: This Python code defines a class `App` that represents the main application logic for a Toga-based GUI application running on Windows using WinForms. The class includes methods to create and manage the application window, handle commands, set up menus, and manage the event loop.\n",
            "\n",
            "Key functionalities include:\n",
            "- Creating the main window and setting up the application context.\n",
            "- Handling menu creation and command execution.\n",
            "- Managing the event loop with an asynchronous proactor event loop.\n",
            "- Implementing a method to open documents (though it's currently not implemented).\n",
            "- Handling exceptions that occur in WinForms threads.\n",
            "- Running the application and managing the main thread.\n",
            "\n",
            "The `DocumentApp` class extends `App` and adds specific functionality for document-based applications, including adding an \"Open...\" command to the file menu.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 5\n",
            "Entry: {'code': '__version__ = \"0.4.0\"\\n\\n\\ndef classFactory(iface):  \\n    \\n    \\n    from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner\\n    return SimplePhotogrammetryRoutePlanner(iface)\\n', 'summary': 'This Python code defines a module with a version number and a function to create instances of a specific class. Here\\'s a summary:\\n\\n1. **Version Information**:\\n   - The `__version__` variable is set to `\"0.4.0\"`, indicating the version of this module.\\n\\n2. **Class Factory Function**:\\n   - The `classFactory` function takes one parameter, `iface`.\\n   - Inside the function, it imports a class named `SimplePhotogrammetryRoutePlanner` from a relative module (`from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner`).\\n   - It then returns an instance of `SimplePhotogrammetryRoutePlanner`, passing the `iface` parameter to its constructor.\\n\\n### Purpose\\nThis code is likely part of a larger system where different route planning algorithms or tools are dynamically loaded and instantiated based on some configuration or interface. The `classFactory` function serves as a factory method to create instances of the `SimplePhotogrammetryRoutePlanner` class, which presumably implements specific functionality for photogrammetry-based route planning.\\n\\n### Usage\\nTo use this code:\\n1. Ensure that the relative module (`SimplePhotogrammetryRoutePlanner.py`) is in the same directory or correctly referenced.\\n2. Call the `classFactory` function with an appropriate `iface` parameter to create an instance of `SimplePhotogrammetryRoutePlanner`.\\n\\nExample usage:\\n```python\\nfrom . import classFactory\\n\\n# Assuming \\'iface\\' is already defined and suitable for the route planner\\nroute_planner = classFactory(iface)\\n```\\n\\nThis would create an instance of `SimplePhotogrammetryRoutePlanner` with the provided `iface`.'}\n",
            "Summary: This Python code defines a module with a version number and a function to create instances of a specific class. Here's a summary:\n",
            "\n",
            "1. **Version Information**:\n",
            "   - The `__version__` variable is set to `\"0.4.0\"`, indicating the version of this module.\n",
            "\n",
            "2. **Class Factory Function**:\n",
            "   - The `classFactory` function takes one parameter, `iface`.\n",
            "   - Inside the function, it imports a class named `SimplePhotogrammetryRoutePlanner` from a relative module (`from .SimplePhotogrammetryRoutePlanner import SimplePhotogrammetryRoutePlanner`).\n",
            "   - It then returns an instance of `SimplePhotogrammetryRoutePlanner`, passing the `iface` parameter to its constructor.\n",
            "\n",
            "### Purpose\n",
            "This code is likely part of a larger system where different route planning algorithms or tools are dynamically loaded and instantiated based on some configuration or interface. The `classFactory` function serves as a factory method to create instances of the `SimplePhotogrammetryRoutePlanner` class, which presumably implements specific functionality for photogrammetry-based route planning.\n",
            "\n",
            "### Usage\n",
            "To use this code:\n",
            "1. Ensure that the relative module (`SimplePhotogrammetryRoutePlanner.py`) is in the same directory or correctly referenced.\n",
            "2. Call the `classFactory` function with an appropriate `iface` parameter to create an instance of `SimplePhotogrammetryRoutePlanner`.\n",
            "\n",
            "Example usage:\n",
            "```python\n",
            "from . import classFactory\n",
            "\n",
            "# Assuming 'iface' is already defined and suitable for the route planner\n",
            "route_planner = classFactory(iface)\n",
            "```\n",
            "\n",
            "This would create an instance of `SimplePhotogrammetryRoutePlanner` with the provided `iface`.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 6\n",
            "Entry: {'code': 'from sklearn.feature_selection import VarianceThreshold\\nimport numpy as np\\n\\nnp.random.seed(1)\\nX = np.random.randn(100, 10)\\nX = np.hstack([X, np.zeros([100, 5])])\\n\\n\\n\\ndef featureSelection_variance(X, thrd):\\n    sel = VarianceThreshold(threshold=thrd)\\n    X_selected = sel.fit_transform(X)\\n    mask = sel.get_support()\\n    return X_selected, mask\\n\\n\\nX = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\\nselector = VarianceThreshold()\\nselector.fit_transform(X)\\nselector.variances_\\n', 'summary': \"The provided Python code demonstrates how to use the `VarianceThreshold` class from the `sklearn.feature_selection` module for feature selection based on variance. Here's a summary of the code:\\n\\n1. **Importing Libraries**:\\n   - The code imports `VarianceThreshold` from `sklearn.feature_selection` and `numpy` as `np`.\\n\\n2. **Setting Random Seed and Creating Data**:\\n   - A random seed is set to 1 for reproducibility.\\n   - A matrix `X` of shape (100, 10) is created with normally distributed random numbers.\\n   - Additional columns of zeros are appended to `X`, making it a total of 15 columns.\\n\\n3. **Defining the Feature Selection Function**:\\n   - The function `featureSelection_variance` takes two parameters: `X` (the data matrix) and `thrd` (the threshold for variance).\\n   - It creates an instance of `VarianceThreshold` with the specified threshold.\\n   - The function fits the selector to `X` and transforms it, selecting features based on their variance being greater than or equal to the threshold.\\n   - It returns the transformed data matrix `X_selected` and a boolean mask indicating which features were selected.\\n\\n4. **Example Usage of Feature Selection Function**:\\n   - A sample data matrix `X` is defined with three rows and four columns.\\n   - An instance of `VarianceThreshold` is created without specifying a threshold, so it uses the default threshold (0).\\n   - The function `fit_transform` is called on this selector with the sample data `X`, which selects features based on their variance.\\n   - The variances of all features in the original data are printed.\\n\\nIn summary, the code demonstrates how to use `VarianceThreshold` for feature selection by filtering out features with low variance. It also shows how to apply this method to both synthetic and sample data matrices.\"}\n",
            "Summary: The provided Python code demonstrates how to use the `VarianceThreshold` class from the `sklearn.feature_selection` module for feature selection based on variance. Here's a summary of the code:\n",
            "\n",
            "1. **Importing Libraries**:\n",
            "   - The code imports `VarianceThreshold` from `sklearn.feature_selection` and `numpy` as `np`.\n",
            "\n",
            "2. **Setting Random Seed and Creating Data**:\n",
            "   - A random seed is set to 1 for reproducibility.\n",
            "   - A matrix `X` of shape (100, 10) is created with normally distributed random numbers.\n",
            "   - Additional columns of zeros are appended to `X`, making it a total of 15 columns.\n",
            "\n",
            "3. **Defining the Feature Selection Function**:\n",
            "   - The function `featureSelection_variance` takes two parameters: `X` (the data matrix) and `thrd` (the threshold for variance).\n",
            "   - It creates an instance of `VarianceThreshold` with the specified threshold.\n",
            "   - The function fits the selector to `X` and transforms it, selecting features based on their variance being greater than or equal to the threshold.\n",
            "   - It returns the transformed data matrix `X_selected` and a boolean mask indicating which features were selected.\n",
            "\n",
            "4. **Example Usage of Feature Selection Function**:\n",
            "   - A sample data matrix `X` is defined with three rows and four columns.\n",
            "   - An instance of `VarianceThreshold` is created without specifying a threshold, so it uses the default threshold (0).\n",
            "   - The function `fit_transform` is called on this selector with the sample data `X`, which selects features based on their variance.\n",
            "   - The variances of all features in the original data are printed.\n",
            "\n",
            "In summary, the code demonstrates how to use `VarianceThreshold` for feature selection by filtering out features with low variance. It also shows how to apply this method to both synthetic and sample data matrices.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 7\n",
            "Entry: {'code': \"from my_multi_main3 import main\\nimport numpy as np\\nimport argparse\\nimport time\\n\\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\\n                    help='input batch size for training (default: 64)')\\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\\n                    help='input batch size for testing (default: 1000)')\\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\\n                    help='number of epochs to train (default: 10)')\\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\\n                    help='learning rate (default: 0.01)')\\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\\n                    help='SGD momentum (default: 0.5)')\\nparser.add_argument('--no-cuda', action='store_true', default=False,\\n                    help='disables CUDA training')\\nparser.add_argument('--seed', type=int, default=1, metavar='S',\\n                    help='random seed (default: 1)')\\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\\n                    help='how many batches to wait before logging training status')\\nparser.add_argument('--save-model', action='store_true', default=False,\\n                    help='For Saving the current Model')\\nparser.add_argument('--norm-flag', type=bool, default=False,\\n                    help='Triggering the Layer Normalization flag for attention scores')\\nparser.add_argument('--gamma', type=float, default=None,\\n                    help='Controlling the sparisty of gfusedmax/sparsemax, the smaller, the more sparse')\\nparser.add_argument('--lam', type=float, default=1.0,\\n                    help='Lambda: Controlling the smoothness of gfusedmax, the larger, the smoother')\\nparser.add_argument('--max-type', type=str, default='softmax',choices=['softmax','sparsemax','gfusedmax'],\\n                    help='mapping function in attention')\\nparser.add_argument('--optim-type', type=str, default='SGD',choices=['SGD','Adam'],\\n                    help='mapping function in attention')\\nparser.add_argument('--head-cnt', type=int, default=2, metavar='S', choices=[1,2,4,5,10],\\n                    help='Number of heads for attention (default: 1)')\\n\\nargs = parser.parse_args()\\n\\nhyperparameter_choices = {\\n    'lr':list(10**np.arange(-4,-1,0.5)),\\n    'norm_flag': [True,False],\\n    'gamma':list(10**np.arange(-1,3,0.5))+[None,],\\n    'lam':list(10**np.arange(-2,2,0.5)),\\n    'max_type':['softmax','sparsemax','gfusedmax'],\\n    \\n    'optim_type':['SGD','Adam'],\\n    'head_cnt':[1,2,4,5,10,20]\\n}\\n\\nparam_num = 25\\nrecord = np.zeros([param_num,len(hyperparameter_choices)+1])\\nrecord_name = 'record3_multi_%s.csv'%time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime())\\nfor n in range(param_num):\\n    for param_index,(k,v) in enumerate(hyperparameter_choices.items()):\\n        print(param_index,k)\\n        value_index = np.random.choice(len(v))\\n        if isinstance(v[value_index],str) or isinstance(v[value_index],bool) or v[value_index] is None:\\n            record[n,param_index] = value_index\\n        else:\\n            record[n,param_index] = v[value_index]\\n        setattr(args,k,v[value_index])\\n    record[n,-1] = main(args)\\n    np.savetxt(record_name, record, delimiter=',')\\n\\n\\n\\n\", 'summary': \"This Python script is designed to perform hyperparameter tuning for a machine learning model using the MNIST dataset. Here's a summary of its functionality:\\n\\n1. **Argument Parsing**: The script uses `argparse` to define and parse command-line arguments that control various parameters such as batch size, number of epochs, learning rate, etc.\\n\\n2. **Hyperparameter Choices**: A dictionary named `hyperparameter_choices` is defined to store possible values for each hyperparameter. This includes choices for learning rate, normalization flag, gamma value, lambda value, attention mapping function type, optimizer type, and number of attention heads.\\n\\n3. **Record Initialization**: An array `record` is initialized to store the results of different hyperparameter combinations along with their corresponding performance metrics.\\n\\n4. **Hyperparameter Sampling**: The script iterates over a specified number of parameter sets (`param_num`). For each set, it randomly selects values from the predefined choices for each hyperparameter and updates the `args` object accordingly.\\n\\n5. **Model Training and Evaluation**: For each combination of hyperparameters, the script calls the `main` function (from `my_multi_main3.py`) to train and evaluate the model. The performance metric is stored in the `record`.\\n\\n6. **Saving Results**: After all combinations are evaluated, the results are saved to a CSV file named with a timestamp.\\n\\n### Key Points:\\n- **Randomized Search**: The script uses random sampling from predefined ranges or lists of values for each hyperparameter.\\n- **Performance Tracking**: It tracks the performance metric (likely accuracy) for each combination of hyperparameters.\\n- **Logging and Saving**: Results are logged to the console and saved to a CSV file for later analysis.\\n\\nThis approach is useful for systematically exploring different configurations of hyperparameters to find the best settings for a given model and dataset.\"}\n",
            "Summary: This Python script is designed to perform hyperparameter tuning for a machine learning model using the MNIST dataset. Here's a summary of its functionality:\n",
            "\n",
            "1. **Argument Parsing**: The script uses `argparse` to define and parse command-line arguments that control various parameters such as batch size, number of epochs, learning rate, etc.\n",
            "\n",
            "2. **Hyperparameter Choices**: A dictionary named `hyperparameter_choices` is defined to store possible values for each hyperparameter. This includes choices for learning rate, normalization flag, gamma value, lambda value, attention mapping function type, optimizer type, and number of attention heads.\n",
            "\n",
            "3. **Record Initialization**: An array `record` is initialized to store the results of different hyperparameter combinations along with their corresponding performance metrics.\n",
            "\n",
            "4. **Hyperparameter Sampling**: The script iterates over a specified number of parameter sets (`param_num`). For each set, it randomly selects values from the predefined choices for each hyperparameter and updates the `args` object accordingly.\n",
            "\n",
            "5. **Model Training and Evaluation**: For each combination of hyperparameters, the script calls the `main` function (from `my_multi_main3.py`) to train and evaluate the model. The performance metric is stored in the `record`.\n",
            "\n",
            "6. **Saving Results**: After all combinations are evaluated, the results are saved to a CSV file named with a timestamp.\n",
            "\n",
            "### Key Points:\n",
            "- **Randomized Search**: The script uses random sampling from predefined ranges or lists of values for each hyperparameter.\n",
            "- **Performance Tracking**: It tracks the performance metric (likely accuracy) for each combination of hyperparameters.\n",
            "- **Logging and Saving**: Results are logged to the console and saved to a CSV file for later analysis.\n",
            "\n",
            "This approach is useful for systematically exploring different configurations of hyperparameters to find the best settings for a given model and dataset.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 8\n",
            "Entry: {'code': 'from __future__ import print_function, absolute_import\\n\\nimport h5py\\n\\nfrom spiker import log\\n\\nlogger = log.get_logger(\"data-hdf5\", log.DEBUG)\\n\\n\\ndef init_hdf5(file_path, mode=\"w\", cam_type=\"davis\"):\\n    \\n    if mode == \"w\":\\n        dataset = h5py.File(file_path, mode=mode)\\n        dataset.create_group(\"dvs\")\\n        dataset.create_group(\"extra\")\\n        if cam_type == \"davis\":\\n            dataset.create_group(\"aps\")\\n            dataset.create_group(\"imu\")\\n    elif mode == \"r\":\\n        dataset = h5py.File(file_path, mode=mode)\\n\\n    return dataset\\n', 'summary': 'This Python code defines a function `init_hdf5` that initializes an HDF5 file for storing data. The function takes three parameters: `file_path`, `mode`, and `cam_type`. \\n\\n- `file_path`: The path to the HDF5 file.\\n- `mode`: The mode in which the file is opened, either \"w\" (write mode) or \"r\" (read mode).\\n- `cam_type`: A string indicating the type of camera, defaulting to \"davis\".\\n\\nThe function uses the `h5py` library to handle HDF5 files. It also imports a logger from the `spiker.log` module.\\n\\nHere\\'s what happens in the function:\\n\\n1. If the mode is \"w\" (write mode):\\n   - The function opens an HDF5 file at the specified path.\\n   - It creates three groups: \"dvs\", \"extra\", and \"aps\" if the camera type is \"davis\".\\n   - It also creates another group called \"imu\".\\n\\n2. If the mode is \"r\" (read mode):\\n   - The function opens an HDF5 file at the specified path in read mode.\\n\\nThe function returns the dataset object, which can be used to interact with the HDF5 file.\\n\\nThis setup is typically used for storing data from a camera system, where different types of data (like DVS events, extra information, and sensor data) are organized into separate groups within the HDF5 file.'}\n",
            "Summary: This Python code defines a function `init_hdf5` that initializes an HDF5 file for storing data. The function takes three parameters: `file_path`, `mode`, and `cam_type`. \n",
            "\n",
            "- `file_path`: The path to the HDF5 file.\n",
            "- `mode`: The mode in which the file is opened, either \"w\" (write mode) or \"r\" (read mode).\n",
            "- `cam_type`: A string indicating the type of camera, defaulting to \"davis\".\n",
            "\n",
            "The function uses the `h5py` library to handle HDF5 files. It also imports a logger from the `spiker.log` module.\n",
            "\n",
            "Here's what happens in the function:\n",
            "\n",
            "1. If the mode is \"w\" (write mode):\n",
            "   - The function opens an HDF5 file at the specified path.\n",
            "   - It creates three groups: \"dvs\", \"extra\", and \"aps\" if the camera type is \"davis\".\n",
            "   - It also creates another group called \"imu\".\n",
            "\n",
            "2. If the mode is \"r\" (read mode):\n",
            "   - The function opens an HDF5 file at the specified path in read mode.\n",
            "\n",
            "The function returns the dataset object, which can be used to interact with the HDF5 file.\n",
            "\n",
            "This setup is typically used for storing data from a camera system, where different types of data (like DVS events, extra information, and sensor data) are organized into separate groups within the HDF5 file.\n",
            "\n",
            "Processing batch batch_0.json, entry ID: 9\n",
            "Entry: {'code': \"import flatbuffers\\n\\nclass FloatingPoint(object):\\n    __slots__ = ['_tab']\\n\\n    @classmethod\\n    def GetRootAsFloatingPoint(cls, buf, offset):\\n        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)\\n        x = FloatingPoint()\\n        x.Init(buf, n + offset)\\n        return x\\n\\n    \\n    def Init(self, buf, pos):\\n        self._tab = flatbuffers.table.Table(buf, pos)\\n\\n    \\n    def Precision(self):\\n        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))\\n        if o != 0:\\n            return self._tab.Get(flatbuffers.number_types.Int16Flags, o + self._tab.Pos)\\n        return 0\\n\\ndef FloatingPointStart(builder): builder.StartObject(1)\\ndef FloatingPointAddPrecision(builder, precision): builder.PrependInt16Slot(0, precision, 0)\\ndef FloatingPointEnd(builder): return builder.EndObject()\\n\", 'summary': \"This Python code defines a class `FloatingPoint` that represents a floating-point number with a specific precision. It uses the FlatBuffers library to serialize and deserialize the data efficiently.\\n\\nHere's a breakdown of the key components:\\n\\n1. **Class Definition**:\\n   - The `FloatingPoint` class has a single attribute `_tab`, which is used to store the table data from FlatBuffers.\\n\\n2. **Class Methods**:\\n   - `GetRootAsFloatingPoint`: This method takes a buffer and an offset, decodes the buffer into a `FloatingPoint` object, and returns it.\\n   - `Init`: This method initializes the `_tab` attribute with the provided buffer and position.\\n\\n3. **Attribute Accessors**:\\n   - `Precision`: This method retrieves the precision of the floating-point number from the table. If the offset is not zero, it reads the int16 value at that offset; otherwise, it returns 0.\\n\\n4. **FlatBuffers Builder Methods**:\\n   - `FloatingPointStart`, `FloatingPointAddPrecision`, and `FloatingPointEnd`: These methods are used to construct a `FloatingPoint` object using the FlatBuffers builder API.\\n     - `FloatingPointStart`: Starts building a new `FloatingPoint` object.\\n     - `FloatingPointAddPrecision`: Adds a precision value to the `FloatingPoint` object being built.\\n     - `FloatingPointEnd`: Completes the construction of the `FloatingPoint` object and returns its offset.\\n\\nThis code is useful for applications that need to serialize floating-point numbers with specific precision in a compact binary format, leveraging FlatBuffers for efficient data handling.\"}\n",
            "Summary: This Python code defines a class `FloatingPoint` that represents a floating-point number with a specific precision. It uses the FlatBuffers library to serialize and deserialize the data efficiently.\n",
            "\n",
            "Here's a breakdown of the key components:\n",
            "\n",
            "1. **Class Definition**:\n",
            "   - The `FloatingPoint` class has a single attribute `_tab`, which is used to store the table data from FlatBuffers.\n",
            "\n",
            "2. **Class Methods**:\n",
            "   - `GetRootAsFloatingPoint`: This method takes a buffer and an offset, decodes the buffer into a `FloatingPoint` object, and returns it.\n",
            "   - `Init`: This method initializes the `_tab` attribute with the provided buffer and position.\n",
            "\n",
            "3. **Attribute Accessors**:\n",
            "   - `Precision`: This method retrieves the precision of the floating-point number from the table. If the offset is not zero, it reads the int16 value at that offset; otherwise, it returns 0.\n",
            "\n",
            "4. **FlatBuffers Builder Methods**:\n",
            "   - `FloatingPointStart`, `FloatingPointAddPrecision`, and `FloatingPointEnd`: These methods are used to construct a `FloatingPoint` object using the FlatBuffers builder API.\n",
            "     - `FloatingPointStart`: Starts building a new `FloatingPoint` object.\n",
            "     - `FloatingPointAddPrecision`: Adds a precision value to the `FloatingPoint` object being built.\n",
            "     - `FloatingPointEnd`: Completes the construction of the `FloatingPoint` object and returns its offset.\n",
            "\n",
            "This code is useful for applications that need to serialize floating-point numbers with specific precision in a compact binary format, leveraging FlatBuffers for efficient data handling.\n",
            "\n",
            "Processed batch written to batches/batch_0_processed.json\n",
            "Processing batch 1\n",
            "Processing batch batch_1.json, entry ID: 0\n",
            "Entry: {'code': 'def sub(x, y):\\n    f\\n\\n\\nclass Light:\\n    pass\\n\\na = Light()\\nb = Ligth()\\n', 'summary': 'The provided Python code consists of two parts: a function definition and a class definition with some object instantiation.\\n\\n1. **Function Definition**:\\n   - The function `sub` is defined to take two parameters, `x` and `y`.\\n   - Inside the function, there is a single character `f`, but it does not complete any statement or expression. This suggests that the function might be incomplete or intended for further development.\\n\\n2. **Class Definition**:\\n   - A class named `Light` is defined using the `class` keyword.\\n   - The class `Light` currently has no attributes or methods defined within its body, indicated by the `pass` statement. The `pass` statement is a placeholder that does nothing but allows the syntax to be valid.\\n\\n3. **Object Instantiation**:\\n   - An object named `a` is created from the `Light` class.\\n   - There seems to be a typo in the code where `b = Ligth()` should likely be `b = Light()`. This creates another object named `b` from the `Light` class.\\n\\nIn summary, the code defines an incomplete function `sub`, a class `Light` with no functionality, and attempts to create two objects of the `Light` class.'}\n",
            "Summary: The provided Python code consists of two parts: a function definition and a class definition with some object instantiation.\n",
            "\n",
            "1. **Function Definition**:\n",
            "   - The function `sub` is defined to take two parameters, `x` and `y`.\n",
            "   - Inside the function, there is a single character `f`, but it does not complete any statement or expression. This suggests that the function might be incomplete or intended for further development.\n",
            "\n",
            "2. **Class Definition**:\n",
            "   - A class named `Light` is defined using the `class` keyword.\n",
            "   - The class `Light` currently has no attributes or methods defined within its body, indicated by the `pass` statement. The `pass` statement is a placeholder that does nothing but allows the syntax to be valid.\n",
            "\n",
            "3. **Object Instantiation**:\n",
            "   - An object named `a` is created from the `Light` class.\n",
            "   - There seems to be a typo in the code where `b = Ligth()` should likely be `b = Light()`. This creates another object named `b` from the `Light` class.\n",
            "\n",
            "In summary, the code defines an incomplete function `sub`, a class `Light` with no functionality, and attempts to create two objects of the `Light` class.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 1\n",
            "Entry: {'code': 'from __future__ import unicode_literals, division, absolute_import\\n\\nimport time\\nimport logging\\nfrom collections import deque\\ntry:\\n    from UserDict import DictMixin\\nexcept ImportError:\\n    from collections import Mapping as DictMixin\\n\\nimport six\\nfrom six import iteritems\\nfrom six.moves import cPickle\\n\\n\\nclass BaseCounter(object):\\n\\n    def __init__(self):\\n        raise NotImplementedError\\n\\n    def event(self, value=1):\\n        \\n        raise NotImplementedError\\n\\n    def value(self, value):\\n        \\n        raise NotImplementedError\\n\\n    @property\\n    def avg(self):\\n        \\n        raise NotImplementedError\\n\\n    @property\\n    def sum(self):\\n        \\n        raise NotImplementedError\\n\\n    def empty(self):\\n        \\n        raise NotImplementedError\\n\\n\\nclass TotalCounter(BaseCounter):\\n    \\n\\n    def __init__(self):\\n        self.cnt = 0\\n\\n    def event(self, value=1):\\n        self.cnt += value\\n\\n    def value(self, value):\\n        self.cnt = value\\n\\n    @property\\n    def avg(self):\\n        return self.cnt\\n\\n    @property\\n    def sum(self):\\n        return self.cnt\\n\\n    def empty(self):\\n        return self.cnt == 0\\n\\n\\nclass AverageWindowCounter(BaseCounter):\\n    \\n\\n    def __init__(self, window_size=300):\\n        self.window_size = window_size\\n        self.values = deque(maxlen=window_size)\\n\\n    def event(self, value=1):\\n        self.values.append(value)\\n\\n    value = event\\n\\n    @property\\n    def avg(self):\\n        return self.sum / len(self.values)\\n\\n    @property\\n    def sum(self):\\n        return sum(self.values)\\n\\n    def empty(self):\\n        if not self.values:\\n            return True\\n\\n\\nclass TimebaseAverageWindowCounter(BaseCounter):\\n    \\n\\n    def __init__(self, window_size=30, window_interval=10):\\n        self.max_window_size = window_size\\n        self.window_size = 0\\n        self.window_interval = window_interval\\n        self.values = deque(maxlen=window_size)\\n        self.times = deque(maxlen=window_size)\\n\\n        self.cache_value = 0\\n        self.cache_start = None\\n        self._first_data_time = None\\n\\n    def event(self, value=1):\\n        now = time.time()\\n        if self._first_data_time is None:\\n            self._first_data_time = now\\n\\n        if self.cache_start is None:\\n            self.cache_value = value\\n            self.cache_start = now\\n        elif now - self.cache_start > self.window_interval:\\n            self.values.append(self.cache_value)\\n            self.times.append(self.cache_start)\\n            self.on_append(self.cache_value, self.cache_start)\\n            self.cache_value = value\\n            self.cache_start = now\\n        else:\\n            self.cache_value += value\\n        return self\\n\\n    def value(self, value):\\n        self.cache_value = value\\n\\n    def _trim_window(self):\\n        now = time.time()\\n        if self.cache_start and now - self.cache_start > self.window_interval:\\n            self.values.append(self.cache_value)\\n            self.times.append(self.cache_start)\\n            self.on_append(self.cache_value, self.cache_start)\\n            self.cache_value = 0\\n            self.cache_start = None\\n\\n        if self.window_size != self.max_window_size and self._first_data_time is not None:\\n            time_passed = now - self._first_data_time\\n            self.window_size = min(self.max_window_size, time_passed / self.window_interval)\\n        window_limit = now - self.window_size * self.window_interval\\n        while self.times and self.times[0] < window_limit:\\n            self.times.popleft()\\n            self.values.popleft()\\n\\n    @property\\n    def avg(self):\\n        sum = float(self.sum)\\n        if not self.window_size:\\n            return 0\\n        return sum / self.window_size / self.window_interval\\n\\n    @property\\n    def sum(self):\\n        self._trim_window()\\n        return sum(self.values) + self.cache_value\\n\\n    def empty(self):\\n        self._trim_window()\\n        if not self.values and not self.cache_start:\\n            return True\\n\\n    def on_append(self, value, time):\\n        pass\\n\\n\\nclass CounterValue(DictMixin):\\n    \\n\\n    def __init__(self, manager, keys):\\n        self.manager = manager\\n        self._keys = keys\\n\\n    def __getitem__(self, key):\\n        if key == \\'__value__\\':\\n            key = self._keys\\n            return self.manager.counters[key]\\n        else:\\n            key = self._keys + (key, )\\n\\n        available_keys = []\\n        for _key in self.manager.counters:\\n            if _key[:len(key)] == key:\\n                available_keys.append(_key)\\n\\n        if len(available_keys) == 0:\\n            raise KeyError\\n        elif len(available_keys) == 1:\\n            if available_keys[0] == key:\\n                return self.manager.counters[key]\\n            else:\\n                return CounterValue(self.manager, key)\\n        else:\\n            return CounterValue(self.manager, key)\\n\\n    def __len__(self):\\n        return len(self.keys())\\n\\n    def __iter__(self):\\n        return iter(self.keys())\\n\\n    def __contains__(self, key):\\n        return key in self.keys()\\n\\n    def keys(self):\\n        result = set()\\n        for key in self.manager.counters:\\n            if key[:len(self._keys)] == self._keys:\\n                key = key[len(self._keys):]\\n                result.add(key[0] if key else \\'__value__\\')\\n        return result\\n\\n    def to_dict(self, get_value=None):\\n        \\n        result = {}\\n        for key, value in iteritems(self):\\n            if isinstance(value, BaseCounter):\\n                if get_value is not None:\\n                    value = getattr(value, get_value)\\n                result[key] = value\\n            else:\\n                result[key] = value.to_dict(get_value)\\n        return result\\n\\n\\nclass CounterManager(DictMixin):\\n    \\n\\n    def __init__(self, cls=TimebaseAverageWindowCounter):\\n        \\n        self.cls = cls\\n        self.counters = {}\\n\\n    def event(self, key, value=1):\\n        \\n        if isinstance(key, six.string_types):\\n            key = (key, )\\n        assert isinstance(key, tuple), \"event key type error\"\\n        if key not in self.counters:\\n            self.counters[key] = self.cls()\\n        self.counters[key].event(value)\\n        return self\\n\\n    def value(self, key, value=1):\\n        \\n        if isinstance(key, six.string_types):\\n            key = (key, )\\n        assert isinstance(key, tuple), \"event key type error\"\\n        if key not in self.counters:\\n            self.counters[key] = self.cls()\\n        self.counters[key].value(value)\\n        return self\\n\\n    def trim(self):\\n        \\n        for key, value in list(iteritems(self.counters)):\\n            if value.empty():\\n                del self.counters[key]\\n\\n    def __getitem__(self, key):\\n        key = (key, )\\n        available_keys = []\\n        for _key in self.counters:\\n            if _key[:len(key)] == key:\\n                available_keys.append(_key)\\n\\n        if len(available_keys) == 0:\\n            raise KeyError\\n        elif len(available_keys) == 1:\\n            if available_keys[0] == key:\\n                return self.counters[key]\\n            else:\\n                return CounterValue(self, key)\\n        else:\\n            return CounterValue(self, key)\\n\\n    def __iter__(self):\\n        return iter(self.keys())\\n\\n    def __len__(self):\\n        return len(self.keys())\\n\\n    def keys(self):\\n        result = set()\\n        for key in self.counters:\\n            result.add(key[0] if key else ())\\n        return result\\n\\n    def to_dict(self, get_value=None):\\n        \\n        self.trim()\\n        result = {}\\n        for key, value in iteritems(self):\\n            if isinstance(value, BaseCounter):\\n                if get_value is not None:\\n                    value = getattr(value, get_value)\\n                result[key] = value\\n            else:\\n                result[key] = value.to_dict(get_value)\\n        return result\\n\\n    def dump(self, filename):\\n        \\n        try:\\n            with open(filename, \\'wb\\') as fp:\\n                cPickle.dump(self.counters, fp)\\n        except:\\n            logging.error(\"can\\'t dump counter to file: %s\" % filename)\\n            return False\\n        return True\\n\\n    def load(self, filename):\\n        \\n        try:\\n            with open(filename) as fp:\\n                self.counters = cPickle.load(fp)\\n        except:\\n            logging.debug(\"can\\'t load counter from file: %s\" % filename)\\n            return False\\n        return True\\n', 'summary': 'This Python code defines a set of classes for managing and manipulating counters. The main components are:\\n\\n1. **BaseCounter**: An abstract base class that outlines the methods any counter should implement:\\n   - `event(value=1)`: Records an event with an optional value.\\n   - `value(value)`: Sets the current value to a specific number.\\n   - `avg`: Property to get the average of recorded values.\\n   - `sum`: Property to get the sum of recorded values.\\n   - `empty()`: Checks if there are no recorded events.\\n\\n2. **TotalCounter**: A concrete implementation of `BaseCounter` that simply counts the total number of events or sets a specific value.\\n\\n3. **AverageWindowCounter**: Extends `BaseCounter` to keep track of an average over a fixed-size window of events. It uses a deque to store recent values and calculates the average based on these values.\\n\\n4. **TimebaseAverageWindowCounter**: Similar to `AverageWindowCounter`, but it also considers time intervals, ensuring that the average is calculated over a sliding window of time rather than just a number of events.\\n\\n5. **CounterValue**: A helper class used for nested counter access, allowing you to access counters through a hierarchical key structure.\\n\\n6. **CounterManager**: Manages multiple counters, providing methods to record events, set values, and retrieve averages or sums. It also includes functionality to trim empty counters and serialize/deserialize the state of all counters using `cPickle`.\\n\\nThe code is designed to be flexible, allowing for different types of counters (e.g., total count, average over a window) and providing tools for managing and persisting these counters in a hierarchical structure.'}\n",
            "Summary: This Python code defines a set of classes for managing and manipulating counters. The main components are:\n",
            "\n",
            "1. **BaseCounter**: An abstract base class that outlines the methods any counter should implement:\n",
            "   - `event(value=1)`: Records an event with an optional value.\n",
            "   - `value(value)`: Sets the current value to a specific number.\n",
            "   - `avg`: Property to get the average of recorded values.\n",
            "   - `sum`: Property to get the sum of recorded values.\n",
            "   - `empty()`: Checks if there are no recorded events.\n",
            "\n",
            "2. **TotalCounter**: A concrete implementation of `BaseCounter` that simply counts the total number of events or sets a specific value.\n",
            "\n",
            "3. **AverageWindowCounter**: Extends `BaseCounter` to keep track of an average over a fixed-size window of events. It uses a deque to store recent values and calculates the average based on these values.\n",
            "\n",
            "4. **TimebaseAverageWindowCounter**: Similar to `AverageWindowCounter`, but it also considers time intervals, ensuring that the average is calculated over a sliding window of time rather than just a number of events.\n",
            "\n",
            "5. **CounterValue**: A helper class used for nested counter access, allowing you to access counters through a hierarchical key structure.\n",
            "\n",
            "6. **CounterManager**: Manages multiple counters, providing methods to record events, set values, and retrieve averages or sums. It also includes functionality to trim empty counters and serialize/deserialize the state of all counters using `cPickle`.\n",
            "\n",
            "The code is designed to be flexible, allowing for different types of counters (e.g., total count, average over a window) and providing tools for managing and persisting these counters in a hierarchical structure.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 2\n",
            "Entry: {'code': 'from typing import List, Optional, Union\\n\\nimport numpy as np\\nfrom PIL import Image\\n\\nfrom ...feature_extraction_utils import BatchFeature, FeatureExtractionMixin\\nfrom ...file_utils import TensorType\\nfrom ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, ImageFeatureExtractionMixin, is_torch_tensor\\nfrom ...utils import logging\\n\\n\\nlogger = logging.get_logger(__name__)\\n\\n\\nclass ViTFeatureExtractor(FeatureExtractionMixin, ImageFeatureExtractionMixin):\\n    r\\n\\n    model_input_names = [\"pixel_values\"]\\n\\n    def __init__(\\n        self,\\n        do_resize=True,\\n        size=224,\\n        resample=Image.BILINEAR,\\n        do_normalize=True,\\n        image_mean=None,\\n        image_std=None,\\n        **kwargs\\n    ):\\n        super().__init__(**kwargs)\\n        self.do_resize = do_resize\\n        self.size = size\\n        self.resample = resample\\n        self.do_normalize = do_normalize\\n        self.image_mean = image_mean if image_mean is not None else IMAGENET_STANDARD_MEAN\\n        self.image_std = image_std if image_std is not None else IMAGENET_STANDARD_STD\\n\\n    def __call__(\\n        self,\\n        images: Union[\\n            Image.Image, np.ndarray, \"torch.Tensor\", List[Image.Image], List[np.ndarray], List[\"torch.Tensor\"]  \\n        ],\\n        return_tensors: Optional[Union[str, TensorType]] = None,\\n        **kwargs\\n    ) -> BatchFeature:\\n        \\n        \\n        valid_images = False\\n\\n        \\n        if isinstance(images, (Image.Image, np.ndarray)) or is_torch_tensor(images):\\n            valid_images = True\\n        elif isinstance(images, (list, tuple)):\\n            if len(images) == 0 or isinstance(images[0], (Image.Image, np.ndarray)) or is_torch_tensor(images[0]):\\n                valid_images = True\\n\\n        if not valid_images:\\n            raise ValueError(\\n                \"Images must of type `PIL.Image.Image`, `np.ndarray` or `torch.Tensor` (single example),\"\\n                \"`List[PIL.Image.Image]`, `List[np.ndarray]` or `List[torch.Tensor]` (batch of examples).\"\\n            )\\n\\n        is_batched = bool(\\n            isinstance(images, (list, tuple))\\n            and (isinstance(images[0], (Image.Image, np.ndarray)) or is_torch_tensor(images[0]))\\n        )\\n\\n        if not is_batched:\\n            images = [images]\\n\\n        \\n        if self.do_resize and self.size is not None:\\n            images = [self.resize(image=image, size=self.size, resample=self.resample) for image in images]\\n        if self.do_normalize:\\n            images = [self.normalize(image=image, mean=self.image_mean, std=self.image_std) for image in images]\\n\\n        \\n        data = {\"pixel_values\": images}\\n        encoded_inputs = BatchFeature(data=data, tensor_type=return_tensors)\\n\\n        return encoded_inputs\\n', 'summary': 'This Python code defines a class `ViTFeatureExtractor` that inherits from both `FeatureExtractionMixin` and `ImageFeatureExtractionMixin`. The class is designed to preprocess images for use with Vision Transformer (ViT) models. Here\\'s a summary of its key functionalities:\\n\\n1. **Initialization (`__init__` method)**:\\n   - Sets up parameters such as resizing, normalization, and default mean/std values.\\n   - Initializes the base classes using `super().__init__(**kwargs)`.\\n\\n2. **Main Call Method (`__call__` method)**:\\n   - Validates that the input images are of valid types (`PIL.Image.Image`, `np.ndarray`, or `torch.Tensor`).\\n   - Checks if the input is a single image or a batch of images.\\n   - Resizes the images if specified and resizing parameters are provided.\\n   - Normalizes the images using the specified mean and standard deviation if normalization is enabled.\\n   - Constructs a dictionary with the preprocessed images under the key `\"pixel_values\"`.\\n   - Creates a `BatchFeature` object containing the preprocessed data, optionally converting it to a specific tensor type.\\n\\n3. **Utility Methods**:\\n   - The class uses methods like `resize` and `normalize` from its base classes to perform image transformations.\\n   - These methods are not explicitly defined in this snippet but are assumed to be part of the base mixins.\\n\\n4. **Logging**:\\n   - Uses a logger to log messages, which is initialized at the module level using `logging.get_logger(__name__)`.\\n\\nIn summary, this class provides a comprehensive pipeline for preprocessing images for ViT models, handling both single and batch inputs, and optionally resizing and normalizing them according to specified parameters.'}\n",
            "Summary: This Python code defines a class `ViTFeatureExtractor` that inherits from both `FeatureExtractionMixin` and `ImageFeatureExtractionMixin`. The class is designed to preprocess images for use with Vision Transformer (ViT) models. Here's a summary of its key functionalities:\n",
            "\n",
            "1. **Initialization (`__init__` method)**:\n",
            "   - Sets up parameters such as resizing, normalization, and default mean/std values.\n",
            "   - Initializes the base classes using `super().__init__(**kwargs)`.\n",
            "\n",
            "2. **Main Call Method (`__call__` method)**:\n",
            "   - Validates that the input images are of valid types (`PIL.Image.Image`, `np.ndarray`, or `torch.Tensor`).\n",
            "   - Checks if the input is a single image or a batch of images.\n",
            "   - Resizes the images if specified and resizing parameters are provided.\n",
            "   - Normalizes the images using the specified mean and standard deviation if normalization is enabled.\n",
            "   - Constructs a dictionary with the preprocessed images under the key `\"pixel_values\"`.\n",
            "   - Creates a `BatchFeature` object containing the preprocessed data, optionally converting it to a specific tensor type.\n",
            "\n",
            "3. **Utility Methods**:\n",
            "   - The class uses methods like `resize` and `normalize` from its base classes to perform image transformations.\n",
            "   - These methods are not explicitly defined in this snippet but are assumed to be part of the base mixins.\n",
            "\n",
            "4. **Logging**:\n",
            "   - Uses a logger to log messages, which is initialized at the module level using `logging.get_logger(__name__)`.\n",
            "\n",
            "In summary, this class provides a comprehensive pipeline for preprocessing images for ViT models, handling both single and batch inputs, and optionally resizing and normalizing them according to specified parameters.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 3\n",
            "Entry: {'code': 'UNKNOWN = -1\\n\\ndef read_val():\\n    return int(input())\\n\\ndef read_row():\\n    return list(map(int, input().split()))\\n\\ndef read_grid():\\n    return [read_row() for _ in range(read_val())]\\n\\ndef make_blank_row(i):\\n    return [UNKNOWN] * i\\n\\ndef make_blank_grid(n):\\n    return [make_blank_row(i) for i in range(1, n + 1)]\\n\\ndef compute_max_path_sum(grid):\\n    memo = make_blank_grid(len(grid))\\n    \\n    def dfs(i, j):\\n        if i == len(grid):\\n            return 0\\n        \\n        if memo[i][j] == UNKNOWN:\\n            memo[i][j] = grid[i][j] + max(dfs(i + 1, j), dfs(i + 1, j + 1))\\n        \\n        return memo[i][j]\\n    \\n    return dfs(0, 0)\\n\\nfor t in range(read_val()):\\n    print(compute_max_path_sum(read_grid()))\\n', 'summary': \"This Python code is designed to solve a problem where you need to find the maximum path sum in a grid. Here's a summary of what each part of the code does:\\n\\n1. **Constants and Functions**:\\n   - `UNKNOWN` is set to `-1`, which is used as a placeholder for uncomputed values.\\n   - `read_val()` reads an integer from input, presumably the number of test cases or rows in the grid.\\n   - `read_row()` reads a line of integers from input, splitting them by spaces and converting each to an integer. This represents a row in the grid.\\n   - `read_grid()` uses `read_row()` to read multiple rows (specified by `read_val()`) and constructs a 2D list representing the grid.\\n\\n2. **Grid Initialization**:\\n   - `make_blank_row(i)` creates a row of length `i` filled with `UNKNOWN`.\\n   - `make_blank_grid(n)` creates an `n x n` grid where each row is initialized using `make_blank_row`.\\n\\n3. **Dynamic Programming for Path Sum Calculation**:\\n   - `compute_max_path_sum(grid)` initializes a memoization table (`memo`) of the same size as the input grid, filled with `UNKNOWN`.\\n   - The inner function `dfs(i, j)` uses depth-first search (DFS) to calculate the maximum path sum starting from cell `(i, j)`. If the value at `(i, j)` in `memo` is still `UNKNOWN`, it computes the sum by adding the current grid value and the maximum of the sums from the two possible next cells (`(i+1, j)` and `(i+1, j+1)`). This result is stored in `memo[i][j]`.\\n   - The function returns the result of `dfs(0, 0)`, which computes the maximum path sum starting from the top-left corner of the grid.\\n\\n4. **Main Execution Loop**:\\n   - The code reads the number of test cases (`t`) using `read_val()`.\\n   - For each test case, it reads a grid and prints the result of `compute_max_path_sum(read_grid())`, which is the maximum path sum for that grid.\\n\\nThis code effectively uses dynamic programming with memoization to efficiently compute the maximum path sum in a grid, handling multiple test cases as specified.\"}\n",
            "Summary: This Python code is designed to solve a problem where you need to find the maximum path sum in a grid. Here's a summary of what each part of the code does:\n",
            "\n",
            "1. **Constants and Functions**:\n",
            "   - `UNKNOWN` is set to `-1`, which is used as a placeholder for uncomputed values.\n",
            "   - `read_val()` reads an integer from input, presumably the number of test cases or rows in the grid.\n",
            "   - `read_row()` reads a line of integers from input, splitting them by spaces and converting each to an integer. This represents a row in the grid.\n",
            "   - `read_grid()` uses `read_row()` to read multiple rows (specified by `read_val()`) and constructs a 2D list representing the grid.\n",
            "\n",
            "2. **Grid Initialization**:\n",
            "   - `make_blank_row(i)` creates a row of length `i` filled with `UNKNOWN`.\n",
            "   - `make_blank_grid(n)` creates an `n x n` grid where each row is initialized using `make_blank_row`.\n",
            "\n",
            "3. **Dynamic Programming for Path Sum Calculation**:\n",
            "   - `compute_max_path_sum(grid)` initializes a memoization table (`memo`) of the same size as the input grid, filled with `UNKNOWN`.\n",
            "   - The inner function `dfs(i, j)` uses depth-first search (DFS) to calculate the maximum path sum starting from cell `(i, j)`. If the value at `(i, j)` in `memo` is still `UNKNOWN`, it computes the sum by adding the current grid value and the maximum of the sums from the two possible next cells (`(i+1, j)` and `(i+1, j+1)`). This result is stored in `memo[i][j]`.\n",
            "   - The function returns the result of `dfs(0, 0)`, which computes the maximum path sum starting from the top-left corner of the grid.\n",
            "\n",
            "4. **Main Execution Loop**:\n",
            "   - The code reads the number of test cases (`t`) using `read_val()`.\n",
            "   - For each test case, it reads a grid and prints the result of `compute_max_path_sum(read_grid())`, which is the maximum path sum for that grid.\n",
            "\n",
            "This code effectively uses dynamic programming with memoization to efficiently compute the maximum path sum in a grid, handling multiple test cases as specified.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 4\n",
            "Entry: {'code': 'import platform\\n\\n\\n\\noperating_system = platform.system().lower()\\nif operating_system == \\'darwin\\':\\n    from .blender_utils_macos import get_installed_blender_versions\\n    operating_system_name = \\'macos\\'\\nelif operating_system == \\'linux\\':\\n    from .blender_utils_linux import get_installed_blender_versions\\n    operating_system_name = \\'linux\\'\\nelif operating_system == \\'windows\\':\\n    from .blender_utils_windows import get_installed_blender_versions\\n    operating_system_name = \\'windows\\'\\nelse:\\n    raise Exception(\"Unimplemented for OS {}\".format(operating_system))\\n\\nfrom .blender_utils_web import get_blender_version_download_links\\n\\n\\ndef find_blender(version):\\n    \\n    installed_versions = get_installed_blender_versions()\\n    if version in installed_versions:\\n        return installed_versions[version]\\n    else:\\n        print(\"blender version \\'{}\\' not found; found {} version(s):\".format(version, len(installed_versions)))\\n        for v, path in installed_versions.items():\\n            print(\"    {}: {}\".format(v, path))\\n        print(\"searching web archive...\")\\n        versions = get_blender_version_download_links(version, operating_system_name)\\n        print(\"found {} download(s) for blender version \\'{}\\', platform \\'{}\\':\".format(len(versions), version, operating_system_name))\\n        for url in versions:\\n            print(\"    {}\".format(url))\\n\\n\\nif __name__ == \\'__main__\\':\\n    for version, exec_path in get_installed_blender_versions().items():\\n        print(\"found blender {version}: {path}\".format(version=version,\\n                                                       path=exec_path))\\n    blender = find_blender(\\'2.80\\')\\n    if blender:\\n        print(\"Found blender: \\'{}\\'\".format(blender))\\n    else:\\n        print(\"No matching blender version installed :(\")\\n', 'summary': 'This Python script is designed to manage Blender, a popular 3D creation suite. It checks the operating system and imports platform-specific utilities for retrieving installed Blender versions. The script defines a function `find_blender` that searches for a specified Blender version locally or on a web archive if it\\'s not found locally.\\n\\nHere\\'s a breakdown of the code:\\n\\n1. **Importing Platform Module**:\\n   ```python\\n   import platform\\n   ```\\n   This module is used to determine the operating system on which the script is running.\\n\\n2. **Determining Operating System**:\\n   ```python\\n   operating_system = platform.system().lower()\\n   ```\\n   The script checks if the operating system is macOS, Linux, or Windows and imports the corresponding utility module (`blender_utils_macos`, `blender_utils_linux`, or `blender_utils_windows`).\\n\\n3. **Importing Web Archive Utility**:\\n   ```python\\n   from .blender_utils_web import get_blender_version_download_links\\n   ```\\n   This utility is used to fetch download links for Blender versions from a web archive.\\n\\n4. **Finding Installed Blender Versions**:\\n   ```python\\n   def find_blender(version):\\n       installed_versions = get_installed_blender_versions()\\n       if version in installed_versions:\\n           return installed_versions[version]\\n       else:\\n           # Search web archive and print results\\n   ```\\n   The `find_blender` function checks if the specified Blender version is installed locally. If not, it searches for download links on a web archive.\\n\\n5. **Main Execution Block**:\\n   ```python\\n   if __name__ == \\'__main__\\':\\n       for version, exec_path in get_installed_blender_versions().items():\\n           print(\"found blender {version}: {path}\".format(version=version,\\n                                                          path=exec_path))\\n       blender = find_blender(\\'2.80\\')\\n       if blender:\\n           print(\"Found blender: \\'{}\\'\".format(blender))\\n       else:\\n           print(\"No matching blender version installed :(\")\\n   ```\\n   This block runs when the script is executed directly. It lists all installed Blender versions and attempts to find a specific version (in this case, \\'2.80\\'). If found, it prints the path; otherwise, it indicates that no matching version is installed.\\n\\n### Summary\\nThe script provides a way to manage Blender installations across different operating systems by checking local installations and fetching download links from a web archive if necessary. It includes functionality to find specific Blender versions and list all installed versions.'}\n",
            "Summary: This Python script is designed to manage Blender, a popular 3D creation suite. It checks the operating system and imports platform-specific utilities for retrieving installed Blender versions. The script defines a function `find_blender` that searches for a specified Blender version locally or on a web archive if it's not found locally.\n",
            "\n",
            "Here's a breakdown of the code:\n",
            "\n",
            "1. **Importing Platform Module**:\n",
            "   ```python\n",
            "   import platform\n",
            "   ```\n",
            "   This module is used to determine the operating system on which the script is running.\n",
            "\n",
            "2. **Determining Operating System**:\n",
            "   ```python\n",
            "   operating_system = platform.system().lower()\n",
            "   ```\n",
            "   The script checks if the operating system is macOS, Linux, or Windows and imports the corresponding utility module (`blender_utils_macos`, `blender_utils_linux`, or `blender_utils_windows`).\n",
            "\n",
            "3. **Importing Web Archive Utility**:\n",
            "   ```python\n",
            "   from .blender_utils_web import get_blender_version_download_links\n",
            "   ```\n",
            "   This utility is used to fetch download links for Blender versions from a web archive.\n",
            "\n",
            "4. **Finding Installed Blender Versions**:\n",
            "   ```python\n",
            "   def find_blender(version):\n",
            "       installed_versions = get_installed_blender_versions()\n",
            "       if version in installed_versions:\n",
            "           return installed_versions[version]\n",
            "       else:\n",
            "           # Search web archive and print results\n",
            "   ```\n",
            "   The `find_blender` function checks if the specified Blender version is installed locally. If not, it searches for download links on a web archive.\n",
            "\n",
            "5. **Main Execution Block**:\n",
            "   ```python\n",
            "   if __name__ == '__main__':\n",
            "       for version, exec_path in get_installed_blender_versions().items():\n",
            "           print(\"found blender {version}: {path}\".format(version=version,\n",
            "                                                          path=exec_path))\n",
            "       blender = find_blender('2.80')\n",
            "       if blender:\n",
            "           print(\"Found blender: '{}'\".format(blender))\n",
            "       else:\n",
            "           print(\"No matching blender version installed :(\")\n",
            "   ```\n",
            "   This block runs when the script is executed directly. It lists all installed Blender versions and attempts to find a specific version (in this case, '2.80'). If found, it prints the path; otherwise, it indicates that no matching version is installed.\n",
            "\n",
            "### Summary\n",
            "The script provides a way to manage Blender installations across different operating systems by checking local installations and fetching download links from a web archive if necessary. It includes functionality to find specific Blender versions and list all installed versions.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 5\n",
            "Entry: {'code': 'import functools\\nimport random\\nfrom math import cos, pi\\n\\nimport cv2\\nimport kornia\\nimport numpy as np\\nimport torch\\nfrom kornia.augmentation import ColorJitter\\n\\nfrom data.util import read_img\\nfrom PIL import Image\\nfrom io import BytesIO\\n\\n\\n\\nfrom utils.util import opt_get\\n\\n\\n\\n\\ndef kornia_color_jitter_numpy(img, setting):\\n    if setting * 255 > 1:\\n        \\n        img = torch.from_numpy(img).permute(2,0,1).unsqueeze(0)\\n        img = ColorJitter(setting, setting, setting, setting)(img)\\n        img = img.squeeze(0).permute(1,2,0).numpy()\\n    return img\\n\\n\\n\\n\\nclass ImageCorruptor:\\n    def __init__(self, opt):\\n        self.opt = opt\\n        self.reset_random()\\n        self.blur_scale = opt[\\'corruption_blur_scale\\'] if \\'corruption_blur_scale\\' in opt.keys() else 1\\n        self.fixed_corruptions = opt[\\'fixed_corruptions\\'] if \\'fixed_corruptions\\' in opt.keys() else []\\n        self.num_corrupts = opt[\\'num_corrupts_per_image\\'] if \\'num_corrupts_per_image\\' in opt.keys() else 0\\n        self.cosine_bias = opt_get(opt, [\\'cosine_bias\\'], True)\\n        if self.num_corrupts == 0:\\n            return\\n        else:\\n            self.random_corruptions = opt[\\'random_corruptions\\'] if \\'random_corruptions\\' in opt.keys() else []\\n\\n    def reset_random(self):\\n        if \\'random_seed\\' in self.opt.keys():\\n            self.rand = random.Random(self.opt[\\'random_seed\\'])\\n        else:\\n            self.rand = random.Random()\\n\\n    \\n    \\n    def get_rand(self):\\n        r = self.rand.random()\\n        if self.cosine_bias:\\n            return 1 - cos(r * pi / 2)\\n        else:\\n            return r\\n\\n    def corrupt_images(self, imgs, return_entropy=False):\\n        if self.num_corrupts == 0 and not self.fixed_corruptions:\\n            if return_entropy:\\n                return imgs, []\\n            else:\\n                return imgs\\n\\n        if self.num_corrupts == 0:\\n            augmentations = []\\n        else:\\n            augmentations = random.choices(self.random_corruptions, k=self.num_corrupts)\\n\\n        \\n        corrupted_imgs = []\\n        entropy = []\\n        undo_fns = []\\n        applied_augs = augmentations + self.fixed_corruptions\\n        for img in imgs:\\n            for aug in augmentations:\\n                r = self.get_rand()\\n                img, undo_fn = self.apply_corruption(img, aug, r, applied_augs)\\n                if undo_fn is not None:\\n                    undo_fns.append(undo_fn)\\n            for aug in self.fixed_corruptions:\\n                r = self.get_rand()\\n                img, undo_fn = self.apply_corruption(img, aug, r, applied_augs)\\n                entropy.append(r)\\n                if undo_fn is not None:\\n                    undo_fns.append(undo_fn)\\n            \\n            for ufn in undo_fns:\\n                img = ufn(img)\\n            corrupted_imgs.append(img)\\n\\n\\n        if return_entropy:\\n            return corrupted_imgs, entropy\\n        else:\\n            return corrupted_imgs\\n\\n    def apply_corruption(self, img, aug, rand_val, applied_augmentations):\\n        undo_fn = None\\n        if \\'color_quantization\\' in aug:\\n            \\n            quant_div = 2 ** (int(rand_val * 10 / 3) + 2)\\n            img = img * 255\\n            img = (img // quant_div) * quant_div\\n            img = img / 255\\n        elif \\'color_jitter\\' in aug:\\n            lo_end = 0\\n            hi_end = .2\\n            setting = rand_val * (hi_end - lo_end) + lo_end\\n            img = kornia_color_jitter_numpy(img, setting)\\n        elif \\'gaussian_blur\\' in aug:\\n            img = cv2.GaussianBlur(img, (0,0), self.blur_scale*rand_val*1.5)\\n        elif \\'motion_blur\\' in aug:\\n            \\n            intensity = self.blur_scale*rand_val * 3 + 1\\n            angle = random.randint(0,360)\\n            k = np.zeros((intensity, intensity), dtype=np.float32)\\n            k[(intensity - 1) // 2, :] = np.ones(intensity, dtype=np.float32)\\n            k = cv2.warpAffine(k, cv2.getRotationMatrix2D((intensity / 2 - 0.5, intensity / 2 - 0.5), angle, 1.0),\\n                               (intensity, intensity))\\n            k = k * (1.0 / np.sum(k))\\n            img = cv2.filter2D(img, -1, k)\\n        elif \\'block_noise\\' in aug:\\n            \\n            pass\\n        elif \\'lq_resampling\\' in aug:\\n            \\n            if \\'lq_resampling4x\\' == aug:\\n                scale = 4\\n            else:\\n                if rand_val < .3:\\n                    scale = 1\\n                elif rand_val < .7:\\n                    scale = 2\\n                else:\\n                    scale = 4\\n            if scale > 1:\\n                interpolation_modes = [cv2.INTER_NEAREST, cv2.INTER_CUBIC, cv2.INTER_LINEAR, cv2.INTER_LANCZOS4]\\n                mode = random.randint(0,4) % len(interpolation_modes)\\n                \\n                img = cv2.resize(img, dsize=(img.shape[1]//scale, img.shape[0]//scale), interpolation=mode)\\n                def lq_resampling_undo_fn(scale, img):\\n                    return cv2.resize(img, dsize=(img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_LINEAR)\\n                undo_fn = functools.partial(lq_resampling_undo_fn, scale)\\n        elif \\'color_shift\\' in aug:\\n            \\n            pass\\n        elif \\'interlacing\\' in aug:\\n            \\n            pass\\n        elif \\'chromatic_aberration\\' in aug:\\n            \\n            pass\\n        elif \\'noise\\' in aug:\\n            \\n            if \\'noise-5\\' == aug:\\n                noise_intensity = 5 / 255.0\\n            else:\\n                noise_intensity = (rand_val*6) / 255.0\\n            img += np.random.rand(*img.shape) * noise_intensity\\n        elif \\'jpeg\\' in aug:\\n            if \\'noise\\' not in applied_augmentations and \\'noise-5\\' not in applied_augmentations:\\n                if aug == \\'jpeg\\':\\n                    lo=10\\n                    range=20\\n                elif aug == \\'jpeg-low\\':\\n                    lo=15\\n                    range=10\\n                elif aug == \\'jpeg-medium\\':\\n                    lo=23\\n                    range=25\\n                elif aug == \\'jpeg-broad\\':\\n                    lo=15\\n                    range=60\\n                elif aug == \\'jpeg-normal\\':\\n                    lo=47\\n                    range=35\\n                else:\\n                    raise NotImplementedError(\"specified jpeg corruption doesn\\'t exist\")\\n                \\n                qf = (int((1-rand_val)*range) + lo)\\n                \\n                img = (img * 255).astype(np.uint8)\\n                img = Image.fromarray(img)\\n                buffer = BytesIO()\\n                img.save(buffer, \"JPEG\", quality=qf, optimize=True)\\n                buffer.seek(0)\\n                jpeg_img_bytes = np.asarray(bytearray(buffer.read()), dtype=\"uint8\")\\n                img = read_img(\"buffer\", jpeg_img_bytes, rgb=True)\\n        elif \\'saturation\\' in aug:\\n            \\n            saturation = rand_val * .3\\n            img = np.clip(img + saturation, a_max=1, a_min=0)\\n        elif \\'greyscale\\' in aug:\\n            img = np.tile(np.mean(img, axis=2, keepdims=True), [1,1,3])\\n        elif \\'none\\' not in aug:\\n            raise NotImplementedError(\"Augmentation doesn\\'t exist\")\\n\\n        return img, undo_fn\\n', 'summary': 'This Python code defines a class `ImageCorruptor` that is used to corrupt images by applying various types of image augmentations. The class takes an options dictionary (`opt`) as input and initializes several parameters based on the options provided.\\n\\nThe main functionalities include:\\n1. **Initialization**: Sets up the corruption parameters such as blur scale, fixed corruptions, number of corruptions per image, and cosine bias.\\n2. **Random Seed Handling**: Resets the random seed if specified in the options to ensure reproducibility.\\n3. **Random Number Generation**: Generates a random number with an optional cosine bias.\\n4. **Image Corruption**: Applies a list of corruption augmentations to input images. It can handle both fixed and randomly selected corruptions.\\n5. **Applying Corruptions**: For each augmentation, it applies the specified transformation to the image and optionally records an undo function for reversing the corruption.\\n6. **Undoing Corruptions**: After applying all corruptions, it reverses any applied transformations using the recorded undo functions.\\n\\nThe code also includes a helper function `kornia_color_jitter_numpy` that uses Kornia library to apply color jitter to images represented as NumPy arrays.\\n\\nOverall, this class provides a flexible framework for corrupting images in various ways, which can be useful for testing and evaluating image processing algorithms.'}\n",
            "Summary: This Python code defines a class `ImageCorruptor` that is used to corrupt images by applying various types of image augmentations. The class takes an options dictionary (`opt`) as input and initializes several parameters based on the options provided.\n",
            "\n",
            "The main functionalities include:\n",
            "1. **Initialization**: Sets up the corruption parameters such as blur scale, fixed corruptions, number of corruptions per image, and cosine bias.\n",
            "2. **Random Seed Handling**: Resets the random seed if specified in the options to ensure reproducibility.\n",
            "3. **Random Number Generation**: Generates a random number with an optional cosine bias.\n",
            "4. **Image Corruption**: Applies a list of corruption augmentations to input images. It can handle both fixed and randomly selected corruptions.\n",
            "5. **Applying Corruptions**: For each augmentation, it applies the specified transformation to the image and optionally records an undo function for reversing the corruption.\n",
            "6. **Undoing Corruptions**: After applying all corruptions, it reverses any applied transformations using the recorded undo functions.\n",
            "\n",
            "The code also includes a helper function `kornia_color_jitter_numpy` that uses Kornia library to apply color jitter to images represented as NumPy arrays.\n",
            "\n",
            "Overall, this class provides a flexible framework for corrupting images in various ways, which can be useful for testing and evaluating image processing algorithms.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 6\n",
            "Entry: {'code': 'print(b\"%%\" % ())\\nprint(b\"=%d=\" % 1)\\nprint(b\"=%d=%d=\" % (1, 2))\\n\\nprint(b\"=%s=\" % b\"str\")\\nprint(b\"=%r=\" % b\"str\")\\n\\nprint(\"PASS\")', 'summary': 'The provided Python code demonstrates the use of string formatting with bytes objects. Here\\'s a summary of each line:\\n\\n1. `print(b\"%%\" % ())`: This prints a byte string containing a single percent sign (`%`). The `%` operator is used for string formatting, but since there are no arguments provided, it simply outputs the literal percent sign.\\n\\n2. `print(b\"=%d=\" % 1)`: This prints a byte string formatted with an integer. The `%d` placeholder in the byte string is replaced by the integer value `1`, resulting in the output `=1=`.\\n\\n3. `print(b\"=%d=%d=\" % (1, 2))`: This prints a byte string formatted with two integers. The placeholders `%d` are replaced by the values `1` and `2`, respectively, resulting in the output `=1=2=`.\\n\\n4. `print(b\"=%s=\" % b\"str\")`: This prints a byte string formatted with another byte string. The `%s` placeholder is replaced by the byte string `b\"str\"`, resulting in the output `=str=`.\\n\\n5. `print(b\"=%r=\" % b\"str\")`: This prints a byte string formatted with the representation of a byte string. The `%r` placeholder outputs the byte string as it would be written in Python code, which is `b\\'str\\'`. Thus, the output is `=b\\'str\\'=`.\\n\\n6. `print(\"PASS\")`: Finally, this line simply prints the string `\"PASS\"`, indicating that all previous operations have been successfully executed without errors.'}\n",
            "Summary: The provided Python code demonstrates the use of string formatting with bytes objects. Here's a summary of each line:\n",
            "\n",
            "1. `print(b\"%%\" % ())`: This prints a byte string containing a single percent sign (`%`). The `%` operator is used for string formatting, but since there are no arguments provided, it simply outputs the literal percent sign.\n",
            "\n",
            "2. `print(b\"=%d=\" % 1)`: This prints a byte string formatted with an integer. The `%d` placeholder in the byte string is replaced by the integer value `1`, resulting in the output `=1=`.\n",
            "\n",
            "3. `print(b\"=%d=%d=\" % (1, 2))`: This prints a byte string formatted with two integers. The placeholders `%d` are replaced by the values `1` and `2`, respectively, resulting in the output `=1=2=`.\n",
            "\n",
            "4. `print(b\"=%s=\" % b\"str\")`: This prints a byte string formatted with another byte string. The `%s` placeholder is replaced by the byte string `b\"str\"`, resulting in the output `=str=`.\n",
            "\n",
            "5. `print(b\"=%r=\" % b\"str\")`: This prints a byte string formatted with the representation of a byte string. The `%r` placeholder outputs the byte string as it would be written in Python code, which is `b'str'`. Thus, the output is `=b'str'=`.\n",
            "\n",
            "6. `print(\"PASS\")`: Finally, this line simply prints the string `\"PASS\"`, indicating that all previous operations have been successfully executed without errors.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 7\n",
            "Entry: {'code': 'import pytest\\nimport albumentations as A\\nfrom .context import TfDataAugmentation as Tfda\\nfrom . import test_utils\\nfrom .test_utils import TestResult\\n\\n\\n@pytest.mark.parametrize(\\n    \"quality_lower, quality_upper, expected, message\", [\\n        \\n        (-1, 100, TestResult.Error,\\n         \"quality_lower < min => Error\"),\\n        (0, 100, TestResult.OK,\\n         \"quality_lower == min => OK\"),\\n        (100, 100, TestResult.OK,\\n         \"quality_lower == max => OK\"),\\n        (101, 100, TestResult.Error,\\n         \"quality_lower >= max => Error\"),\\n\\n        \\n        (0, -1, TestResult.Error,\\n         \"quality_upper < min => Error\"),\\n        (0, 0, TestResult.OK,\\n         \"quality_upper == min => OK\"),\\n        (0, 100, TestResult.OK,\\n         \"quality_upper == max => OK\"),\\n        (0, 101, TestResult.Error,\\n         \"quality_upper > max => Error\"),\\n\\n        \\n        (50, 50, TestResult.OK,\\n         \"quality_lower == quality_upper => OK\"),\\n        (51, 50, TestResult.Error,\\n         \"quality_lower > quality_upper => Error\"),\\n    ])\\ndef test_hue_shift_limit_value(\\n        quality_lower, quality_upper, expected, message):\\n    try:\\n        Tfda.JpegCompression(\\n            quality_lower=quality_lower,\\n            quality_upper=quality_upper)\\n        actual = TestResult.OK\\n    except ValueError:\\n        actual = TestResult.Error\\n    assert expected == actual, message\\n\\n\\ndef test_call():\\n    quality_lower = 50\\n    quality_upper = 100\\n    tgt_jpeg = Tfda.JpegCompression(\\n        quality_lower=quality_lower,\\n        quality_upper=quality_upper,\\n        p=1.0)\\n    tgt_transform = \\\\\\n        test_utils.make_tgt_transform(tgt_jpeg)\\n    image = test_utils.make_test_image()\\n\\n    tgt_result = tgt_transform(image=image)\\n    actual_image = tgt_result[\\'image\\']\\n\\n    image_np = image.numpy()\\n    quality = float(tgt_jpeg.get_param(\\'quality\\'))\\n    expected_image = A.image_compression(\\n        image_np, quality, image_type=\\'.jpg\\')\\n\\n    test_utils.partial_assert_array(\\n        expected_image, actual_image, 0.6, \"image\", eps=0.1)\\n', 'summary': 'This Python code is a set of tests for the `JpegCompression` class from the `TfDataAugmentation` module using the `pytest` framework and `albumentations` library. The tests validate the behavior of the `JpegCompression` class under different conditions related to JPEG compression quality settings.\\n\\n1. **Test Function (`test_hue_shift_limit_value`)**:\\n   - This function uses `@pytest.mark.parametrize` to run multiple test cases with varying values for `quality_lower` and `quality_upper`.\\n   - It checks if the `JpegCompression` class raises a `ValueError` when the quality limits are out of valid ranges (0-100).\\n   - The expected result (`TestResult.OK` or `TestResult.Error`) is compared with the actual result to ensure correctness.\\n\\n2. **Test Function (`test_call`)**:\\n   - This function tests the functionality of the `JpegCompression` class when applied to an image.\\n   - It creates a transformation pipeline using `Tfda.JpegCompression`, applies it to a test image, and compares the transformed image with the expected result using `albumentations.image_compression`.\\n   - The comparison is done using `test_utils.partial_assert_array` to check if the images are similar within a certain tolerance.\\n\\nOverall, these tests ensure that the `JpegCompression` class behaves as expected under various conditions and produces the correct output when applied to images.'}\n",
            "Summary: This Python code is a set of tests for the `JpegCompression` class from the `TfDataAugmentation` module using the `pytest` framework and `albumentations` library. The tests validate the behavior of the `JpegCompression` class under different conditions related to JPEG compression quality settings.\n",
            "\n",
            "1. **Test Function (`test_hue_shift_limit_value`)**:\n",
            "   - This function uses `@pytest.mark.parametrize` to run multiple test cases with varying values for `quality_lower` and `quality_upper`.\n",
            "   - It checks if the `JpegCompression` class raises a `ValueError` when the quality limits are out of valid ranges (0-100).\n",
            "   - The expected result (`TestResult.OK` or `TestResult.Error`) is compared with the actual result to ensure correctness.\n",
            "\n",
            "2. **Test Function (`test_call`)**:\n",
            "   - This function tests the functionality of the `JpegCompression` class when applied to an image.\n",
            "   - It creates a transformation pipeline using `Tfda.JpegCompression`, applies it to a test image, and compares the transformed image with the expected result using `albumentations.image_compression`.\n",
            "   - The comparison is done using `test_utils.partial_assert_array` to check if the images are similar within a certain tolerance.\n",
            "\n",
            "Overall, these tests ensure that the `JpegCompression` class behaves as expected under various conditions and produces the correct output when applied to images.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 8\n",
            "Entry: {'code': 'import os\\n\\nfrom torch.utils.data import DataLoader\\nfrom continuum.datasets import CIFAR10, InMemoryDataset\\nfrom continuum.datasets import MNIST\\nimport torchvision\\nfrom continuum.scenarios import TransformationIncremental\\nimport pytest\\nimport numpy as np\\n\\nfrom continuum.transforms.bg_swap import BackgroundSwap\\n\\nDATA_PATH = os.environ.get(\"CONTINUUM_DATA_PATH\")\\n\\n\\n\\n\\n\\ndef test_bg_swap_fast():\\n    \\n    bg_x = np.ones(shape=[2, 5, 5, 3]) * -1\\n    bg_y = np.random.rand(2)\\n\\n    fg = np.random.normal(loc=.5, scale=.1, size=[5, 5])\\n    bg = InMemoryDataset(bg_x, bg_y)\\n\\n    bg_swap = BackgroundSwap(bg, input_dim=(5, 5), normalize_bg=None)\\n\\n    spliced_1_channel = bg_swap(fg)[:, :, 0]\\n\\n    assert np.array_equal((spliced_1_channel <= -1), (fg <= .5))\\n\\n\\n@pytest.mark.slow\\ndef test_background_swap_numpy():\\n    \\n    mnist = MNIST(DATA_PATH, download=True, train=True)\\n    cifar = CIFAR10(DATA_PATH, download=True, train=True)\\n\\n    bg_swap = BackgroundSwap(cifar, input_dim=(28, 28))\\n\\n    im = mnist.get_data()[0][0]\\n    im = bg_swap(im)\\n\\n    \\n    \\n    \\n\\n\\n@pytest.mark.slow\\ndef test_background_swap_torch():\\n    \\n    cifar = CIFAR10(DATA_PATH, download=True, train=True)\\n\\n    mnist = torchvision.datasets.MNIST(DATA_PATH, train=True, download=True,\\n                                       transform=torchvision.transforms.Compose([\\n                                           torchvision.transforms.ToTensor()\\n                                       ]))\\n\\n    bg_swap = BackgroundSwap(cifar, input_dim=(28, 28))\\n    im = mnist[0][0]\\n\\n    im = bg_swap(im)\\n\\n    \\n    \\n    \\n\\n\\n@pytest.mark.slow\\ndef test_background_tranformation():\\n    \\n    cifar = CIFAR10(DATA_PATH, train=True)\\n    mnist = MNIST(DATA_PATH, download=False, train=True)\\n    nb_task = 3\\n    list_trsf = []\\n    for i in range(nb_task):\\n        list_trsf.append([torchvision.transforms.ToTensor(), BackgroundSwap(cifar, bg_label=i, input_dim=(28, 28)),\\n                          torchvision.transforms.ToPILImage()])\\n    scenario = TransformationIncremental(mnist, base_transformations=[torchvision.transforms.ToTensor()],\\n                                         incremental_transformations=list_trsf)\\n    folder = \"tests/samples/background_trsf/\"\\n    if not os.path.exists(folder):\\n        os.makedirs(folder)\\n    for task_id, task_data in enumerate(scenario):\\n        task_data.plot(path=folder, title=f\"background_{task_id}.jpg\", nb_samples=100, shape=[28, 28, 3])\\n        loader = DataLoader(task_data)\\n        _, _, _ = next(iter(loader))\\n', 'summary': 'This Python code is a test suite for the `BackgroundSwap` transformation in the Continuum library. The tests are designed to ensure that the `BackgroundSwap` function works correctly with different datasets and transformations.\\n\\n1. **Imports**: The code imports necessary libraries such as `os`, `torch`, `continuum`, `pytest`, and `numpy`.\\n\\n2. **Environment Variable**: It retrieves the data path from an environment variable named `CONTINUUM_DATA_PATH`.\\n\\n3. **Test Functions**:\\n   - `test_bg_swap_fast`: This function tests the `BackgroundSwap` transformation with a simple background and foreground image. It checks if the transformed image meets certain conditions.\\n   - `test_background_swap_numpy`: This function tests the `BackgroundSwap` transformation using the MNIST dataset in NumPy format.\\n   - `test_background_swap_torch`: This function tests the `BackgroundSwap` transformation using the MNIST dataset in PyTorch format.\\n   - `test_background_tranformation`: This function tests a more complex scenario where multiple tasks are created with different transformations, including `BackgroundSwap`.\\n\\n4. **Scenario Creation**: The last test function creates a `TransformationIncremental` scenario that combines MNIST and CIFAR10 datasets with various transformations, including `BackgroundSwap`. It then plots the transformed data for each task and saves it to disk.\\n\\nOverall, this code is designed to validate the functionality of the `BackgroundSwap` transformation in different scenarios and formats.'}\n",
            "Summary: This Python code is a test suite for the `BackgroundSwap` transformation in the Continuum library. The tests are designed to ensure that the `BackgroundSwap` function works correctly with different datasets and transformations.\n",
            "\n",
            "1. **Imports**: The code imports necessary libraries such as `os`, `torch`, `continuum`, `pytest`, and `numpy`.\n",
            "\n",
            "2. **Environment Variable**: It retrieves the data path from an environment variable named `CONTINUUM_DATA_PATH`.\n",
            "\n",
            "3. **Test Functions**:\n",
            "   - `test_bg_swap_fast`: This function tests the `BackgroundSwap` transformation with a simple background and foreground image. It checks if the transformed image meets certain conditions.\n",
            "   - `test_background_swap_numpy`: This function tests the `BackgroundSwap` transformation using the MNIST dataset in NumPy format.\n",
            "   - `test_background_swap_torch`: This function tests the `BackgroundSwap` transformation using the MNIST dataset in PyTorch format.\n",
            "   - `test_background_tranformation`: This function tests a more complex scenario where multiple tasks are created with different transformations, including `BackgroundSwap`.\n",
            "\n",
            "4. **Scenario Creation**: The last test function creates a `TransformationIncremental` scenario that combines MNIST and CIFAR10 datasets with various transformations, including `BackgroundSwap`. It then plots the transformed data for each task and saves it to disk.\n",
            "\n",
            "Overall, this code is designed to validate the functionality of the `BackgroundSwap` transformation in different scenarios and formats.\n",
            "\n",
            "Processing batch batch_1.json, entry ID: 9\n",
            "Entry: {'code': 'import os\\n\\n\\nJQUERY_VERSION = \"1.6.2\"\\nJQUERY_UI_VERSION = \"1.8.16\"\\n\\n\\nDATE_TEXT_SIZE = 25\\nTEXT_SIZE = 85\\nTEXTAREA_COLS = 85\\nTEXTAREA_ROWS_SHORT = 2\\nTEXTAREA_ROWS_LONG = 4\\nTEXTAREA_ROWS_XLONG = 10\\nMAX_LENGTH_CHECKLIST_NOTES = 255\\nEMAIL_LENGTH = 60\\n\\n\\n_app_path = None\\n_config_file = None\\n_app_name = None\\nsession_lock_dir = None\\npublish_dir = None\\n\\n\\ndef update_cache_values():\\n    \\n    global _app_path, _config_file, _app_name, session_lock_dir, publish_dir\\n\\n    if _app_path is None:\\n        _app_path = os.path.normpath(os.path.join(os.path.dirname(__file__), \\'..\\', \\'..\\', \\'..\\'))\\n        _app_name = os.path.split(_app_path)[1]\\n        _config_file = os.path.join(_app_path, \\'..\\', \\'..\\', \\'config\\', _app_name + \\'.ini\\')\\n        session_lock_dir = os.path.join(_app_path, \\'python\\', \\'session_lock\\')\\n        publish_dir = os.path.join(_app_path, \\'python\\', \\'published_files\\')\\n\\n        try:\\n            os.makedirs(session_lock_dir)\\n        except os.error:\\n            pass\\n\\n        try:\\n            os.makedirs(publish_dir)\\n        except os.error:\\n            pass\\n', 'summary': \"This Python code defines constants and variables for various configuration settings and paths related to a web application. It also includes a function `update_cache_values()` that initializes these variables if they are not already set.\\n\\nHere's a summary of the key components:\\n\\n1. **Constants**:\\n   - `JQUERY_VERSION` and `JQUERY_UI_VERSION`: Versions of jQuery and jQuery UI libraries.\\n   - `DATE_TEXT_SIZE`, `TEXT_SIZE`, `TEXTAREA_COLS`, `TEXTAREA_ROWS_SHORT`, `TEXTAREA_ROWS_LONG`, `TEXTAREA_ROWS_XLONG`: Various text sizes and dimensions for HTML elements.\\n   - `MAX_LENGTH_CHECKLIST_NOTES` and `EMAIL_LENGTH`: Maximum lengths for checklist notes and email addresses.\\n\\n2. **Global Variables**:\\n   - `_app_path`, `_config_file`, `_app_name`, `session_lock_dir`, `publish_dir`: These variables are initialized by the `update_cache_values()` function to store paths and configuration details of the application.\\n\\n3. **Function `update_cache_values()`**:\\n   - This function sets the global variables if they are not already set.\\n   - It calculates `_app_path` as the normalized path of the parent directory four levels up from where the script is located.\\n   - It determines `_app_name` by splitting `_app_path`.\\n   - It constructs paths for `_config_file`, `session_lock_dir`, and `publish_dir`.\\n   - It attempts to create directories for `session_lock_dir` and `publish_dir` if they do not exist, handling any errors that occur during directory creation.\\n\\nThis setup ensures that the application has consistent configuration values and necessary directories ready for use.\"}\n",
            "Summary: This Python code defines constants and variables for various configuration settings and paths related to a web application. It also includes a function `update_cache_values()` that initializes these variables if they are not already set.\n",
            "\n",
            "Here's a summary of the key components:\n",
            "\n",
            "1. **Constants**:\n",
            "   - `JQUERY_VERSION` and `JQUERY_UI_VERSION`: Versions of jQuery and jQuery UI libraries.\n",
            "   - `DATE_TEXT_SIZE`, `TEXT_SIZE`, `TEXTAREA_COLS`, `TEXTAREA_ROWS_SHORT`, `TEXTAREA_ROWS_LONG`, `TEXTAREA_ROWS_XLONG`: Various text sizes and dimensions for HTML elements.\n",
            "   - `MAX_LENGTH_CHECKLIST_NOTES` and `EMAIL_LENGTH`: Maximum lengths for checklist notes and email addresses.\n",
            "\n",
            "2. **Global Variables**:\n",
            "   - `_app_path`, `_config_file`, `_app_name`, `session_lock_dir`, `publish_dir`: These variables are initialized by the `update_cache_values()` function to store paths and configuration details of the application.\n",
            "\n",
            "3. **Function `update_cache_values()`**:\n",
            "   - This function sets the global variables if they are not already set.\n",
            "   - It calculates `_app_path` as the normalized path of the parent directory four levels up from where the script is located.\n",
            "   - It determines `_app_name` by splitting `_app_path`.\n",
            "   - It constructs paths for `_config_file`, `session_lock_dir`, and `publish_dir`.\n",
            "   - It attempts to create directories for `session_lock_dir` and `publish_dir` if they do not exist, handling any errors that occur during directory creation.\n",
            "\n",
            "This setup ensures that the application has consistent configuration values and necessary directories ready for use.\n",
            "\n",
            "Processed batch written to batches/batch_1_processed.json\n",
            "Processing batch 2\n",
            "Processing batch batch_2.json, entry ID: 0\n",
            "Entry: {'code': 'from typing import Any, TYPE_CHECKING\\n\\nfrom azure.core.configuration import Configuration\\nfrom azure.core.pipeline import policies\\nfrom azure.mgmt.core.policies import ARMHttpLoggingPolicy\\n\\nfrom .._version import VERSION\\n\\nif TYPE_CHECKING:\\n    \\n    from azure.core.credentials_async import AsyncTokenCredential\\n\\n\\nclass WebSiteManagementClientConfiguration(Configuration):\\n    \\n\\n    def __init__(\\n        self,\\n        credential: \"AsyncTokenCredential\",\\n        subscription_id: str,\\n        **kwargs: Any\\n    ) -> None:\\n        if credential is None:\\n            raise ValueError(\"Parameter \\'credential\\' must not be None.\")\\n        if subscription_id is None:\\n            raise ValueError(\"Parameter \\'subscription_id\\' must not be None.\")\\n        super(WebSiteManagementClientConfiguration, self).__init__(**kwargs)\\n\\n        self.credential = credential\\n        self.subscription_id = subscription_id\\n        self.api_version = \"2015-08-01\"\\n        self.credential_scopes = kwargs.pop(\\'credential_scopes\\', [\\'https://management.azure.com/.default\\'])\\n        kwargs.setdefault(\\'sdk_moniker\\', \\'mgmt-web/{}\\'.format(VERSION))\\n        self._configure(**kwargs)\\n\\n    def _configure(\\n        self,\\n        **kwargs: Any\\n    ) -> None:\\n        self.user_agent_policy = kwargs.get(\\'user_agent_policy\\') or policies.UserAgentPolicy(**kwargs)\\n        self.headers_policy = kwargs.get(\\'headers_policy\\') or policies.HeadersPolicy(**kwargs)\\n        self.proxy_policy = kwargs.get(\\'proxy_policy\\') or policies.ProxyPolicy(**kwargs)\\n        self.logging_policy = kwargs.get(\\'logging_policy\\') or policies.NetworkTraceLoggingPolicy(**kwargs)\\n        self.http_logging_policy = kwargs.get(\\'http_logging_policy\\') or ARMHttpLoggingPolicy(**kwargs)\\n        self.retry_policy = kwargs.get(\\'retry_policy\\') or policies.AsyncRetryPolicy(**kwargs)\\n        self.custom_hook_policy = kwargs.get(\\'custom_hook_policy\\') or policies.CustomHookPolicy(**kwargs)\\n        self.redirect_policy = kwargs.get(\\'redirect_policy\\') or policies.AsyncRedirectPolicy(**kwargs)\\n        self.authentication_policy = kwargs.get(\\'authentication_policy\\')\\n        if self.credential and not self.authentication_policy:\\n            self.authentication_policy = policies.AsyncBearerTokenCredentialPolicy(self.credential, *self.credential_scopes, **kwargs)\\n', 'summary': \"This Python code defines a configuration class for the Azure Web Site Management Client. The `WebSiteManagementClientConfiguration` class inherits from `azure.core.configuration.Configuration`. It is used to configure various aspects of the client, such as credentials, subscription ID, API version, and policies.\\n\\nHere's a summary of the key components:\\n\\n1. **Initialization (`__init__` method)**:\\n   - Takes parameters for `credential`, `subscription_id`, and additional keyword arguments.\\n   - Validates that both `credential` and `subscription_id` are not None.\\n   - Initializes the base class with any additional keyword arguments.\\n   - Sets default values for properties like `api_version` and `credential_scopes`.\\n   - Calls `_configure` to set up various policies.\\n\\n2. **Configuration (`_configure` method)**:\\n   - Accepts keyword arguments to configure different policies such as user agent, headers, proxy, logging, HTTP logging, retry, custom hooks, redirect, and authentication.\\n   - If no authentication policy is provided but a credential is available, it sets up an `AsyncBearerTokenCredentialPolicy`.\\n\\nThis configuration class ensures that the client is properly set up with all necessary components to interact with Azure Web Sites, including handling authentication and various network policies.\"}\n",
            "Summary: This Python code defines a configuration class for the Azure Web Site Management Client. The `WebSiteManagementClientConfiguration` class inherits from `azure.core.configuration.Configuration`. It is used to configure various aspects of the client, such as credentials, subscription ID, API version, and policies.\n",
            "\n",
            "Here's a summary of the key components:\n",
            "\n",
            "1. **Initialization (`__init__` method)**:\n",
            "   - Takes parameters for `credential`, `subscription_id`, and additional keyword arguments.\n",
            "   - Validates that both `credential` and `subscription_id` are not None.\n",
            "   - Initializes the base class with any additional keyword arguments.\n",
            "   - Sets default values for properties like `api_version` and `credential_scopes`.\n",
            "   - Calls `_configure` to set up various policies.\n",
            "\n",
            "2. **Configuration (`_configure` method)**:\n",
            "   - Accepts keyword arguments to configure different policies such as user agent, headers, proxy, logging, HTTP logging, retry, custom hooks, redirect, and authentication.\n",
            "   - If no authentication policy is provided but a credential is available, it sets up an `AsyncBearerTokenCredentialPolicy`.\n",
            "\n",
            "This configuration class ensures that the client is properly set up with all necessary components to interact with Azure Web Sites, including handling authentication and various network policies.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 1\n",
            "Entry: {'code': 'import django.http\\n\\nimport unittest.mock\\n\\nfrom .. import middleware\\n\\n\\ndef get_response(req):\\n    \\n    return django.http.HttpResponse()\\n\\n\\ndef test_leaves_remote_addr_alone_if_no_real_ip():\\n    remote_addr = object()\\n    request = unittest.mock.MagicMock()\\n    request.META = {\"REMOTE_ADDR\": remote_addr}\\n\\n    middleware.XRealIPMiddleware(get_response)(request)\\n\\n    assert request.META[\"REMOTE_ADDR\"] is remote_addr\\n\\n\\ndef test_switches_out_x_real_ip_if_available():\\n    remote_addr = object()\\n    x_real_ip = object()\\n\\n    request = unittest.mock.MagicMock()\\n    request.META = {\"REMOTE_ADDR\": remote_addr, \"HTTP_X_REAL_IP\": x_real_ip}\\n\\n    middleware.XRealIPMiddleware(get_response)(request)\\n\\n    assert request.META[\"REMOTE_ADDR\"] is x_real_ip\\n    assert request.META[\"HTTP_X_REAL_IP\"] is x_real_ip\\n', 'summary': \"This Python code consists of a test suite for the `XRealIPMiddleware` class from the `middleware` module. The middleware is designed to handle HTTP requests and potentially modify the `REMOTE_ADDR` header based on an `X-Real-IP` header if it's present.\\n\\nThe code defines two test functions:\\n\\n1. **test_leaves_remote_addr_alone_if_no_real_ip**: This function tests the behavior of the middleware when there is no `X-Real-IP` header in the request. It creates a mock request object with only a `REMOTE_ADDR` header and passes it through the middleware. The test asserts that after processing, the `REMOTE_ADDR` header remains unchanged.\\n\\n2. **test_switches_out_x_real_ip_if_available**: This function tests the behavior of the middleware when both `REMOTE_ADDR` and `X-Real-IP` headers are present in the request. It creates a mock request object with both headers and passes it through the middleware. The test asserts that after processing, both the `REMOTE_ADDR` and `HTTP_X_REAL_IP` headers are updated to the value of `X-Real-IP`.\\n\\nThe `get_response` function is a simple helper that returns an empty HTTP response.\\n\\nOverall, these tests ensure that the `XRealIPMiddleware` correctly handles requests with and without the `X-Real-IP` header, ensuring that the `REMOTE_ADDR` header is updated appropriately.\"}\n",
            "Summary: This Python code consists of a test suite for the `XRealIPMiddleware` class from the `middleware` module. The middleware is designed to handle HTTP requests and potentially modify the `REMOTE_ADDR` header based on an `X-Real-IP` header if it's present.\n",
            "\n",
            "The code defines two test functions:\n",
            "\n",
            "1. **test_leaves_remote_addr_alone_if_no_real_ip**: This function tests the behavior of the middleware when there is no `X-Real-IP` header in the request. It creates a mock request object with only a `REMOTE_ADDR` header and passes it through the middleware. The test asserts that after processing, the `REMOTE_ADDR` header remains unchanged.\n",
            "\n",
            "2. **test_switches_out_x_real_ip_if_available**: This function tests the behavior of the middleware when both `REMOTE_ADDR` and `X-Real-IP` headers are present in the request. It creates a mock request object with both headers and passes it through the middleware. The test asserts that after processing, both the `REMOTE_ADDR` and `HTTP_X_REAL_IP` headers are updated to the value of `X-Real-IP`.\n",
            "\n",
            "The `get_response` function is a simple helper that returns an empty HTTP response.\n",
            "\n",
            "Overall, these tests ensure that the `XRealIPMiddleware` correctly handles requests with and without the `X-Real-IP` header, ensuring that the `REMOTE_ADDR` header is updated appropriately.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 2\n",
            "Entry: {'code': 'import time\\n\\nimport RPi.GPIO as GPIO\\n\\n\\nGPIO.setmode(GPIO.BCM)\\nGPIO.setup(21, GPIO.OUT)\\nGPIO.output(21, GPIO.LOW)\\n\\ntime.sleep(3.00)\\n\\nGPIO.output(21, GPIO.HIGH)\\nGPIO.cleanup()\\n\\n', 'summary': \"This Python script is designed to control a GPIO pin on a Raspberry Pi using the RPi.GPIO library. Here's a summary of what each part of the code does:\\n\\n1. **Import Libraries**:\\n   - `time`: This module provides various time-related functions.\\n   - `RPi.GPIO`: This module allows you to interact with the GPIO pins on a Raspberry Pi.\\n\\n2. **Set GPIO Mode**:\\n   ```python\\n   GPIO.setmode(GPIO.BCM)\\n   ```\\n   This line sets the numbering mode for the GPIO pins. `GPIO.BCM` refers to Broadcom SOC channel numbers, which are the physical pin numbers on the Raspberry Pi board.\\n\\n3. **Setup GPIO Pin**:\\n   ```python\\n   GPIO.setup(21, GPIO.OUT)\\n   ```\\n   This line configures GPIO pin 21 as an output pin. Output pins can be set to either high (True) or low (False).\\n\\n4. **Initial State of the Pin**:\\n   ```python\\n   GPIO.output(21, GPIO.LOW)\\n   ```\\n   This line sets the initial state of GPIO pin 21 to low.\\n\\n5. **Delay**:\\n   ```python\\n   time.sleep(3.00)\\n   ```\\n   This line pauses the execution of the script for 3 seconds. During this time, the GPIO pin remains in its current state (low).\\n\\n6. **Change State of the Pin**:\\n   ```python\\n   GPIO.output(21, GPIO.HIGH)\\n   ```\\n   After the delay, this line changes the state of GPIO pin 21 to high.\\n\\n7. **Cleanup**:\\n   ```python\\n   GPIO.cleanup()\\n   ```\\n   This line cleans up all GPIO settings and restores them to their default state. It's a good practice to call this function when you're done using the GPIO pins to ensure that any resources are properly released.\\n\\nIn summary, this script turns on an output device connected to GPIO pin 21 for 3 seconds and then turns it off.\"}\n",
            "Summary: This Python script is designed to control a GPIO pin on a Raspberry Pi using the RPi.GPIO library. Here's a summary of what each part of the code does:\n",
            "\n",
            "1. **Import Libraries**:\n",
            "   - `time`: This module provides various time-related functions.\n",
            "   - `RPi.GPIO`: This module allows you to interact with the GPIO pins on a Raspberry Pi.\n",
            "\n",
            "2. **Set GPIO Mode**:\n",
            "   ```python\n",
            "   GPIO.setmode(GPIO.BCM)\n",
            "   ```\n",
            "   This line sets the numbering mode for the GPIO pins. `GPIO.BCM` refers to Broadcom SOC channel numbers, which are the physical pin numbers on the Raspberry Pi board.\n",
            "\n",
            "3. **Setup GPIO Pin**:\n",
            "   ```python\n",
            "   GPIO.setup(21, GPIO.OUT)\n",
            "   ```\n",
            "   This line configures GPIO pin 21 as an output pin. Output pins can be set to either high (True) or low (False).\n",
            "\n",
            "4. **Initial State of the Pin**:\n",
            "   ```python\n",
            "   GPIO.output(21, GPIO.LOW)\n",
            "   ```\n",
            "   This line sets the initial state of GPIO pin 21 to low.\n",
            "\n",
            "5. **Delay**:\n",
            "   ```python\n",
            "   time.sleep(3.00)\n",
            "   ```\n",
            "   This line pauses the execution of the script for 3 seconds. During this time, the GPIO pin remains in its current state (low).\n",
            "\n",
            "6. **Change State of the Pin**:\n",
            "   ```python\n",
            "   GPIO.output(21, GPIO.HIGH)\n",
            "   ```\n",
            "   After the delay, this line changes the state of GPIO pin 21 to high.\n",
            "\n",
            "7. **Cleanup**:\n",
            "   ```python\n",
            "   GPIO.cleanup()\n",
            "   ```\n",
            "   This line cleans up all GPIO settings and restores them to their default state. It's a good practice to call this function when you're done using the GPIO pins to ensure that any resources are properly released.\n",
            "\n",
            "In summary, this script turns on an output device connected to GPIO pin 21 for 3 seconds and then turns it off.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 3\n",
            "Entry: {'code': 'from direct.directnotify.DirectNotifyGlobal import directNotify\\n\\n\\nclass Notifier:\\n    def __init__(self, name):\\n        \\n        self.notify = directNotify.newCategory(name)\\n', 'summary': \"The provided Python code defines a class named `Notifier` that is used for logging and notification purposes. Here's a summary of the code:\\n\\n1. **Import Statement**:\\n   - The code imports `directNotify` from `direct.directnotify.DirectNotifyGlobal`. This module is likely part of a larger framework or library designed for game development or similar applications, where detailed logging and notifications are required.\\n\\n2. **Class Definition**:\\n   - A class named `Notifier` is defined. This class will be used to create instances that handle specific types of notifications.\\n\\n3. **Constructor (`__init__` Method)**:\\n   - The `__init__` method initializes a new instance of the `Notifier` class.\\n   - It takes one parameter: `name`, which is expected to be a string representing the name or category for this notifier.\\n   - Inside the constructor, it creates a new notification category using `directNotify.newCategory(name)`. This category will be used to log messages related to the specified name.\\n\\n### Summary\\n- **Purpose**: The `Notifier` class provides a way to create and manage notification categories for logging purposes.\\n- **Usage**: Instances of `Notifier` can be created with a specific name, and they will use that name to categorize their logs.\\n- **Dependencies**: The code relies on the `directNotify` module from the `direct.directnotify` package.\\n\\nThis class is useful in scenarios where you need to organize log messages into different categories for better readability and management.\"}\n",
            "Summary: The provided Python code defines a class named `Notifier` that is used for logging and notification purposes. Here's a summary of the code:\n",
            "\n",
            "1. **Import Statement**:\n",
            "   - The code imports `directNotify` from `direct.directnotify.DirectNotifyGlobal`. This module is likely part of a larger framework or library designed for game development or similar applications, where detailed logging and notifications are required.\n",
            "\n",
            "2. **Class Definition**:\n",
            "   - A class named `Notifier` is defined. This class will be used to create instances that handle specific types of notifications.\n",
            "\n",
            "3. **Constructor (`__init__` Method)**:\n",
            "   - The `__init__` method initializes a new instance of the `Notifier` class.\n",
            "   - It takes one parameter: `name`, which is expected to be a string representing the name or category for this notifier.\n",
            "   - Inside the constructor, it creates a new notification category using `directNotify.newCategory(name)`. This category will be used to log messages related to the specified name.\n",
            "\n",
            "### Summary\n",
            "- **Purpose**: The `Notifier` class provides a way to create and manage notification categories for logging purposes.\n",
            "- **Usage**: Instances of `Notifier` can be created with a specific name, and they will use that name to categorize their logs.\n",
            "- **Dependencies**: The code relies on the `directNotify` module from the `direct.directnotify` package.\n",
            "\n",
            "This class is useful in scenarios where you need to organize log messages into different categories for better readability and management.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 4\n",
            "Entry: {'code': 'import numpy as np\\n\\n\\ndef train_ml_squarer() -> None:\\n    print(\"Training!\")\\n\\n\\ndef square() -> int:\\n    \\n    return np.random.randint(1, 100)\\n\\n\\nif __name__ == \\'__main__\\':\\n    train_ml_squarer()', 'summary': 'This Python script includes two functions and a main execution block. Here\\'s a summary:\\n\\n1. **Imports**: The script starts by importing the `numpy` library as `np`, which is commonly used for numerical operations in Python.\\n\\n2. **Function Definitions**:\\n   - **train_ml_squarer()**: This function prints \"Training!\" when called.\\n   - **square()**: This function returns a random integer between 1 and 99 (inclusive) using `np.random.randint(1, 100)`.\\n\\n3. **Main Execution Block**:\\n   - The script checks if it is being run as the main program (`if __name__ == \\'__main__\\':`).\\n   - If so, it calls the `train_ml_squarer()` function, which prints \"Training!\" to the console.\\n\\nIn summary, this script defines two functions: one for printing a training message and another for generating a random number. The main part of the script simply runs the training message function when executed directly.'}\n",
            "Summary: This Python script includes two functions and a main execution block. Here's a summary:\n",
            "\n",
            "1. **Imports**: The script starts by importing the `numpy` library as `np`, which is commonly used for numerical operations in Python.\n",
            "\n",
            "2. **Function Definitions**:\n",
            "   - **train_ml_squarer()**: This function prints \"Training!\" when called.\n",
            "   - **square()**: This function returns a random integer between 1 and 99 (inclusive) using `np.random.randint(1, 100)`.\n",
            "\n",
            "3. **Main Execution Block**:\n",
            "   - The script checks if it is being run as the main program (`if __name__ == '__main__':`).\n",
            "   - If so, it calls the `train_ml_squarer()` function, which prints \"Training!\" to the console.\n",
            "\n",
            "In summary, this script defines two functions: one for printing a training message and another for generating a random number. The main part of the script simply runs the training message function when executed directly.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 5\n",
            "Entry: {'code': 'import arcade\\n\\n\\nSCREEN_WIDTH = 1000\\nSCREEN_HEIGHT = 650\\nSCREEN_TITLE = \"Platformer\"\\n\\n\\nCHARACTER_SCALING = 1\\nTILE_SCALING = 0.5\\nCOIN_SCALING = 0.5\\nSPRITE_PIXEL_SIZE = 128\\nGRID_PIXEL_SIZE = SPRITE_PIXEL_SIZE * TILE_SCALING\\n\\n\\nPLAYER_MOVEMENT_SPEED = 10\\nGRAVITY = 1\\nPLAYER_JUMP_SPEED = 20\\n\\n\\nclass MyGame(arcade.Window):\\n    \\n\\n    def __init__(self):\\n\\n        \\n        super().__init__(SCREEN_WIDTH, SCREEN_HEIGHT, SCREEN_TITLE)\\n\\n        \\n        self.tile_map = None\\n\\n        \\n        self.scene = None\\n\\n        \\n        self.player_sprite = None\\n\\n        \\n        self.physics_engine = None\\n\\n        \\n        self.camera = None\\n\\n        \\n        self.gui_camera = None\\n\\n        \\n        self.score = 0\\n\\n        \\n        self.collect_coin_sound = arcade.load_sound(\":resources:sounds/coin1.wav\")\\n        self.jump_sound = arcade.load_sound(\":resources:sounds/jump1.wav\")\\n\\n        arcade.set_background_color(arcade.csscolor.CORNFLOWER_BLUE)\\n\\n    def setup(self):\\n        \\n\\n        \\n        self.camera = arcade.Camera(self.width, self.height)\\n        self.gui_camera = arcade.Camera(self.width, self.height)\\n\\n        \\n        map_name = \":resources:tiled_maps/map.json\"\\n\\n        \\n        \\n        \\n        layer_options = {\\n            \"Platforms\": {\\n                \"use_spatial_hash\": True,\\n            },\\n        }\\n\\n        \\n        self.tile_map = arcade.load_tilemap(map_name, TILE_SCALING, layer_options)\\n\\n        \\n        \\n        self.scene = arcade.Scene.from_tilemap(self.tile_map)\\n\\n        \\n        self.score = 0\\n\\n        \\n        image_source = \":resources:images/animated_characters/female_adventurer/femaleAdventurer_idle.png\"\\n        self.player_sprite = arcade.Sprite(image_source, CHARACTER_SCALING)\\n        self.player_sprite.center_x = 128\\n        self.player_sprite.center_y = 128\\n        self.scene.add_sprite(\"Player\", self.player_sprite)\\n\\n        \\n        \\n        if self.tile_map.background_color:\\n            arcade.set_background_color(self.tile_map.background_color)\\n\\n        \\n        self.physics_engine = arcade.PhysicsEnginePlatformer(\\n            self.player_sprite, gravity_constant=GRAVITY, walls=self.scene[\"Platforms\"]\\n        )\\n\\n    def on_draw(self):\\n        \\n\\n        \\n        arcade.start_render()\\n\\n        \\n        self.camera.use()\\n\\n        \\n        self.scene.draw()\\n\\n        \\n        self.gui_camera.use()\\n\\n        \\n        score_text = f\"Score: {self.score}\"\\n        arcade.draw_text(\\n            score_text,\\n            10,\\n            10,\\n            arcade.csscolor.WHITE,\\n            18,\\n        )\\n\\n    def on_key_press(self, key, modifiers):\\n        \\n\\n        if key == arcade.key.UP or key == arcade.key.W:\\n            if self.physics_engine.can_jump():\\n                self.player_sprite.change_y = PLAYER_JUMP_SPEED\\n                arcade.play_sound(self.jump_sound)\\n        elif key == arcade.key.LEFT or key == arcade.key.A:\\n            self.player_sprite.change_x = -PLAYER_MOVEMENT_SPEED\\n        elif key == arcade.key.RIGHT or key == arcade.key.D:\\n            self.player_sprite.change_x = PLAYER_MOVEMENT_SPEED\\n\\n    def on_key_release(self, key, modifiers):\\n        \\n\\n        if key == arcade.key.LEFT or key == arcade.key.A:\\n            self.player_sprite.change_x = 0\\n        elif key == arcade.key.RIGHT or key == arcade.key.D:\\n            self.player_sprite.change_x = 0\\n\\n    def center_camera_to_player(self):\\n        screen_center_x = self.player_sprite.center_x - (self.camera.viewport_width / 2)\\n        screen_center_y = self.player_sprite.center_y - (\\n            self.camera.viewport_height / 2\\n        )\\n        if screen_center_x < 0:\\n            screen_center_x = 0\\n        if screen_center_y < 0:\\n            screen_center_y = 0\\n        player_centered = screen_center_x, screen_center_y\\n\\n        self.camera.move_to(player_centered)\\n\\n    def on_update(self, delta_time):\\n        \\n\\n        \\n        self.physics_engine.update()\\n\\n        \\n        coin_hit_list = arcade.check_for_collision_with_list(\\n            self.player_sprite, self.scene[\"Coins\"]\\n        )\\n\\n        \\n        for coin in coin_hit_list:\\n            \\n            coin.remove_from_sprite_lists()\\n            \\n            arcade.play_sound(self.collect_coin_sound)\\n            \\n            self.score += 1\\n\\n        \\n        self.center_camera_to_player()\\n\\n\\ndef main():\\n    \\n    window = MyGame()\\n    window.setup()\\n    arcade.run()\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n', 'summary': \"This Python code is a simple platformer game using the `arcade` library. The game features a player character that can move left, right, and jump on platforms to collect coins. Here's a summary of the key components:\\n\\n1. **Game Setup**:\\n   - The game window dimensions are set (`SCREEN_WIDTH`, `SCREEN_HEIGHT`, `SCREEN_TITLE`).\\n   - Scaling factors for characters, tiles, and coins are defined.\\n   - Movement speeds, gravity, and jump speed are set.\\n\\n2. **MyGame Class**:\\n   - Inherits from `arcade.Window`.\\n   - Initializes game variables such as the tile map, scene, player sprite, physics engine, cameras, and score.\\n   - The `setup` method initializes the game state, including loading the tilemap, setting up the player, and initializing the physics engine.\\n\\n3. **Game Loop**:\\n   - The `on_draw` method renders the game screen, drawing the scene and displaying the score.\\n   - The `on_key_press` and `on_key_release` methods handle player input for movement and jumping.\\n   - The `center_camera_to_player` method centers the camera on the player sprite to follow their movements.\\n   - The `on_update` method updates the game state, including physics and collision detection.\\n\\n4. **Main Function**:\\n   - Creates an instance of `MyGame`, sets up the game, and starts the arcade loop.\\n\\nThe game uses a tilemap for the level design, which includes platforms and coins. The player can interact with these elements to progress through the level and collect points.\"}\n",
            "Summary: This Python code is a simple platformer game using the `arcade` library. The game features a player character that can move left, right, and jump on platforms to collect coins. Here's a summary of the key components:\n",
            "\n",
            "1. **Game Setup**:\n",
            "   - The game window dimensions are set (`SCREEN_WIDTH`, `SCREEN_HEIGHT`, `SCREEN_TITLE`).\n",
            "   - Scaling factors for characters, tiles, and coins are defined.\n",
            "   - Movement speeds, gravity, and jump speed are set.\n",
            "\n",
            "2. **MyGame Class**:\n",
            "   - Inherits from `arcade.Window`.\n",
            "   - Initializes game variables such as the tile map, scene, player sprite, physics engine, cameras, and score.\n",
            "   - The `setup` method initializes the game state, including loading the tilemap, setting up the player, and initializing the physics engine.\n",
            "\n",
            "3. **Game Loop**:\n",
            "   - The `on_draw` method renders the game screen, drawing the scene and displaying the score.\n",
            "   - The `on_key_press` and `on_key_release` methods handle player input for movement and jumping.\n",
            "   - The `center_camera_to_player` method centers the camera on the player sprite to follow their movements.\n",
            "   - The `on_update` method updates the game state, including physics and collision detection.\n",
            "\n",
            "4. **Main Function**:\n",
            "   - Creates an instance of `MyGame`, sets up the game, and starts the arcade loop.\n",
            "\n",
            "The game uses a tilemap for the level design, which includes platforms and coins. The player can interact with these elements to progress through the level and collect points.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 6\n",
            "Entry: {'code': \"import logging\\nimport os\\nimport tempfile\\n\\nfrom ..process import (\\n    FileHandles,\\n    Process,\\n)\\nfrom ..util.fs import (\\n    default_python_binary_path,\\n    save_json_file,\\n)\\nfrom ..ycmd.constants import (\\n    YCMD_LOG_SPOOL_OUTPUT,\\n    YCMD_LOG_SPOOL_SIZE,\\n    YCMD_DEFAULT_SERVER_CHECK_INTERVAL_SECONDS,\\n    YCMD_DEFAULT_SERVER_IDLE_SUICIDE_SECONDS,\\n)\\nfrom ..ycmd.settings import (\\n    get_default_settings_path,\\n    generate_settings_data,\\n)\\n\\nlogger = logging.getLogger('sublime-ycmd.' + __name__)\\n\\n\\nclass StartupParameters(object):\\n    \\n\\n    def __init__(self, ycmd_root_directory=None,\\n                 ycmd_settings_path=None,\\n                 working_directory=None,\\n                 python_binary_path=None,\\n                 server_idle_suicide_seconds=None,\\n                 server_check_interval_seconds=None):\\n        self._ycmd_root_directory = None\\n        self._ycmd_settings_path = None\\n\\n        self._working_directory = None\\n        self._python_binary_path = None\\n        self._server_idle_suicide_seconds = None\\n        self._server_check_interval_seconds = None\\n\\n        \\n        self._log_level = None\\n        self._stdout_log_path = None\\n        self._stderr_log_path = None\\n        self._keep_logs = None\\n\\n        self.ycmd_root_directory = ycmd_root_directory\\n        self.ycmd_settings_path = ycmd_settings_path\\n        self.working_directory = working_directory\\n        self.python_binary_path = python_binary_path\\n        self.server_idle_suicide_seconds = server_idle_suicide_seconds\\n        self.server_check_interval_seconds = server_check_interval_seconds\\n\\n    @property\\n    def ycmd_root_directory(self):\\n        if self._ycmd_root_directory is None:\\n            logger.warning('no ycmd root directory has been set')\\n        return self._ycmd_root_directory\\n\\n    @ycmd_root_directory.setter\\n    def ycmd_root_directory(self, ycmd_root_directory):\\n        if ycmd_root_directory is not None and \\\\\\n                not isinstance(ycmd_root_directory, str):\\n            raise TypeError(ycmd_root_directory,)\\n        self._ycmd_root_directory = ycmd_root_directory\\n\\n    @property\\n    def ycmd_settings_path(self):\\n        if self._ycmd_settings_path is None:\\n            if self._ycmd_root_directory is not None:\\n                return get_default_settings_path(self._ycmd_root_directory)\\n            logger.warning('no ycmd root directory has been set')\\n\\n        return self._ycmd_settings_path\\n\\n    @ycmd_settings_path.setter\\n    def ycmd_settings_path(self, ycmd_settings_path):\\n        if ycmd_settings_path is not None and \\\\\\n                not isinstance(ycmd_settings_path, str):\\n            raise TypeError(ycmd_settings_path,)\\n        self._ycmd_settings_path = ycmd_settings_path\\n\\n    @property\\n    def working_directory(self):\\n        if self._working_directory is None:\\n            return os.getcwd()\\n        return self._working_directory\\n\\n    @working_directory.setter\\n    def working_directory(self, working_directory):\\n        if working_directory is not None and \\\\\\n                not isinstance(working_directory, str):\\n            raise TypeError(working_directory,)\\n        self._working_directory = working_directory\\n\\n    @property\\n    def python_binary_path(self):\\n        if self._python_binary_path is None:\\n            return default_python_binary_path()\\n        return self._python_binary_path\\n\\n    @python_binary_path.setter\\n    def python_binary_path(self, python_binary_path):\\n        if python_binary_path is not None and \\\\\\n                not isinstance(python_binary_path, str):\\n            raise TypeError(python_binary_path,)\\n        self._python_binary_path = python_binary_path\\n\\n    @property\\n    def server_idle_suicide_seconds(self):\\n        if self._server_idle_suicide_seconds is None:\\n            return YCMD_DEFAULT_SERVER_IDLE_SUICIDE_SECONDS\\n        return self._server_idle_suicide_seconds\\n\\n    @server_idle_suicide_seconds.setter\\n    def server_idle_suicide_seconds(self, server_idle_suicide_seconds):\\n        if server_idle_suicide_seconds is not None and \\\\\\n                not isinstance(server_idle_suicide_seconds, int):\\n            raise TypeError(server_idle_suicide_seconds,)\\n        self._server_idle_suicide_seconds = server_idle_suicide_seconds\\n\\n    @property\\n    def server_check_interval_seconds(self):\\n        if self._server_check_interval_seconds is None:\\n            return YCMD_DEFAULT_SERVER_CHECK_INTERVAL_SECONDS\\n        return self._server_check_interval_seconds\\n\\n    @server_check_interval_seconds.setter\\n    def server_check_interval_seconds(self, server_check_interval_seconds):\\n        if server_check_interval_seconds is not None and \\\\\\n                not isinstance(server_check_interval_seconds, int):\\n            raise TypeError(server_check_interval_seconds,)\\n        self._server_check_interval_seconds = server_check_interval_seconds\\n\\n    @property\\n    def log_level(self):\\n        return self._log_level\\n\\n    @log_level.setter\\n    def log_level(self, log_level):\\n        if log_level is not None and not isinstance(log_level, str):\\n            raise TypeError('log level must be a str: %r' % (log_level))\\n\\n        if log_level is not None and not _is_valid_log_level(log_level):\\n            logger.warning('log level unrecognized: %r', log_level)\\n            \\n\\n        self._log_level = log_level\\n\\n    @property\\n    def stdout_log_path(self):\\n        return self._stdout_log_path\\n\\n    @stdout_log_path.setter\\n    def stdout_log_path(self, stdout_log_path):\\n        if stdout_log_path is not None and \\\\\\n                not isinstance(stdout_log_path, str):\\n            raise TypeError(\\n                'stdout log path must be a str: %r' % (stdout_log_path)\\n            )\\n        self._stdout_log_path = stdout_log_path\\n\\n    @property\\n    def stderr_log_path(self):\\n        return self._stderr_log_path\\n\\n    @stderr_log_path.setter\\n    def stderr_log_path(self, stderr_log_path):\\n        if stderr_log_path is not None and \\\\\\n                not isinstance(stderr_log_path, str):\\n            raise TypeError(\\n                'stderr_log_path must be a str: %r' % (stderr_log_path)\\n            )\\n        self._stderr_log_path = stderr_log_path\\n\\n    @property\\n    def keep_logs(self):\\n        if self._keep_logs is None:\\n            return False\\n        return self._keep_logs\\n\\n    @keep_logs.setter\\n    def keep_logs(self, keep_logs):\\n        if keep_logs is not None and not isinstance(keep_logs, bool):\\n            raise TypeError('keep-logs must be a bool: %r' % (keep_logs))\\n        self._keep_logs = keep_logs\\n\\n    @property\\n    def ycmd_module_directory(self):\\n        if self._ycmd_root_directory is None:\\n            logger.error('no ycmd root directory set')\\n            raise AttributeError\\n        return os.path.join(self._ycmd_root_directory, 'ycmd')\\n\\n    def copy(self):\\n        \\n        raw_attrs = [\\n            '_ycmd_root_directory',\\n            '_ycmd_settings_path',\\n            '_working_directory',\\n            '_python_binary_path',\\n            '_server_idle_suicide_seconds',\\n            '_server_check_interval_seconds',\\n            '_log_level',\\n            '_stdout_log_path',\\n            '_stderr_log_path',\\n            '_keep_logs',\\n        ]\\n        result = StartupParameters()\\n\\n        for attr in raw_attrs:\\n            attr_value = getattr(self, attr)\\n            setattr(result, attr, attr_value)\\n\\n        return result\\n\\n    def __iter__(self):\\n        \\n        return iter((\\n            ('ycmd_root_directory', self.ycmd_root_directory),\\n            ('ycmd_settings_path', self.ycmd_settings_path),\\n            ('working_directory', self.working_directory),\\n            ('python_binary_path', self.python_binary_path),\\n            ('server_idle_suicide_seconds', self.server_idle_suicide_seconds),\\n            (\\n                'server_check_interval_seconds',\\n                self.server_check_interval_seconds,\\n            ),\\n            ('ycmd_module_directory', self.ycmd_module_directory),\\n            ('log_level', self.log_level),\\n            ('stdout_log_path', self.stdout_log_path),\\n            ('stderr_log_path', self.stderr_log_path),\\n            ('keep_logs', self.keep_logs),\\n        ))\\n\\n    def __str__(self):\\n        return (\\n            'ycmd path, default settings path, '\\n            'python binary path, working directory: '\\n            '%(ycmd_root_directory)s, %(ycmd_settings_path)s, '\\n            '%(python_binary_path)s, %(working_directory)s' %\\n            (dict(self))\\n        )\\n\\n    def __repr__(self):\\n        return '%s(%r)' % (StartupParameters, dict(self))\\n\\n\\ndef to_startup_parameters(ycmd_root_directory,\\n                          ycmd_settings_path=None,\\n                          working_directory=None,\\n                          python_binary_path=None,\\n                          server_idle_suicide_seconds=None,\\n                          server_check_interval_seconds=None):\\n    \\n    if isinstance(ycmd_root_directory, StartupParameters):\\n        \\n        \\n        \\n        if ycmd_settings_path is not None:\\n            logger.warning(\\n                'ycmd settings path will be ignored: %s', ycmd_settings_path,\\n            )\\n        if working_directory is not None:\\n            logger.warning(\\n                'working directory will be ignored: %s', working_directory,\\n            )\\n        if python_binary_path is not None:\\n            logger.warning(\\n                'python binary path will be ignored: %s', python_binary_path,\\n            )\\n        if server_idle_suicide_seconds is not None:\\n            logger.warning(\\n                'server idle suicide seconds will be ignored: %s',\\n                server_idle_suicide_seconds,\\n            )\\n        if server_check_interval_seconds is not None:\\n            logger.warning(\\n                'server check interval seconds will be ignored: %s',\\n                server_check_interval_seconds,\\n            )\\n\\n        return ycmd_root_directory\\n\\n    \\n    logger.warning('[DEPRECATED] to startup parameters', stack_info=True)\\n    logger.debug(\\n        'generating startup parameters with root: %s', ycmd_root_directory,\\n    )\\n\\n    return StartupParameters(\\n        ycmd_root_directory,\\n        ycmd_settings_path=ycmd_settings_path,\\n        working_directory=working_directory,\\n        python_binary_path=python_binary_path,\\n        server_idle_suicide_seconds=server_idle_suicide_seconds,\\n        server_check_interval_seconds=server_check_interval_seconds,\\n    )\\n\\n\\ndef check_startup_parameters(startup_parameters):\\n    \\n    if not isinstance(startup_parameters, StartupParameters):\\n        raise TypeError(\\n            'startup parameters must be StartupParameters: %r' %\\n            (startup_parameters)\\n        )\\n\\n    ycmd_root_directory = startup_parameters.ycmd_root_directory\\n    if not ycmd_root_directory:\\n        raise RuntimeError('no ycmd root directory has been set')\\n\\n    ycmd_settings_path = startup_parameters.ycmd_settings_path\\n    if not ycmd_settings_path:\\n        raise RuntimeError('no ycmd default settings path has been set')\\n\\n    logger.debug(\\n        'startup parameters seem to be filled in, '\\n        'ready to attempt startup: %r', startup_parameters,\\n    )\\n\\n\\ndef write_ycmd_settings_file(ycmd_settings_path, ycmd_hmac_secret, out=None):\\n    \\n    ycmd_settings_data = generate_settings_data(\\n        ycmd_settings_path, ycmd_hmac_secret,\\n    )\\n\\n    out_path = None\\n\\n    if out is None:\\n        \\n        temp_file_object = tempfile.NamedTemporaryFile(\\n            prefix='ycmd_settings_', suffix='.json', delete=False,\\n        )\\n        temp_file_name = temp_file_object.name\\n        temp_file_handle = temp_file_object.file    \\n\\n        out = temp_file_handle\\n        out_path = temp_file_name\\n\\n        def flush():\\n            temp_file_handle.flush()\\n\\n        def close():\\n            temp_file_object.close()\\n    else:\\n        raise NotImplementedError('unimplemented: output to specific file')\\n\\n    if out_path is None and out is not None:\\n        logger.error('failed to get path for output file: %r', out)\\n        \\n\\n    save_json_file(out, ycmd_settings_data)\\n\\n    flush()\\n    close()\\n\\n    logger.debug('successfully wrote file: %s', out_path)\\n    return out_path\\n\\n\\ndef prepare_ycmd_process(startup_parameters, ycmd_settings_tempfile_path,\\n                         ycmd_server_hostname, ycmd_server_port):\\n    \\n    assert isinstance(startup_parameters, StartupParameters), \\\\\\n        'startup parameters must be StartupParameters: %r' % \\\\\\n        (startup_parameters)\\n    assert isinstance(ycmd_settings_tempfile_path, str), \\\\\\n        'ycmd settings temporary file path must be a str: %r' % \\\\\\n        (ycmd_settings_tempfile_path)\\n\\n    \\n    check_startup_parameters(startup_parameters)\\n\\n    working_directory = startup_parameters.working_directory\\n    python_binary_path = startup_parameters.python_binary_path\\n    server_idle_suicide_seconds = \\\\\\n        startup_parameters.server_idle_suicide_seconds\\n    server_check_interval_seconds = \\\\\\n        startup_parameters.server_check_interval_seconds\\n    ycmd_module_directory = startup_parameters.ycmd_module_directory\\n\\n    if YCMD_LOG_SPOOL_OUTPUT:\\n        stdout_log_spool = \\\\\\n            tempfile.SpooledTemporaryFile(max_size=YCMD_LOG_SPOOL_SIZE)\\n        stderr_log_spool = \\\\\\n            tempfile.SpooledTemporaryFile(max_size=YCMD_LOG_SPOOL_SIZE)\\n\\n        logger.debug(\\n            'using temporary spools for stdout, stderr: %r, %r',\\n            stdout_log_spool, stderr_log_spool,\\n        )\\n\\n        stdout_handle = stdout_log_spool\\n        stderr_handle = stderr_log_spool\\n    else:\\n        \\n        stdout_handle = FileHandles.DEVNULL\\n        stderr_handle = FileHandles.DEVNULL\\n\\n    ycmd_process_handle = Process()\\n\\n    ycmd_process_handle.binary = python_binary_path\\n    ycmd_process_handle.args.extend([\\n        ycmd_module_directory,\\n        '--host=%s' % (ycmd_server_hostname),\\n        '--port=%s' % (ycmd_server_port),\\n        '--idle_suicide_seconds=%s' % (server_idle_suicide_seconds),\\n        '--check_interval_seconds=%s' % (server_check_interval_seconds),\\n        '--options_file=%s' % (ycmd_settings_tempfile_path),\\n    ])\\n\\n    ycmd_process_handle.cwd = working_directory\\n    ycmd_process_handle.filehandles.stdout = stdout_handle\\n    ycmd_process_handle.filehandles.stderr = stderr_handle\\n\\n    if startup_parameters.log_level is not None:\\n        add_ycmd_debug_args(\\n            ycmd_process_handle,\\n            log_level=startup_parameters.log_level,\\n            stdout_file_name=startup_parameters.stdout_log_path,\\n            stderr_file_name=startup_parameters.stderr_log_path,\\n            keep_logfiles=startup_parameters.keep_logs,\\n        )\\n\\n    return ycmd_process_handle\\n\\n\\ndef add_ycmd_debug_args(ycmd_process_handle, log_level='info',\\n                        stdout_file_name=None, stderr_file_name=None,\\n                        keep_logfiles=False):\\n    \\n    if not isinstance(ycmd_process_handle, Process):\\n        raise TypeError(\\n            'ycmd process handle must be a Process: %r' % (ycmd_process_handle)\\n        )\\n    assert isinstance(ycmd_process_handle, Process)\\n    if ycmd_process_handle.alive():\\n        raise ValueError(\\n            'ycmd process is already started, cannot modify it: %r' %\\n            (ycmd_process_handle)\\n        )\\n\\n    if not _is_valid_log_level(log_level):\\n        logger.warning('log level unrecognized: %r', log_level)\\n        \\n\\n    ycmd_debug_args = [\\n        '--log=%s' % (log_level),\\n    ]\\n    if stdout_file_name and stderr_file_name:\\n        ycmd_debug_args.extend([\\n            '--stdout=%s' % (stdout_file_name),\\n            '--stderr=%s' % (stderr_file_name),\\n        ])\\n\\n        if keep_logfiles:\\n            ycmd_debug_args.append(\\n                '--keep_logfiles',\\n            )\\n\\n    logger.debug('adding ycmd debug args: %r', ycmd_debug_args)\\n    ycmd_process_handle.args.extend(ycmd_debug_args)\\n\\n\\ndef _is_valid_log_level(log_level):\\n    if not isinstance(log_level, str):\\n        raise TypeError('log level must be a str: %r' % (log_level))\\n\\n    \\n    recognized_log_levels = [\\n        'debug',\\n        'info',\\n        'warning',\\n        'error',\\n        'critical',\\n    ]\\n    return log_level in recognized_log_levels\\n\", 'summary': \"This code snippet appears to be part of a larger system for managing and starting a YCMD (YouCompleteMe Daemon) server. The functions provided handle various aspects of setting up and configuring the YCMD process, including:\\n\\n1. Writing configuration files for YCMD.\\n2. Preparing the environment and arguments needed to start the YCMD process.\\n3. Handling logging and output redirection.\\n4. Validating log levels.\\n\\nHere's a breakdown of some key functionalities:\\n\\n- `write_ycmd_settings`: Writes a JSON configuration file for YCMD, which includes settings like server host, port, idle timeout, etc.\\n- `prepare_ycmd_process`: Sets up the process object with the necessary binary path, arguments, working directory, and file handles (stdout/stderr).\\n- `add_ycmd_debug_args`: Adds additional arguments to the process for debugging purposes, such as setting log levels and redirecting output files.\\n\\nThe code also includes utility functions like `_is_valid_log_level` to ensure that log levels are recognized and valid.\\n\\nOverall, this code is responsible for preparing the environment and starting a YCMD server with the correct configuration and settings.\"}\n",
            "Summary: This code snippet appears to be part of a larger system for managing and starting a YCMD (YouCompleteMe Daemon) server. The functions provided handle various aspects of setting up and configuring the YCMD process, including:\n",
            "\n",
            "1. Writing configuration files for YCMD.\n",
            "2. Preparing the environment and arguments needed to start the YCMD process.\n",
            "3. Handling logging and output redirection.\n",
            "4. Validating log levels.\n",
            "\n",
            "Here's a breakdown of some key functionalities:\n",
            "\n",
            "- `write_ycmd_settings`: Writes a JSON configuration file for YCMD, which includes settings like server host, port, idle timeout, etc.\n",
            "- `prepare_ycmd_process`: Sets up the process object with the necessary binary path, arguments, working directory, and file handles (stdout/stderr).\n",
            "- `add_ycmd_debug_args`: Adds additional arguments to the process for debugging purposes, such as setting log levels and redirecting output files.\n",
            "\n",
            "The code also includes utility functions like `_is_valid_log_level` to ensure that log levels are recognized and valid.\n",
            "\n",
            "Overall, this code is responsible for preparing the environment and starting a YCMD server with the correct configuration and settings.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 7\n",
            "Entry: {'code': 'import serial\\nimport sys\\nimport struct\\nimport pprint\\nimport argparse\\nimport code\\n\\npp = pprint.PrettyPrinter()\\n\\n\\nclass ConsoleUI:\\n    def opStart(self, name):\\n        sys.stdout.write(name.ljust(40))\\n\\n    def opProgress(self, progress, total=-1):\\n        if (total >= 0):\\n            prstr = \"0x%04x / 0x%04x\" % (progress, total)\\n        else:\\n            prstr = \"0x%04x\" % (progress)\\n\\n        sys.stdout.write(prstr.ljust(20))\\n        sys.stdout.write(\\'\\\\x08\\' * 20)\\n        sys.stdout.flush()\\n\\n    def opEnd(self, result):\\n        sys.stdout.write(result.ljust(20))\\n        sys.stdout.write(\"\\\\n\")\\n\\n\\nclass XFlash:\\n    def __init__(self, serialport):\\n        self.serial = serial.Serial(serialport, baudrate=115200)\\n\\n    def __del__(self):\\n        try:\\n            self.serial.close()\\n            del self.serial\\n        except:\\n            pass\\n\\n    def cmd(self, cmd, argA=0, argB=0):\\n        buffer = struct.pack(\"<LL\", argA, argB)\\n\\n        self.serial.write(bytes([cmd]))\\n        self.serial.write(buffer)\\n        self.serial.flush()\\n\\n    def flashPowerOn(self):\\n        self.cmd(0x10)\\n\\n    def flashShutdown(self):\\n        self.cmd(0x11)\\n\\n    def update(self):\\n        try:\\n            self.cmd(0xF0)\\n        except:\\n            pass\\n\\n    def flashInit(self):\\n        self.cmd(0x03)\\n\\n        buffer = self.serial.read(4)\\n        return struct.unpack(\"<L\", buffer)[0]\\n\\n    def flashDeInit(self):\\n        self.cmd(0x04)\\n\\n    def flashStatus(self):\\n        self.cmd(0x05)\\n\\n        buffer = self.serial.read(2)\\n        return struct.unpack(\"<H\", buffer)[0]\\n\\n    def flashErase(self, block):\\n        self.cmd(0x06, block)\\n        \\n\\n    def flashReadBlock(self, block):\\n        self.cmd(0x01, block, 528 * 32)\\n\\n        \\n        buffer = self.serial.read(528 * 32)\\n\\n        status = self.flashStatus()\\n        return (status, buffer)\\n\\n    def flashWriteBlock(self, block, buffer):\\n        self.cmd(0x02, block, len(buffer))\\n\\n        self.serial.write(buffer)\\n\\n        return self.flashStatus()\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ndef main(argv):\\n    parser = argparse.ArgumentParser(description=\\'XBox 360 NAND Flasher\\')\\n    parser.add_argument(\\'port\\', metavar=\\'port\\', type=str,\\n                        help=\\'serial port for comms (e.g. COM5 or /dev/ttyUSB0)\\')\\n\\n    subparsers = parser.add_subparsers(title=\\'Operations\\', dest=\\'action\\')\\n\\n    parser_read = subparsers.add_parser(\\'read\\', help=\\'Dumps an image from the NAND\\')\\n    parser_read.add_argument(\\'file\\', nargs=1, type=argparse.FileType(\\'wb\\'), help=\\'The file to dump the NAND to\\')\\n    parser_read.add_argument(\\'start\\', nargs=\\'?\\', metavar=\\'start\\', action=\\'store\\', type=int, default=0,\\n                             help=\\'The block to start the action from\\')\\n    parser_read.add_argument(\\'end\\', nargs=\\'?\\', metavar=\\'end\\', action=\\'store\\', type=int, default=0x400,\\n                             help=\\'The count of blocks to perform the action to\\')\\n\\n    parser_write = subparsers.add_parser(\\'write\\', help=\\'Writes an image into the NAND\\')\\n    parser_write.add_argument(\\'file\\', nargs=1, type=argparse.FileType(\\'rb\\'), help=\\'The image file to write to the NAND\\')\\n    parser_write.add_argument(\\'start\\', nargs=\\'?\\', metavar=\\'start\\', action=\\'store\\', type=int, default=0,\\n                              help=\\'The block to start the action from\\')\\n    parser_write.add_argument(\\'end\\', nargs=\\'?\\', metavar=\\'end\\', action=\\'store\\', type=int, default=0x400,\\n                              help=\\'The count of blocks to perform the action to\\')\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    arguments = parser.parse_args(argv[1:])\\n\\n    ui = ConsoleUI()\\n\\n    xf = XFlash(arguments.port)\\n\\n    if arguments.action in (\\'erase\\', \\'write\\', \\'read\\'):\\n        try:\\n            flash_config = xf.flashInit()\\n            print(\"FlashConfig: 0x%08x\" % (flash_config))\\n            if flash_config <= 0:\\n                raise Exception(\"FlashConfig invalid!\")\\n        except Exception as e:\\n            print(\"Error!\", e)\\n            xf.flashDeInit()\\n            return 1\\n\\n    try:\\n        if arguments.action == \\'erase\\':\\n            \\n            \\n            start = arguments.start\\n            end = arguments.end\\n\\n            ui.opStart(\\'Erase\\')\\n\\n            ui.opProgress(0, end)\\n            for b in range(start, end):\\n                status = xf.flashErase(b)\\n                ui.opProgress(b + 1, end)\\n\\n            ui.opEnd(\\'0x%04x blocks OK\\' % (end))\\n\\n        if arguments.action == \\'read\\':\\n            \\n            \\n            start = arguments.start\\n            end = arguments.end\\n\\n            ui.opStart(\\'Read\\')\\n\\n            ui.opProgress(0, end)\\n            for b in range(start, end):\\n                (status, buffer) = xf.flashReadBlock(b)\\n                ui.opProgress(b + 1, end)\\n                arguments.file[0].write(buffer)\\n\\n        if arguments.action == \\'write\\':\\n            \\n            \\n\\n            start = arguments.start\\n            end = arguments.end\\n            blocksize = 528 * 32\\n\\n            ui.opStart(\\'Write\\')\\n\\n            ui.opProgress(0, end)\\n            for b in range(start, end):\\n                buffer = arguments.file[0].read(blocksize)\\n\\n                if len(buffer) < blocksize:\\n                    buffer += (\\'\\\\xFF\\' * (blocksize - len(buffer)))\\n\\n                status = xf.flashWriteBlock(b, buffer)\\n                ui.opProgress(b + 1, end)\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n    except Exception as e:\\n        raise e\\n    finally:\\n        xf.flashDeInit()\\n        return 0\\n\\nif __name__ == \\'__main__\\':\\n    sys.exit(main(sys.argv))\\n\\n', 'summary': \"This Python script is designed to interact with an Xbox 360 NAND flash memory using a serial connection. It provides functionality to read, write, and erase blocks of the NAND flash memory. Here's a summary of the key components:\\n\\n1. **ConsoleUI Class**: This class handles user interface operations such as displaying progress and status messages.\\n\\n2. **XFlash Class**: This class manages communication with the Xbox 360 NAND flash memory over a serial port. It includes methods for initializing, deinitializing, reading, writing, erasing, and checking the status of the flash memory.\\n\\n3. **Main Function**:\\n   - Parses command-line arguments to determine the operation (read, write, erase).\\n   - Initializes the `ConsoleUI` and `XFlash` objects.\\n   - Performs the selected operation based on the command-line arguments.\\n   - Handles exceptions and ensures proper cleanup by deinitializing the flash memory.\\n\\n### Key Operations:\\n- **Read**: Dumps an image from the NAND flash memory to a file.\\n- **Write**: Writes an image into the NAND flash memory from a file.\\n- **Erase**: Erases blocks of the NAND flash memory.\\n\\n### Usage:\\nThe script can be run from the command line with various options. For example:\\n```sh\\npython script.py COM5 read output.bin 0 100\\n```\\nThis command reads 100 blocks starting from block 0 and saves them to `output.bin`.\\n\\n### Error Handling:\\n- The script includes basic error handling to catch exceptions during operations and ensure the flash memory is properly deinitialized.\\n\\n### Dependencies:\\nThe script requires several Python libraries, including `serial`, `sys`, `struct`, `pprint`, `argparse`, and `code`. These are imported at the beginning of the script.\"}\n",
            "Summary: This Python script is designed to interact with an Xbox 360 NAND flash memory using a serial connection. It provides functionality to read, write, and erase blocks of the NAND flash memory. Here's a summary of the key components:\n",
            "\n",
            "1. **ConsoleUI Class**: This class handles user interface operations such as displaying progress and status messages.\n",
            "\n",
            "2. **XFlash Class**: This class manages communication with the Xbox 360 NAND flash memory over a serial port. It includes methods for initializing, deinitializing, reading, writing, erasing, and checking the status of the flash memory.\n",
            "\n",
            "3. **Main Function**:\n",
            "   - Parses command-line arguments to determine the operation (read, write, erase).\n",
            "   - Initializes the `ConsoleUI` and `XFlash` objects.\n",
            "   - Performs the selected operation based on the command-line arguments.\n",
            "   - Handles exceptions and ensures proper cleanup by deinitializing the flash memory.\n",
            "\n",
            "### Key Operations:\n",
            "- **Read**: Dumps an image from the NAND flash memory to a file.\n",
            "- **Write**: Writes an image into the NAND flash memory from a file.\n",
            "- **Erase**: Erases blocks of the NAND flash memory.\n",
            "\n",
            "### Usage:\n",
            "The script can be run from the command line with various options. For example:\n",
            "```sh\n",
            "python script.py COM5 read output.bin 0 100\n",
            "```\n",
            "This command reads 100 blocks starting from block 0 and saves them to `output.bin`.\n",
            "\n",
            "### Error Handling:\n",
            "- The script includes basic error handling to catch exceptions during operations and ensure the flash memory is properly deinitialized.\n",
            "\n",
            "### Dependencies:\n",
            "The script requires several Python libraries, including `serial`, `sys`, `struct`, `pprint`, `argparse`, and `code`. These are imported at the beginning of the script.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 8\n",
            "Entry: {'code': 'from CIM16.IEC61968.Common.ActivityRecord import ActivityRecord\\n\\nclass ComplianceEvent(ActivityRecord):\\n    \\n\\n    def __init__(self, deadline=\\'\\', *args, **kw_args):\\n        \\n        \\n        self.deadline = deadline\\n\\n        super(ComplianceEvent, self).__init__(*args, **kw_args)\\n\\n    _attrs = [\"deadline\"]\\n    _attr_types = {\"deadline\": str}\\n    _defaults = {\"deadline\": \\'\\'}\\n    _enums = {}\\n    _refs = []\\n    _many_refs = []\\n\\n', 'summary': 'This Python code defines a class `ComplianceEvent` that inherits from the `ActivityRecord` class. The `ComplianceEvent` class represents an event related to compliance, and it includes a single attribute:\\n\\n- `deadline`: A string representing the deadline for the compliance event.\\n\\nThe constructor (`__init__`) initializes the `deadline` attribute with a default value of an empty string if no value is provided. It then calls the constructor of the parent class `ActivityRecord` using `super()` to ensure that any initialization logic defined in `ActivityRecord` is also executed.\\n\\nAdditionally, the code defines several internal attributes used by the CIM (Common Information Model) framework:\\n\\n- `_attrs`: A list containing the names of the attributes for this class.\\n- `_attr_types`: A dictionary mapping attribute names to their data types.\\n- `_defaults`: A dictionary specifying default values for each attribute.\\n- `_enums`: An empty dictionary, indicating that no enumeration types are used in this class.\\n- `_refs`: An empty list, suggesting that there are no reference attributes.\\n- `_many_refs`: An empty list, implying that there are no many-to-many relationships defined.\\n\\nOverall, the `ComplianceEvent` class is designed to represent compliance-related events with a deadline attribute and follows the structure expected by the CIM framework for data modeling.'}\n",
            "Summary: This Python code defines a class `ComplianceEvent` that inherits from the `ActivityRecord` class. The `ComplianceEvent` class represents an event related to compliance, and it includes a single attribute:\n",
            "\n",
            "- `deadline`: A string representing the deadline for the compliance event.\n",
            "\n",
            "The constructor (`__init__`) initializes the `deadline` attribute with a default value of an empty string if no value is provided. It then calls the constructor of the parent class `ActivityRecord` using `super()` to ensure that any initialization logic defined in `ActivityRecord` is also executed.\n",
            "\n",
            "Additionally, the code defines several internal attributes used by the CIM (Common Information Model) framework:\n",
            "\n",
            "- `_attrs`: A list containing the names of the attributes for this class.\n",
            "- `_attr_types`: A dictionary mapping attribute names to their data types.\n",
            "- `_defaults`: A dictionary specifying default values for each attribute.\n",
            "- `_enums`: An empty dictionary, indicating that no enumeration types are used in this class.\n",
            "- `_refs`: An empty list, suggesting that there are no reference attributes.\n",
            "- `_many_refs`: An empty list, implying that there are no many-to-many relationships defined.\n",
            "\n",
            "Overall, the `ComplianceEvent` class is designed to represent compliance-related events with a deadline attribute and follows the structure expected by the CIM framework for data modeling.\n",
            "\n",
            "Processing batch batch_2.json, entry ID: 9\n",
            "Entry: {'code': 'import logging\\n\\nfrom django.db.models.query_utils import Q\\nfrom django.shortcuts import get_object_or_404\\nfrom django.utils.decorators import method_decorator\\nfrom django_filters.rest_framework import DjangoFilterBackend\\nfrom drf_yasg import openapi\\nfrom drf_yasg.openapi import Parameter\\nfrom drf_yasg.utils import no_body, swagger_auto_schema\\nfrom notifications.signals import notify\\nfrom rest_framework import mixins, status, viewsets\\nfrom rest_framework.decorators import action\\nfrom rest_framework.decorators import parser_classes as dparser_classes\\nfrom rest_framework.parsers import FormParser, JSONParser, MultiPartParser\\nfrom rest_framework.permissions import IsAuthenticated\\nfrom rest_framework.response import Response\\nfrom rest_framework_extensions.mixins import DetailSerializerMixin, NestedViewSetMixin\\n\\nfrom looking_for_group.mixins import AutoPermissionViewSetMixin, ParentObjectAutoPermissionViewSetMixin\\n\\nfrom . import models, serializers\\nfrom .signals import player_kicked, player_left\\n\\nlogger = logging.getLogger(\"api\")\\n\\nparent_lookup_game__slug = Parameter(\\n    name=\"parent_lookup_game__slug\",\\n    in_=\"path\",\\n    type=\"string\",\\n    format=openapi.FORMAT_SLUG,\\n    description=\"Slug of related game object.\",\\n)\\nparent_lookup_session__slug = Parameter(\\n    name=\"parent_lookup_session__slug\",\\n    in_=\"path\",\\n    type=\"string\",\\n    format=openapi.FORMAT_SLUG,\\n    description=\"Slug of related session object.\",\\n)\\nparent_lookup_session__game__slug = Parameter(\\n    name=\"parent_lookup_session__game__slug\",\\n    in_=\"path\",\\n    type=\"string\",\\n    format=openapi.FORMAT_SLUG,\\n    description=\"Slug of related game object.\",\\n)\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"List Games\",\\n        operation_description=\"Fetch a list of game records. **NOTE**: You will probably want to filter by status at least.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"create\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Create\",\\n        operation_description=\"Create a new game posting.\",\\n        request_body=serializers.GameDataSerializer,\\n        responses={201: serializers.GameDataSerializer},\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Details\",\\n        operation_description=\"Fetch the details for the given game. **NOTE**: If you are not a member of the game, only a subset of the available information will be displayed.\",\\n        responses={\\n            200: serializers.GameDataSerializer,\\n            403: \"You are not authorized to view this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Update\",\\n        operation_description=\"Update the details of this game. (Only available to GM)\",\\n        request_body=serializers.GameDataSerializer,\\n        responses={\\n            200: serializers.GameDataSerializer,\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"partial_update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Update\",\\n        operation_description=\"Update the details of this game. (Only available to GM)\",\\n        request_body=serializers.GameDataSerializer,\\n        responses={\\n            200: serializers.GameDataSerializer,\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"destroy\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Delete\",\\n        operation_description=\"Delete the given game. (Only available to GM.)\",\\n        request_body=no_body,\\n        responses={204: \"Game was deleted.\", 403: \"You are not the GM of this game.\"},\\n    ),\\n)\\n@method_decorator(\\n    name=\"leave\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Leave\",\\n        operation_description=\"Leave the current game. (Players only.)\",\\n        request_body=no_body,\\n        reponses={\\n            204: \"You have successfully left the game.\",\\n            400: \"You are not a member of this game.\",\\n            403: \"You are the GM and cannot leave.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"apply\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Apply\",\\n        operation_description=\"Apply to join this game.\",\\n        request_body=serializers.GameApplicationSerializer,\\n        responses={\\n            201: serializers.GameApplicationSerializer,\\n            400: \"You are already a member of this game.\",\\n            403: \"You are not permitted to apply to this game either due to your access rights or the game\\'s status.\",\\n        },\\n    ),\\n)\\nclass GamePostingViewSet(\\n    AutoPermissionViewSetMixin,\\n    DetailSerializerMixin,\\n    NestedViewSetMixin,\\n    viewsets.ModelViewSet,\\n):\\n    \\n\\n    permission_classes = (IsAuthenticated,)\\n    parser_classes = [FormParser, MultiPartParser]\\n    model = models.GamePosting\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    serializer_class = serializers.GameDataListSerializer\\n    serializer_detail_class = serializers.GameDataSerializer\\n    filter_backends = [DjangoFilterBackend]\\n    filterset_fields = [\\n        \"published_game\",\\n        \"game_system\",\\n        \"published_module\",\\n        \"status\",\\n        \"game_type\",\\n        \"game_mode\",\\n    ]\\n    permission_type_map = {\\n        **AutoPermissionViewSetMixin.permission_type_map,\\n        \"apply\": \"apply\",\\n        \"leave\": \"leave\",\\n    }\\n\\n    def get_queryset(self):\\n        gamer = self.request.user.gamerprofile\\n        friends = gamer.friends.all()\\n        communities = [f.id for f in gamer.communities.all()]\\n        game_player_ids = [\\n            obj.game.id\\n            for obj in models.Player.objects.filter(gamer=gamer).select_related(\"game\")\\n        ]\\n        q_gm = Q(gm=gamer)\\n        q_gm_is_friend = Q(gm__in=friends) & Q(privacy_level=\"community\")\\n        q_isplayer = Q(id__in=game_player_ids)\\n        q_community = Q(communities__id__in=communities) & Q(privacy_level=\"community\")\\n        q_public = Q(privacy_level=\"public\")\\n        qs = models.GamePosting.objects.filter(\\n            q_gm | q_public | q_gm_is_friend | q_isplayer | q_community\\n        ).distinct()\\n        return qs\\n\\n    def create(self, request, *args, **kwargs):\\n        self.serializer_class = serializers.GameDataSerializer\\n        return super().create(request, *args, **kwargs)\\n\\n    def retrieve(self, request, *args, **kwargs):\\n        if not request.user.has_perm(\"game.is_member\", self.get_object()):\\n            logger.debug(\\n                \"User is not a member of game, swtiching serializer to list view mode.\"\\n            )\\n            self.serializer_detail_class = serializers.GameDataListSerializer\\n        return super().retrieve(request, *args, **kwargs)\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def apply(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        logger.debug(\"Retrieved game object of {}\".format(obj))\\n        if request.user.has_perm(\"game.is_member\", obj):\\n            return Response(\\n                data={\"errors\": \"You are already in this game...\"},\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        new_application = serializers.GameApplicationSerializer(\\n            data=request.data, context={\"request\": request}\\n        )\\n        if not new_application.is_valid():\\n            return Response(\\n                data=new_application.errors, status=status.HTTP_400_BAD_REQUEST\\n            )\\n        app = models.GamePostingApplication.objects.create(\\n            game=obj,\\n            gamer=request.user.gamerprofile,\\n            message=new_application.validated_data[\"message\"],\\n            status=\"pending\",\\n        )\\n        notify.send(\\n            request.user.gamerprofile,\\n            recipient=obj.gm.user,\\n            verb=\"submitted application\",\\n            action_object=app,\\n            target=obj,\\n        )\\n        return Response(\\n            data=serializers.GameApplicationSerializer(\\n                app, context={\"request\": request}\\n            ).data,\\n            status=status.HTTP_201_CREATED,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def leave(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        if request.user == obj.gm.user:\\n            return Response(\\n                data={\"errors\": \"The GM cannot leave the game.\"},\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        player = models.Player.objects.get(gamer=request.user.gamerprofile, game=obj)\\n        player_left.send(models.Player, player=player)\\n        player.delete()\\n        return Response(status=status.HTTP_204_NO_CONTENT)\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: List Sessions\",\\n        operation_description=\"List the sessions for the given game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Details\",\\n        operation_description=\"Get the details for the given session. **NOTE**: If the user is just a player, the GM notes and player details will not be included.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            403: \"You are not a member of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Update\",\\n        operation_description=\"Update details of the game session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.GameSessionGMSerializer,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"partial_update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Update\",\\n        operation_description=\"Update details of the game session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.GameSessionGMSerializer,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"destroy\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Delete\",\\n        operation_description=\"Delete the game session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.GameSessionGMSerializer,\\n        responses={\\n            204: \"Session was deleted.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"cancel\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Cancel\",\\n        operation_description=\"Cancel the game session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            400: \"This session is already canceled or complete.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"uncancel\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Uncancel\",\\n        operation_description=\"Uncancel the game session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            400: \"This session is not canceled.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"complete\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Mark Complete\",\\n        operation_description=\"Mark the game session as complete.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            400: \"This session is already canceled or complete.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"uncomplete\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Uncomplete\",\\n        operation_description=\"Undo the completion status of the session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            400: \"This session isn\\'t marked as complete.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"reschedule\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Reschedule\",\\n        operation_description=\"Reschedule the game session to another date/time.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.ScheduleSerializer,\\n        responses={\\n            200: serializers.GameSessionGMSerializer,\\n            400: \"Your date and time were invalid or the session is already marked as complete or canceled.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"addlog\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Session: Add Adventure Log\",\\n        operation_description=\"Add an adventure log to this session.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.AdventureLogSerializer,\\n        responses={\\n            201: serializers.AdventureLogSerializer,\\n            400: \"This session already has an adventure log. You should update that instead.\",\\n            403: \"You don\\'t have permission to add an adventure log.\",\\n        },\\n    ),\\n)\\nclass GameSessionViewSet(\\n    ParentObjectAutoPermissionViewSetMixin,\\n    NestedViewSetMixin,\\n    mixins.ListModelMixin,\\n    mixins.RetrieveModelMixin,\\n    mixins.UpdateModelMixin,\\n    mixins.DestroyModelMixin,\\n    viewsets.GenericViewSet,\\n):\\n    \\n\\n    model = models.GameSession\\n    serializer_class = serializers.GameSessionSerializer\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    parent_dependent_actions = [\\n        \"create\",\\n        \"retrieve\",\\n        \"update\",\\n        \"partial_update\",\\n        \"list\",\\n        \"destroy\",\\n        \"reschedule\",\\n        \"cancel\",\\n        \"uncancel\",\\n        \"addlog\",\\n        \"complete\",\\n        \"uncomplete\",\\n    ]\\n    parent_lookup_field = \"game\"\\n    parent_object_model = models.GamePosting\\n    parent_object_lookup_field = \"slug\"\\n    parent_object_url_kwarg = \"parent_lookup_game__slug\"\\n    permission_type_map = {\\n        **ParentObjectAutoPermissionViewSetMixin.permission_type_map,\\n        \"addlog\": \"view\",\\n        \"reschedule\": \"change\",\\n        \"cancel\": \"change\",\\n        \"uncancel\": \"change\",\\n        \"complete\": \"change\",\\n        \"uncomplete\": \"change\",\\n    }\\n    permission_type_map[\"list\"] = \"view\"\\n\\n    def get_parent_game(self):\\n        return get_object_or_404(\\n            models.GamePosting, slug=self.kwargs[\"parent_lookup_game__slug\"]\\n        )\\n\\n    def get_queryset(self):\\n        return self.model.objects.filter(\\n            game__slug=self.kwargs[\"parent_lookup_game__slug\"]\\n        ).order_by(\"-scheduled_time\")\\n\\n    def dispatch(self, request, *args, **kwargs):\\n        if (\\n            request.user.is_authenticated\\n            and request.user.gamerprofile == self.get_parent_game().gm\\n        ):\\n            self.serializer_class = serializers.GameSessionGMSerializer\\n        return super().dispatch(request, *args, **kwargs)\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def reschedule(self, request, *args, **kwargs):\\n        date_serializer = serializers.ScheduleSerializer(data=request.data)\\n        if not date_serializer.is_valid():\\n            return Response(\\n                data=date_serializer.errors, status=status.HTTP_400_BAD_REQUEST\\n            )\\n        obj = self.get_object()\\n        if obj.status in [\"complete\", \"cancel\"]:\\n            return Response(\\n                data={\\n                    \"errors\": \"This session is already marked as {} and cannot be rescheduled.\".format(\\n                        obj.get_status_display()\\n                    )\\n                },\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        obj.move(date_serializer.validated_data[\"new_scheduled_time\"])\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def complete(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        if obj.status in [\"complete\", \"cancel\"]:\\n            return Response(\\n                data={\\n                    \"errors\": \"This object is either already completed or canceled and cannot be toggled to complete.\"\\n                },\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        obj.status = \"complete\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def uncomplete(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        if obj.status != \"complete\":\\n            return Response(\\n                data={\\n                    \"errors\": \"This object is not completed and so completion cannot be undone.\"\\n                },\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        obj.status = \"pending\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def cancel(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        if obj.status in [\"complete\", \"cancel\"]:\\n            return Response(\\n                data={\"errors\": \"This session is already completed or canceled.\"},\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        obj.cancel()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def uncancel(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        if obj.status != \"cancel\":\\n            return Response(\\n                data={\\n                    \"errors\": \"This session is not canceled and can\\'t be changed this way.\"\\n                },\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n        obj.uncancel()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def addlog(self, request, *args, **kwargs):\\n        \\n        session = self.get_object()\\n        if hasattr(session, \"adventurelog\"):\\n            return Response(\\n                data={\"errors\": \"This session already has an adventure log.\"},\\n                status=status.HTTP_400_BAD_REQUEST,\\n            )\\n\\n        log_serializer = serializers.AdventureLogSerializer(\\n            session=session, data=request.data, context={\"request\": request}\\n        )\\n        if not log_serializer.is_valid():\\n            return Response(\\n                data=log_serializer.errors, status=status.HTTP_400_BAD_REQUEST\\n            )\\n        new_log = log_serializer.save()\\n        return Response(\\n            data=serializers.AdventureLogSerializer(\\n                new_log, context={\"request\": request}\\n            ).data,\\n            status=status.HTTP_201_CREATED,\\n        )\\n\\n\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Adventure Log: Details\",\\n        operation_description=\"Fetch the details for a given adventure log.\",\\n        manual_parameters=[\\n            parent_lookup_session__game__slug,\\n            parent_lookup_session__slug,\\n        ],\\n        responses={\\n            200: serializers.AdventureLogSerializer,\\n            403: \"You are not a member of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Adventure Log: Update\",\\n        operation_description=\"Update the details for a given adventure log.\",\\n        manual_parameters=[\\n            parent_lookup_session__game__slug,\\n            parent_lookup_session__slug,\\n        ],\\n        request_body=serializers.AdventureLogSerializer,\\n        responses={\\n            200: serializers.AdventureLogSerializer,\\n            403: \"You don\\'t have permissions to edit this adventure log.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"partial_update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Adventure Log: Update\",\\n        operation_description=\"Update the details for a given adventure log.\",\\n        manual_parameters=[\\n            parent_lookup_session__game__slug,\\n            parent_lookup_session__slug,\\n        ],\\n        request_body=serializers.AdventureLogSerializer,\\n        responses={\\n            200: serializers.AdventureLogSerializer,\\n            403: \"You don\\'t have permissions to edit this adventure log.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"destroy\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Adventure Log: Delete\",\\n        operation_description=\"Delete a given adventure log.\",\\n        manual_parameters=[\\n            parent_lookup_session__game__slug,\\n            parent_lookup_session__slug,\\n        ],\\n        request_body=no_body,\\n        responses={\\n            204: \"The adventure log was successfully deleted.\",\\n            403: \"You don\\'t have permissions to edit this adventure log.\",\\n        },\\n    ),\\n)\\nclass AdventureLogViewSet(\\n    ParentObjectAutoPermissionViewSetMixin,\\n    NestedViewSetMixin,\\n    mixins.RetrieveModelMixin,\\n    mixins.UpdateModelMixin,\\n    mixins.DestroyModelMixin,\\n    viewsets.GenericViewSet,\\n):\\n    \\n\\n    model = models.AdventureLog\\n    parent_lookup_field = \"session__game\"\\n    parent_object_model = models.GamePosting\\n    parent_object_lookup_field = \"slug\"\\n    parent_object_url_kwarg = \"parent_lookup_session__game__slug\"\\n    serializer_class = serializers.AdventureLogSerializer\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    permission_required = \"game.is_member\"\\n    permission_type_map = {**ParentObjectAutoPermissionViewSetMixin.permission_type_map}\\n    permission_type_map[\"list\"] = \"add\"\\n    parent_dependent_actions = [\\n        \"create\",\\n        \"retrieve\",\\n        \"update\",\\n        \"partial_update\",\\n        \"destroy\",\\n    ]\\n\\n    def get_queryset(self):\\n        return models.AdventureLog.objects.filter(\\n            session__slug=self.kwargs[\"parent_lookup_session__slug\"]\\n        )\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"List Your Game Applications\",\\n        operation_description=\"Fetch a list of all your game applications.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Game Application: Details\",\\n        operation_description=\"Fetch the details of your game application.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Game Application: Update\",\\n        operation_description=\"Update the details of your game application.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"partial_update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Game Application: Update\",\\n        operation_description=\"Update the details of your game application.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"destroy\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Game Application: Withdraw\",\\n        operation_description=\"Withdraw your game application by deleting the record.\",\\n    ),\\n)\\nclass GameApplicationViewSet(\\n    AutoPermissionViewSetMixin,\\n    mixins.ListModelMixin,\\n    mixins.RetrieveModelMixin,\\n    mixins.UpdateModelMixin,\\n    mixins.DestroyModelMixin,\\n    viewsets.GenericViewSet,\\n):\\n    \\n\\n    permission_classes = (IsAuthenticated,)\\n    serializer_class = serializers.GameApplicationSerializer\\n    filter_backends = [DjangoFilterBackend]\\n    filterset_fields = [\"status\"]\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    permission_type_map = {**AutoPermissionViewSetMixin.permission_type_map}\\n\\n    def get_queryset(self):\\n        logger.debug(\"Fetching gamerprofile from request...\")\\n        gamer = self.request.user.gamerprofile\\n        logger.debug(\"Fetching game applications for gamer {}\".format(gamer))\\n        qs = models.GamePostingApplication.objects.filter(\\n            gamer=self.request.user.gamerprofile\\n        ).order_by(\"-modified\", \"-created\", \"status\")\\n        logger.debug(\\n            \"Retrieved queryset of length {} for gamer {}\".format(\\n                qs.count(), self.request.user.gamerprofile\\n            )\\n        )\\n        return qs\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"List Applicants for Game\",\\n        operation_description=\"List the applicants for the current game. (GM Only)\",\\n        manual_parameters=[parent_lookup_game__slug],\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Applicant: Details\",\\n        operation_description=\"Fetch details for a given game application. (GM Only)\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        reponses={\\n            200: serializers.GameApplicationGMSerializer,\\n            403: \"You are not the GM for this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"approve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Applicant: Approve\",\\n        operation_description=\"Approve the game applicant and add as a player to game.\",\\n        request_body=no_body,\\n        responses={\\n            201: serializers.PlayerSerializer,\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"reject\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game Applicant: Reject\",\\n        operation_description=\"Reject the game applicant.\",\\n        request_body=no_body,\\n        responses={\\n            200: serializers.GameApplicationGMSerializer,\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\nclass GMGameApplicationViewSet(\\n    ParentObjectAutoPermissionViewSetMixin,\\n    NestedViewSetMixin,\\n    mixins.ListModelMixin,\\n    mixins.RetrieveModelMixin,\\n    viewsets.GenericViewSet,\\n):\\n    \\n\\n    permission_classes = (IsAuthenticated,)\\n    serializer_class = serializers.GameApplicationGMSerializer\\n    filter_backends = [DjangoFilterBackend]\\n    filterset_fields = [\"status\"]\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    parent_lookup_field = \"game\"\\n    parent_object_lookup_field = \"slug\"\\n    parent_object_model = models.GamePosting\\n    parent_object_url_kwarg = \"parent_lookup_game__slug\"\\n    parent_dependent_actions = [\"list\", \"retrieve\", \"approve\", \"reject\"]\\n    permission_type_map = {\\n        **ParentObjectAutoPermissionViewSetMixin.permission_type_map,\\n        \"approve\": \"approve\",\\n        \"reject\": \"approve\",\\n    }\\n    permission_type_map[\"retrieve\"] = \"approve\"\\n    permission_type_map[\"list\"] = \"approve\"\\n\\n    def get_queryset(self):\\n        return models.GamePostingApplication.objects.filter(\\n            game__slug=self.kwargs[\"parent_lookup_game__slug\"]\\n        ).exclude(status=\"new\")\\n\\n    def get_parent_game(self):\\n        return get_object_or_404(\\n            models.GamePosting, slug=self.kwargs[\"parent_lookup_game__slug\"]\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def approve(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"approve\"\\n        player = models.Player.objects.create(game=obj.game, gamer=obj.gamer)\\n        obj.save()\\n        return Response(\\n            data=serializers.PlayerSerializer(\\n                player, context={\"request\", request}\\n            ).data,\\n            status=status.HTTP_201_CREATED,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def reject(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"deny\"\\n        obj.save()\\n        notify.send(\\n            obj,\\n            recipient=obj.gamer.user,\\n            verb=\"Your player application was not accepted\",\\n            action_object=obj,\\n            target=obj.game,\\n        )\\n        return Response(\\n            data=serializers.GameApplicationSerializer(\\n                obj, context={\"request\": request}\\n            ).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Player List\",\\n        operation_description=\"List players for a given game\",\\n        manual_parameters=[parent_lookup_game__slug],\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Player: Details\",\\n        operation_description=\"Details for a player record in a given game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        responses={\\n            200: serializers.PlayerSerializer,\\n            403: \"You are not a member of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"kick\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Player: Kick from game\",\\n        operation_description=\"Kick the player out of the game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            204: \"Player was removed from the game.\",\\n            403: \"You are not the GM of this game.\",\\n        },\\n    ),\\n)\\nclass PlayerViewSet(\\n    ParentObjectAutoPermissionViewSetMixin,\\n    NestedViewSetMixin,\\n    mixins.ListModelMixin,\\n    mixins.RetrieveModelMixin,\\n    viewsets.GenericViewSet,\\n):\\n    \\n\\n    permission_classes = (IsAuthenticated,)\\n    serializer_class = serializers.PlayerSerializer\\n    permission_required = \"game.is_member\"\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    parent_lookup_field = \"game\"\\n    parent_object_model = models.GamePosting\\n    parent_object_lookup_field = \"slug\"\\n    parent_object_url_kwarg = \"parent_lookup_game__slug\"\\n    parent_dependent_actions = [\"list\", \"retrieve\"]\\n    permission_type_map = {**ParentObjectAutoPermissionViewSetMixin.permission_type_map}\\n    permission_type_map[\"list\"] = \"view\"\\n\\n    def get_parent_game(self):\\n        return get_object_or_404(\\n            models.GamePosting, slug=self.kwargs[\"parent_lookup_game__slug\"]\\n        )\\n\\n    def get_queryset(self):\\n        return models.Player.objects.filter(game=self.get_parent_game())\\n\\n    @action(methods=[\"post\"], detail=True)\\n    def kick(self, request, *args, **kwargs):\\n        obj = self.get_object()\\n        player_kicked.send(request.user, player=obj)\\n        obj.delete()\\n        return Response(status=status.HTTP_204_NO_CONTENT)\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: List Characters\",\\n        operation_description=\"Fetch the list of characters for a given game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Character Details\",\\n        operation_description=\"Fetch the details of a character for a given game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            403: \"You are not a member of this game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Update Character Details\",\\n        operation_description=\"Update the character for the given game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.CharacterSerializer,\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            403: \"You are not the owner of this character or the GM of the game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"partial_update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Update Character Details\",\\n        operation_description=\"Update the character for the given game.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=serializers.CharacterSerializer,\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            403: \"You are not the owner of this character or the GM of the game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"deactivate\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Deactivate Character\",\\n        operation_description=\"Mark the character as inactive.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            400: \"This character is already inactive.\",\\n            403: \"You are not the owner of this character or the GM of the game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"reactivate\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Reactivate Character\",\\n        operation_description=\"Mark the character as active.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            400: \"This character is already active.\",\\n            403: \"You are not the owner of this character or the GM of the game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"destroy\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Delete Character\",\\n        operation_description=\"Delete the character.\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            204: \"Character was deleted.\",\\n            403: \"You are not the owner of this character.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"approve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Approve Character\",\\n        operation_description=\"Mark the character as approved (GM Only).\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            400: \"This character is already approved.\",\\n            403: \"You are not the GM of the game.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"reject\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Game: Reject Character\",\\n        operation_description=\"Mark the character as rejected (GM Only).\",\\n        manual_parameters=[parent_lookup_game__slug],\\n        request_body=no_body,\\n        responses={\\n            200: serializers.CharacterSerializer,\\n            400: \"This character is already rejected.\",\\n            403: \"You are not the GM of the game.\",\\n        },\\n    ),\\n)\\nclass CharacterViewSet(\\n    ParentObjectAutoPermissionViewSetMixin, NestedViewSetMixin, viewsets.ModelViewSet\\n):\\n    \\n\\n    permission_classes = (IsAuthenticated,)\\n    parser_classes = [FormParser, MultiPartParser]\\n    parent_object_lookup_field = \"slug\"\\n    parent_object_url_kwarg = \"parent_lookup_game__slug\"\\n    parent_lookup_field = \"game\"\\n    parent_object_model = models.GamePosting\\n    parent_dependent_actions = [\"create\", \"list\", \"retrieve\"]\\n    serializer_class = serializers.CharacterSerializer\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    filter_backends = [DjangoFilterBackend]\\n    filterset_fields = [\"status\"]\\n    parent_game = None\\n    permission_type_map = {\\n        **ParentObjectAutoPermissionViewSetMixin.permission_type_map,\\n        \"approve\": \"approve\",\\n        \"reject\": \"approve\",\\n        \"deactivate\": \"delete\",\\n        \"reactivate\": \"delete\",\\n    }\\n    permission_type_map[\"list\"] = \"gamelist\"\\n\\n    def get_parent_game(self):\\n        if not self.parent_game:\\n            self.parent_game = get_object_or_404(\\n                models.GamePosting, slug=self.kwargs[\"parent_lookup_game__slug\"]\\n            )\\n        return self.parent_game\\n\\n    def get_queryset(self):\\n        return models.Character.objects.filter(game=self.get_parent_game())\\n\\n    def create(self, request, *args, **kwargs):\\n        if request.user.gamerprofile == self.get_parent_game().gm:\\n            return Response(\\n                data={\"errors\": \"Only a player can create a character.\"},\\n                status=status.HTTP_403_FORBIDDEN,\\n            )\\n        char_ser = serializers.CharacterSerializer(\\n            data=request.data,\\n            context={\"request\": request, \"game\": self.get_parent_game()},\\n        )\\n        if not char_ser.is_valid():\\n            return Response(data=char_ser.errors, status=status.HTTP_400_BAD_REQUEST)\\n        char_ser.save()\\n        return Response(data=char_ser.data, status=status.HTTP_201_CREATED)\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def approve(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"approved\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def reject(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"rejected\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def deactivate(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"inactive\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def reactivate(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"pending\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n\\n@method_decorator(\\n    name=\"list\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"List Your Characters\",\\n        operation_description=\"Fetch a list of all of your characters.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"retrieve\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Character: Details\",\\n        operation_description=\"Fetch the details of your character.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Character: Update\",\\n        operation_description=\"Update the details of your character.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"partial_update\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Character: Update\",\\n        operation_description=\"Update the details of your character.\",\\n    ),\\n)\\n@method_decorator(\\n    name=\"destroy\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Character: Delete\",\\n        operation_description=\"Delete your character.\",\\n        request_body=no_body,\\n        responses={204: \"Character was deleted.\"},\\n    ),\\n)\\n@method_decorator(\\n    name=\"deactivate\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Character: Deactivate\",\\n        operation_description=\"Mark your character as inactive.\",\\n        request_body=no_body,\\n        responses={\\n            200: \"Character was marked as inactive.\",\\n            400: \"Character was already inactive.\",\\n        },\\n    ),\\n)\\n@method_decorator(\\n    name=\"reactivate\",\\n    decorator=swagger_auto_schema(\\n        operation_summary=\"Your Character: Reactivate\",\\n        operation_description=\"Mark your character as active.\",\\n        request_body=no_body,\\n        responses={\\n            200: \"Character was marked as active.\",\\n            400: \"Character was already active.\",\\n        },\\n    ),\\n)\\nclass MyCharacterViewSet(\\n    AutoPermissionViewSetMixin,\\n    NestedViewSetMixin,\\n    mixins.ListModelMixin,\\n    mixins.RetrieveModelMixin,\\n    mixins.UpdateModelMixin,\\n    mixins.DestroyModelMixin,\\n    viewsets.GenericViewSet,\\n):\\n    \\n\\n    serializer_class = serializers.CharacterSerializer\\n    permission_classes = (IsAuthenticated,)\\n    lookup_field = \"slug\"\\n    lookup_url_kwarg = \"slug\"\\n    filter_backends = [DjangoFilterBackend]\\n    filterset_fields = [\"status\"]\\n    permission_type_map = {\\n        **AutoPermissionViewSetMixin.permission_type_map,\\n        \"deactivate\": \"delete\",\\n        \"reactivate\": \"delete\",\\n    }\\n    permission_type_map[\"retrieve\"] = \"delete\"\\n    parser_classes = [FormParser, MultiPartParser]\\n\\n    def get_queryset(self):\\n        return models.Character.objects.filter(\\n            player__gamer=self.request.user.gamerprofile\\n        )\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def deactivate(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"inactive\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @action(methods=[\"post\"], detail=True, parser_classes=[FormParser, JSONParser])\\n    def reactivate(self, request, *args, **kwargs):\\n        \\n        obj = self.get_object()\\n        obj.status = \"pending\"\\n        obj.save()\\n        return Response(\\n            data=self.serializer_class(obj, context={\"request\": request}).data,\\n            status=status.HTTP_200_OK,\\n        )\\n\\n    @dparser_classes([FormParser, JSONParser])\\n    def destroy(self, request, *args, **kwargs):\\n        self.parser_classes = [FormParser, JSONParser]\\n        return super().destroy(request, *args, **kwargs)\\n', 'summary': 'This code defines two Django REST Framework (DRF) viewsets for managing characters in a game. The first viewset, `CharacterViewSet`, is used to manage characters that belong to any player and includes actions like creating, updating, deleting, deactivating, and reactivating characters. It also has an action to list all characters.\\n\\nThe second viewset, `MyCharacterViewSet`, is specifically for managing a player\\'s own characters. It provides similar actions but restricts access to only the player\\'s own characters. This includes listing, retrieving, updating, deleting, deactivating, and reactivating characters.\\n\\nHere are some key points about the code:\\n\\n1. **Viewsets**: Both viewsets use DRF\\'s `viewsets` module, which simplifies the implementation of common patterns for building APIs.\\n\\n2. **Permissions**: The `permission_classes` attribute is set to `(IsAuthenticated,)`, meaning that only authenticated users can access these views.\\n\\n3. **Actions**: Each viewset defines several actions using the `@action` decorator. These actions correspond to different HTTP methods (GET, POST, PUT, DELETE) and perform specific operations on characters.\\n\\n4. **Querysets**: The `get_queryset` method is overridden in both viewsets to filter characters based on whether they belong to any player or a specific player.\\n\\n5. **Swagger Documentation**: The `swagger_auto_schema` decorator from the `drf_yasg` package is used to generate API documentation automatically, making it easier for developers and users to understand how to interact with the API.\\n\\n6. **Parser Classes**: The `parser_classes` attribute specifies which parsers should be used to handle incoming requests. In this case, both viewsets use `FormParser` and `MultiPartParser`.\\n\\n7. **Custom Actions**: The `deactivate` and `reactivate` actions are defined in both viewsets to change the status of a character (e.g., from \"pending\" to \"inactive\").\\n\\nOverall, this code provides a robust framework for managing characters in a game using DRF, with clear separation between public and private character management.'}\n",
            "Summary: This code defines two Django REST Framework (DRF) viewsets for managing characters in a game. The first viewset, `CharacterViewSet`, is used to manage characters that belong to any player and includes actions like creating, updating, deleting, deactivating, and reactivating characters. It also has an action to list all characters.\n",
            "\n",
            "The second viewset, `MyCharacterViewSet`, is specifically for managing a player's own characters. It provides similar actions but restricts access to only the player's own characters. This includes listing, retrieving, updating, deleting, deactivating, and reactivating characters.\n",
            "\n",
            "Here are some key points about the code:\n",
            "\n",
            "1. **Viewsets**: Both viewsets use DRF's `viewsets` module, which simplifies the implementation of common patterns for building APIs.\n",
            "\n",
            "2. **Permissions**: The `permission_classes` attribute is set to `(IsAuthenticated,)`, meaning that only authenticated users can access these views.\n",
            "\n",
            "3. **Actions**: Each viewset defines several actions using the `@action` decorator. These actions correspond to different HTTP methods (GET, POST, PUT, DELETE) and perform specific operations on characters.\n",
            "\n",
            "4. **Querysets**: The `get_queryset` method is overridden in both viewsets to filter characters based on whether they belong to any player or a specific player.\n",
            "\n",
            "5. **Swagger Documentation**: The `swagger_auto_schema` decorator from the `drf_yasg` package is used to generate API documentation automatically, making it easier for developers and users to understand how to interact with the API.\n",
            "\n",
            "6. **Parser Classes**: The `parser_classes` attribute specifies which parsers should be used to handle incoming requests. In this case, both viewsets use `FormParser` and `MultiPartParser`.\n",
            "\n",
            "7. **Custom Actions**: The `deactivate` and `reactivate` actions are defined in both viewsets to change the status of a character (e.g., from \"pending\" to \"inactive\").\n",
            "\n",
            "Overall, this code provides a robust framework for managing characters in a game using DRF, with clear separation between public and private character management.\n",
            "\n",
            "Processed batch written to batches/batch_2_processed.json\n",
            "Processing batch 3\n",
            "Processing batch batch_3.json, entry ID: 0\n",
            "Entry: {'code': 'import os\\nimport os.path\\nimport sys\\n\\nimport pytest  \\n\\nfrom mypy.test.config import test_temp_dir\\nfrom mypy.test.data import DataDrivenTestCase, DataSuite\\nfrom mypy.test.helpers import assert_string_arrays_equal\\nfrom mypy.util import try_find_python2_interpreter\\nfrom mypy import api\\n\\nthis_file_dir = os.path.dirname(os.path.realpath(__file__))\\nprefix = os.path.dirname(this_file_dir)\\ninipath = os.path.abspath(os.path.join(prefix, \\'test\\'))\\n\\n\\ntest_data_prefix = os.path.join(prefix, \\'test\\', \\'test-data\\')\\n\\n\\nclass SQLDataSuite(DataSuite):\\n    files = [\\'sqlalchemy-basics.test\\',\\n             \\'sqlalchemy-sql-elements.test\\',\\n             \\'sqlalchemy-sql-sqltypes.test\\',\\n             \\'sqlalchemy-sql-selectable.test\\',\\n             \\'sqlalchemy-sql-schema.test\\',\\n             \\'sqlalchemy-plugin-features.test\\',\\n             \\'sqlalchemy-plugin-query.test\\']\\n    data_prefix = test_data_prefix\\n\\n    def run_case(self, testcase: DataDrivenTestCase) -> None:\\n\\n        assert testcase.old_cwd is not None, \"test was not properly set up\"\\n        mypy_cmdline = [\\n            \\'--show-traceback\\',\\n            \\'--no-silence-site-packages\\',\\n            \\'--config-file={}/sqlalchemy.ini\\'.format(inipath),\\n        ]\\n        py2 = testcase.name.lower().endswith(\\'python2\\')\\n        if py2:\\n            if try_find_python2_interpreter() is None:\\n                pytest.skip()\\n                return\\n            mypy_cmdline.append(\\'--py2\\')\\n        else:\\n            mypy_cmdline.append(\\'--python-version={}\\'.format(\\'.\\'.join(map(str,\\n                                                                          sys.version_info[:2]))))\\n\\n        \\n        program_path = os.path.join(test_temp_dir, \\'main.py\\')\\n        mypy_cmdline.append(program_path)\\n        with open(program_path, \\'w\\') as file:\\n            for s in testcase.input:\\n                file.write(\\'{}\\\\n\\'.format(s))\\n        output = []\\n        \\n        out, err, returncode = api.run(mypy_cmdline)\\n        \\n        for line in (out + err).splitlines():\\n            if line.startswith(test_temp_dir + os.sep):\\n                output.append(line[len(test_temp_dir + os.sep):].rstrip(\"\\\\r\\\\n\").replace(\\'.py\\',\\n                                                                                        \\'\\'))\\n            else:\\n                output.append(line.rstrip(\"\\\\r\\\\n\"))\\n        \\n        os.remove(program_path)\\n        assert_string_arrays_equal(testcase.output, output,\\n                                   \\'Invalid output ({}, line {})\\'.format(\\n                                   testcase.file, testcase.line))\\n', 'summary': \"This Python code is a test suite for the `mypy` static type checker, specifically focusing on testing SQLAlchemy-related code. Here's a summary of what it does:\\n\\n1. **Imports and Setup**:\\n   - Imports necessary modules like `os`, `sys`, `pytest`, and others.\\n   - Defines paths and configurations for the test environment.\\n\\n2. **Class Definition**:\\n   - Defines a class `SQLDataSuite` that inherits from `DataSuite`.\\n   - This class is designed to run tests on SQLAlchemy-related code.\\n\\n3. **Test Files**:\\n   - Specifies a list of test files (`files`) that contain test cases for SQLAlchemy.\\n   - Sets the data prefix for these test files.\\n\\n4. **Running Test Cases**:\\n   - The `run_case` method is overridden to handle running each test case.\\n   - It constructs the command line arguments for `mypy` based on whether the test is for Python 2 or Python 3.\\n   - Writes the input code from the test case to a temporary file (`main.py`).\\n   - Runs `mypy` using the constructed command line and captures its output.\\n   - Processes the output to remove paths and replace `.py` extensions with nothing.\\n   - Asserts that the actual output matches the expected output from the test case.\\n\\n5. **Cleanup**:\\n   - Removes the temporary file after running the test.\\n\\n### Key Points:\\n- **Test Environment**: The code assumes a specific directory structure for test data and configuration files.\\n- **Dynamic Command Line Arguments**: It dynamically constructs command line arguments based on the Python version and whether the test is for Python 2 or Python 3.\\n- **Temporary Files**: It uses temporary files to store the input code for each test case.\\n- **Output Processing**: It processes the output from `mypy` to make it more readable and comparable.\\n\\nThis script is designed to be run as part of a larger testing framework, likely using `pytest`, to ensure that SQLAlchemy-related code is type-checked correctly by `mypy`.\"}\n",
            "Summary: This Python code is a test suite for the `mypy` static type checker, specifically focusing on testing SQLAlchemy-related code. Here's a summary of what it does:\n",
            "\n",
            "1. **Imports and Setup**:\n",
            "   - Imports necessary modules like `os`, `sys`, `pytest`, and others.\n",
            "   - Defines paths and configurations for the test environment.\n",
            "\n",
            "2. **Class Definition**:\n",
            "   - Defines a class `SQLDataSuite` that inherits from `DataSuite`.\n",
            "   - This class is designed to run tests on SQLAlchemy-related code.\n",
            "\n",
            "3. **Test Files**:\n",
            "   - Specifies a list of test files (`files`) that contain test cases for SQLAlchemy.\n",
            "   - Sets the data prefix for these test files.\n",
            "\n",
            "4. **Running Test Cases**:\n",
            "   - The `run_case` method is overridden to handle running each test case.\n",
            "   - It constructs the command line arguments for `mypy` based on whether the test is for Python 2 or Python 3.\n",
            "   - Writes the input code from the test case to a temporary file (`main.py`).\n",
            "   - Runs `mypy` using the constructed command line and captures its output.\n",
            "   - Processes the output to remove paths and replace `.py` extensions with nothing.\n",
            "   - Asserts that the actual output matches the expected output from the test case.\n",
            "\n",
            "5. **Cleanup**:\n",
            "   - Removes the temporary file after running the test.\n",
            "\n",
            "### Key Points:\n",
            "- **Test Environment**: The code assumes a specific directory structure for test data and configuration files.\n",
            "- **Dynamic Command Line Arguments**: It dynamically constructs command line arguments based on the Python version and whether the test is for Python 2 or Python 3.\n",
            "- **Temporary Files**: It uses temporary files to store the input code for each test case.\n",
            "- **Output Processing**: It processes the output from `mypy` to make it more readable and comparable.\n",
            "\n",
            "This script is designed to be run as part of a larger testing framework, likely using `pytest`, to ensure that SQLAlchemy-related code is type-checked correctly by `mypy`.\n",
            "\n",
            "Processing batch batch_3.json, entry ID: 1\n",
            "Entry: {'code': 'from __future__ import print_function\\nimport argparse\\nimport hashlib\\nimport os\\nimport sys\\nfrom gnupg import GPG\\nfrom jinja2 import Template\\n\\n\\nclass Version:\\n    def __init__(self, version):\\n        self.version = version\\n        parts = version.split(\\'.\\')\\n        if len(parts) > 2:\\n            self.major = \".\".join(parts[:2])\\n            self.patch = version\\n        else:\\n            self.major = version\\n            self.patch = None\\n\\n    def __str__(self):\\n        return self.version\\n\\n\\ndef _main():\\n    descr = \\'Generate Gerrit release announcement email text\\'\\n    parser = argparse.ArgumentParser(\\n        description=descr,\\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\\n    parser.add_argument(\\'-v\\', \\'--version\\', dest=\\'version\\',\\n                        required=True,\\n                        help=\\'gerrit version to release\\')\\n    parser.add_argument(\\'-p\\', \\'--previous\\', dest=\\'previous\\',\\n                        help=\\'previous gerrit version (optional)\\')\\n    parser.add_argument(\\'-s\\', \\'--summary\\', dest=\\'summary\\',\\n                        help=\\'summary of the release content (optional)\\')\\n    options = parser.parse_args()\\n\\n    summary = options.summary\\n    if summary and not summary.endswith(\".\"):\\n        summary = summary + \".\"\\n\\n    data = {\\n         \"version\": Version(options.version),\\n         \"previous\": options.previous,\\n         \"summary\": summary\\n    }\\n\\n    war = os.path.join(\\n        os.path.expanduser(\"~/.m2/repository/com/google/gerrit/gerrit-war/\"),\\n        \"%(version)s/gerrit-war-%(version)s.war\" % data)\\n    if not os.path.isfile(war):\\n        print(\"Could not find war file for Gerrit %s in local Maven repository\"\\n              % data[\"version\"], file=sys.stderr)\\n        sys.exit(1)\\n\\n    md5 = hashlib.md5()\\n    sha1 = hashlib.sha1()\\n    sha256 = hashlib.sha256()\\n    BUF_SIZE = 65536  \\n    with open(war, \\'rb\\') as f:\\n        while True:\\n            d = f.read(BUF_SIZE)\\n            if not d:\\n                break\\n            md5.update(d)\\n            sha1.update(d)\\n            sha256.update(d)\\n\\n    data[\"sha1\"] = sha1.hexdigest()\\n    data[\"sha256\"] = sha256.hexdigest()\\n    data[\"md5\"] = md5.hexdigest()\\n\\n    template = Template(open(\"tools/release-announcement-template.txt\").read())\\n    output = template.render(data=data)\\n\\n    filename = \"release-announcement-gerrit-%s.txt\" % data[\"version\"]\\n    with open(filename, \"w\") as f:\\n        f.write(output)\\n\\n    gpghome = os.path.abspath(os.path.expanduser(\"~/.gnupg\"))\\n    if not os.path.isdir(gpghome):\\n        print(\"Skipping signing due to missing gnupg home folder\")\\n    else:\\n        try:\\n            gpg = GPG(homedir=gpghome)\\n        except TypeError:\\n            gpg = GPG(gnupghome=gpghome)\\n        signed = gpg.sign(output)\\n        filename = filename + \".asc\"\\n        with open(filename, \"w\") as f:\\n            f.write(str(signed))\\n\\n\\nif __name__ == \"__main__\":\\n    _main()\\n', 'summary': \"This Python script is designed to generate a release announcement email for Gerrit, an open-source code review tool. Here's a summary of its functionality:\\n\\n1. **Imports and Setup**:\\n   - The script imports necessary modules such as `argparse`, `hashlib`, `os`, `sys`, `gnupg`, and `jinja2`.\\n   - It uses the `print_function` from `__future__` to ensure compatibility with Python 3's print function.\\n\\n2. **Version Class**:\\n   - A `Version` class is defined to handle version strings, splitting them into major and patch components if necessary.\\n\\n3. **Main Function (`_main`)**:\\n   - The script sets up an argument parser to accept command-line arguments for the Gerrit version, previous version (optional), and a summary of the release content (optional).\\n   - It constructs a dictionary `data` containing the parsed options.\\n   - The script checks if the WAR file for the specified Gerrit version exists in the local Maven repository. If not, it prints an error message and exits.\\n\\n4. **Checksum Calculation**:\\n   - The script calculates MD5, SHA-1, and SHA-256 checksums of the WAR file using Python's `hashlib`.\\n\\n5. **Template Rendering**:\\n   - It reads a template file (`release-announcement-template.txt`) using Jinja2 templating engine.\\n   - The template is rendered with the data dictionary to generate the release announcement text.\\n\\n6. **Output File Creation**:\\n   - The script writes the generated release announcement text to a file named `release-announcement-gerrit-{version}.txt`.\\n\\n7. **GPG Signing (Optional)**:\\n   - If a GPG home directory is found, the script attempts to sign the release announcement using GPG.\\n   - The signed output is written to a file with an `.asc` extension.\\n\\n8. **Execution**:\\n   - The script checks if it's being run as the main module and calls `_main()` if so.\\n\\nThis script automates the process of generating a release announcement for Gerrit, including checksums and optional GPG signing, based on user-provided input and template files.\"}\n",
            "Summary: This Python script is designed to generate a release announcement email for Gerrit, an open-source code review tool. Here's a summary of its functionality:\n",
            "\n",
            "1. **Imports and Setup**:\n",
            "   - The script imports necessary modules such as `argparse`, `hashlib`, `os`, `sys`, `gnupg`, and `jinja2`.\n",
            "   - It uses the `print_function` from `__future__` to ensure compatibility with Python 3's print function.\n",
            "\n",
            "2. **Version Class**:\n",
            "   - A `Version` class is defined to handle version strings, splitting them into major and patch components if necessary.\n",
            "\n",
            "3. **Main Function (`_main`)**:\n",
            "   - The script sets up an argument parser to accept command-line arguments for the Gerrit version, previous version (optional), and a summary of the release content (optional).\n",
            "   - It constructs a dictionary `data` containing the parsed options.\n",
            "   - The script checks if the WAR file for the specified Gerrit version exists in the local Maven repository. If not, it prints an error message and exits.\n",
            "\n",
            "4. **Checksum Calculation**:\n",
            "   - The script calculates MD5, SHA-1, and SHA-256 checksums of the WAR file using Python's `hashlib`.\n",
            "\n",
            "5. **Template Rendering**:\n",
            "   - It reads a template file (`release-announcement-template.txt`) using Jinja2 templating engine.\n",
            "   - The template is rendered with the data dictionary to generate the release announcement text.\n",
            "\n",
            "6. **Output File Creation**:\n",
            "   - The script writes the generated release announcement text to a file named `release-announcement-gerrit-{version}.txt`.\n",
            "\n",
            "7. **GPG Signing (Optional)**:\n",
            "   - If a GPG home directory is found, the script attempts to sign the release announcement using GPG.\n",
            "   - The signed output is written to a file with an `.asc` extension.\n",
            "\n",
            "8. **Execution**:\n",
            "   - The script checks if it's being run as the main module and calls `_main()` if so.\n",
            "\n",
            "This script automates the process of generating a release announcement for Gerrit, including checksums and optional GPG signing, based on user-provided input and template files.\n",
            "\n",
            "Processing batch batch_3.json, entry ID: 2\n",
            "Entry: {'code': 'from flask import Flask, jsonify, request, make_response, redirect, url_for\\nimport jwt\\nimport datetime\\nimport os\\nfrom functools import wraps\\nfrom flask_sqlalchemy import SQLAlchemy\\nimport uuid\\nfrom werkzeug.security import generate_password_hash, check_password_hash\\nfrom werkzeug.utils import secure_filename\\nfrom sqlalchemy import select\\nfrom flask_migrate import Migrate, migrate\\nfrom flask_cors import CORS\\nfrom sqlalchemy import inspect\\nfrom sqlalchemy import Table, Column, MetaData, Integer, Computed\\nfrom numpy import array\\n\\napp = Flask(__name__)\\napp.config[\\'SECRET_KEY\\'] = \\'secretollave\\'\\napp.config[\\'SQLALCHEMY_DATABASE_URI\\'] = \\'sqlite:///todo.db\\'\\nABSOLUTE_PATH_TO_YOUR_FOLDER =\\'/home/dani/flask/static/fotosPerfil\\'\\nABSOLUTE_PATH_TO_YOUR_PDF_FOLDER =\\'/home/dani/flask/static/pdf\\'\\nCORS(app)\\ndb  = SQLAlchemy(app)\\nmigrate = Migrate(app, db)\\n\\n\\n\\nclass Usuario(db.Model):\\n    nick = db.Column(db.String(20), primary_key=True)\\n    Nombre_de_usuario = db.Column(db.String(50))\\n    password = db.Column(db.String(50))\\n    e_mail = db.Column(db.String(50), unique=True, nullable=False)\\n    descripcion  = db.Column(db.String(1000))\\n    link  = db.Column(db.String(200))\\n    foto_de_perfil = db.Column(db.String(400))\\n\\nclass Sigue(db.Model):\\n    \\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n    Usuario_Nickb = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n\\nclass Chat(db.Model):\\n\\n    \\n    timestamp = db.Column(db.TIMESTAMP, nullable=False,\\n                  server_default=db.func.now(),\\n                  onupdate=db.func.now())\\n\\n    mensaje  = db.Column(db.String(1000))\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n    Usuario_Nickb = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n\\n\\nclass Publicacion(db.Model):\\n\\n    id  = db.Column(Integer,primary_key=True)\\n    \\n    descripcion  = db.Column(db.String(1000))\\n    \\n    timestamp = db.Column(db.TIMESTAMP, nullable=False,\\n                  server_default=db.func.now(),\\n                  onupdate=db.func.now())\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'))\\n\\nclass Propia(db.Model):\\n\\n    pdf = db.Column(db.String(400))\\n    id = db.Column(db.String(20), db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n\\n\\nclass Recomendacion(db.Model):\\n\\n    link  = db.Column(db.String(200),nullable=False)\\n    titulo = db.Column(db.String(200),nullable=False)\\n    autor  = db.Column(db.String(200),nullable=False)\\n    id = db.Column(db.String(20), db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n\\nclass Tematica(db.Model):\\n\\n    tema  = db.Column(db.String(50), primary_key=True )\\n\\n\\nclass Notificaciones(db.Model):\\n\\n    id  = db.Column(db.Integer, primary_key=True )\\n    fecha  = db.Column(db.Date)\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n\\n\\nclass Prefiere(db.Model):\\n\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n    tema = db.Column(db.String(50), db.ForeignKey(\\'tematica.tema\\'),primary_key=True)\\n\\n\\nclass Trata_pub_del_tema(db.Model):\\n\\n    id = db.Column(db.Integer, db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n    tema = db.Column(db.String(50), db.ForeignKey(\\'tematica.tema\\'),primary_key=True)\\n\\nclass Gusta(db.Model):\\n\\n    id = db.Column(db.Integer, db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n\\n\\nclass Comenta(db.Model):\\n\\n    id = db.Column(db.Integer, db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n    comentario  = db.Column(db.String(1000))\\n\\nclass Guarda(db.Model):\\n\\n    id = db.Column(db.Integer, db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n\\nclass Trata(db.Model):\\n\\n    id_publi = db.Column(db.Integer, db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n    id_notif = db.Column(db.String(20), db.ForeignKey(\\'notificaciones.id\\'),primary_key=True)\\n\\n\\nclass Genera(db.Model):\\n\\n    id = db.Column(db.Integer, db.ForeignKey(\\'publicacion.id\\'),primary_key=True)\\n    Usuario_Nicka = db.Column(db.String(20), db.ForeignKey(\\'usuario.nick\\'),primary_key=True)\\n\\n\\n\\n\\ndef token_required(f):\\n    @wraps(f)\\n    def decorated(*args, **kwargs):\\n        \\n        \\n        token = request.headers[\\'token\\']\\n        \\n        if not token:\\n            return jsonify({\\'error\\': \\'Token no existe\\'}), 403\\n\\n        try:\\n            data = jwt.decode(token, app.config[\\'SECRET_KEY\\'])\\n            current_user = Usuario.query.filter_by(nick=data[\\'nick\\']).first()\\n            current_user = data[\\'nick\\']\\n        except:\\n            return jsonify({\\'error\\': \\'Token no valido\\'}), 403\\n\\n        return f(current_user,*args, **kwargs)\\n    return decorated\\n\\ndef token_required_id(f):\\n    @wraps(f)\\n    def decorated(*args, **kwargs):\\n        \\n        \\n        token = request.headers[\\'token\\']\\n        \\n        if not token:\\n            return jsonify({\\'error\\': \\'Token no existe\\'}), 403\\n\\n        try:\\n            data = jwt.decode(token, app.config[\\'SECRET_KEY\\'])\\n            current_user = Usuario.query.filter_by(nick=data[\\'nick\\']).first()\\n            current_user = data[\\'nick\\']\\n            current_id = Publicacion.query.filter_by(id=data[\\'id\\']).first()\\n            _id = data[\\'id\\']\\n        except:\\n            return jsonify({\\'error\\': \\'Token no valido\\'}), 403\\n\\n        return f(current_user,_id,*args, **kwargs)\\n    return decorated\\n\\n\\n@app.route(\\'/unprotected\\')\\ndef unprotected():\\n    return jsonify({\\'message\\': \\'Puede entrar tol mundo\\'})\\n\\n@app.route(\\'/protected\\')\\n@token_required\\ndef protected(current_user):\\n    print(current_user)\\n    return jsonify({\\'message\\': \\'Puedes entrar si puedes\\'})\\n\\n\\n\\n\\n\\n@app.route(\\'/register\\', methods=[\\'POST\\'])\\ndef add_data():\\n    data= request.get_json()\\n    \\n    \\n    \\n\\n\\n    user = Usuario.query.filter_by(e_mail=data[\\'e_mail\\']).first()\\n    nick = Usuario.query.filter_by(nick=data[\\'nick\\']).first()\\n    if user: \\n        return jsonify({\\'error\\': \\'Existe correo\\'}) \\n    if nick:\\n        return jsonify({\\'error\\': \\'Existe nick\\'})\\n    \\n    register = Usuario(nick=data[\\'nick\\'],password=generate_password_hash(data[\\'password\\']), e_mail=data[\\'e_mail\\'],foto_de_perfil=\"platon.jpg\")\\n    db.session.add(register)\\n    db.session.commit()\\n\\n\\n    token = jwt.encode({\\'nick\\' : data[\\'nick\\'], \\'exp\\': datetime.datetime.utcnow() + datetime.timedelta(minutes=30)}, app.config[\\'SECRET_KEY\\'])\\n    return jsonify({\\'token\\' : token.decode(\\'UTF-8\\')})\\n\\n\\n\\n@app.route(\\'/login\\', methods=[\\'POST\\'])\\ndef login():\\n    \\n\\n    data= request.get_json()\\n\\n    if \\'@\\' in data[\\'nickOcorreo\\']:\\n        user = Usuario.query.filter_by(e_mail=data[\\'nickOcorreo\\']).first()\\n    else:\\n        user = Usuario.query.filter_by(nick=data[\\'nickOcorreo\\']).first()\\n\\n    if not user:\\n        return jsonify({\\'error\\': \\'No existe ese usuario\\'})\\n    if not check_password_hash(user.password, data[\\'password\\']):\\n        return jsonify({\\'error\\': \\'Mal contrasea\\'}) \\n\\n\\n    token = jwt.encode({\\'nick\\' : data[\\'nickOcorreo\\'], \\'exp\\': datetime.datetime.utcnow() + datetime.timedelta(minutes=9999999)}, app.config[\\'SECRET_KEY\\'])\\n    return jsonify({\\'token\\' : token.decode(\\'UTF-8\\')})\\n\\n\\n\\n\\n@app.route(\\'/editarPerfil\\', methods=[\\'GET\\'])\\n@token_required\\ndef editarPerfilget(current_user):\\n    s = select([Usuario.Nombre_de_usuario,  Usuario.descripcion,Usuario.link, Usuario.foto_de_perfil]).where((Usuario.nick == current_user))\\n    result = db.session.execute(s)\\n\\n    seguidos= db.session.query(Sigue).filter(Sigue.Usuario_Nicka == current_user ).count()\\n    seguidores= db.session.query(Sigue).filter(Sigue.Usuario_Nickb == current_user ).count()\\n    nposts= db.session.query(Publicacion).filter(Publicacion.Usuario_Nicka == current_user ).count()\\n\\n    tema = select([Prefiere.tema]).where((Prefiere.Usuario_Nicka == current_user))\\n    temas = db.session.execute(tema)\\n    vector = []\\n    for row in temas:\\n        vector += row\\n    for row in result:\\n        fila = {\\n            \"nick\": current_user,\\n            \"nombre_de_usuario\":row[0],\\n            \"descripcion\":row[1],\\n            \"link\":row[2],\\n            \"foto_de_perfil\": \\'http://51.255.50.207:5000/display/\\' + row[3],\\n            \"nsiguiendo\": seguidos,\\n            \"nseguidores\": seguidores,\\n            \"nposts\": nposts,\\n            \"tematicas\": vector\\n            \\n        }\\n    return fila\\n\\n@app.route(\\'/display/<filename>\\')\\ndef foto(filename):\\n    return redirect(url_for(\\'static\\', filename=\\'fotosPerfil/\\' + filename),code = 301)\\n\\n\\n@app.route(\\'/editarPerfil\\', methods=[\\'POST\\'])\\n@token_required\\ndef editarPerfilpost(current_user):\\n\\n    data= request.get_json()\\n    user = Usuario.query.filter_by(nick=current_user).first()\\n    user.Nombre_de_usuario = data[\\'nombre_de_usuario\\']\\n    print(data[\\'nombre_de_usuario\\'])\\n    print(data[\\'descripcion\\'])\\n    print(data[\\'link\\'])\\n    print(data[\\'tematicas\\'])\\n    user.descripcion = data[\\'descripcion\\']\\n    user.link = data[\\'link\\']\\n    tematicas = data[\\'tematicas\\']\\n    for temas in tematicas:\\n        tema = Prefiere.query.filter_by(tema=temas).first()\\n        if not tema:\\n            tema = Prefiere(Usuario_Nicka=current_user, tema = temas)\\n            db.session.add(tema)\\n        \\n    \\n\\n    db.session.commit()\\n\\n    token = jwt.encode({\\'nick\\' : current_user, \\'exp\\': datetime.datetime.utcnow() + datetime.timedelta(minutes=30)}, app.config[\\'SECRET_KEY\\'])\\n    return jsonify({\\'token\\' : token.decode(\\'UTF-8\\')})\\n\\n\\n@app.route(\\'/actualizarImagen\\', methods=[\\'POST\\'])\\n@token_required\\ndef actualizarImagen(current_user):\\n    user = Usuario.query.filter_by(nick=current_user).first()\\n\\n    if request.files[\\'nueva_foto\\'] is not None: \\n\\n    \\tfile = request.files[\\'nueva_foto\\']\\n    \\tprint(request.files[\\'nueva_foto\\'])\\n    \\tfilename = secure_filename(file.filename)\\n    \\tfile.save(os.path.join(ABSOLUTE_PATH_TO_YOUR_FOLDER, filename))\\n    \\tuser.foto_de_perfil = filename\\n    \\tdb.session.commit()\\n\\n    token = jwt.encode({\\'nick\\' : current_user, \\'exp\\': datetime.datetime.utcnow() + datetime.timedelta(minutes=30)}, app.config[\\'SECRET_KEY\\'])\\n    return jsonify({\\'token\\' : token.decode(\\'UTF-8\\')})\\n\\n@app.route(\\'/subirPost\\', methods=[\\'POST\\'])\\n@token_required\\ndef subirPost(current_user):\\n\\n    data= request.get_json()\\n\\n    publicacion = Publicacion(descripcion=data[\\'descripcion\\'],Usuario_Nicka=current_user) \\n    db.session.add(publicacion)\\n    db.session.commit()\\n\\n    tematicas = data[\\'tematicas\\']\\n    for temas in tematicas:\\n        temita = Tematica.query.filter_by(tema=temas).first()\\n        if temita:\\n            nuevo = Trata_pub_del_tema(id=publicacion.id, tema = temita.tema)\\n            db.session.add(nuevo)\\n    db.session.commit()\\n    if (data[\\'tipo\\']==\"1\"): \\n        return jsonify({\\'id\\' : publicacion.id})\\n        \\n    elif(data[\\'tipo\\']==\"2\"): \\n        recomendacion = Recomendacion(link=data[\\'link\\'],titulo=data[\\'titulo\\'], autor = data[\\'autor\\'], id = publicacion.id)\\n        db.session.add(recomendacion)\\n        \\n    \\n    db.session.commit()\\n    token = jwt.encode({\\'nick\\' : current_user, \\'exp\\': datetime.datetime.utcnow() + datetime.timedelta(minutes=30)}, app.config[\\'SECRET_KEY\\'])\\n    return jsonify({\\'token\\' : token.decode(\\'UTF-8\\')})\\n\\n@app.route(\\'/subirPdf\\', methods=[\\'POST\\'])\\n@token_required\\ndef guardarPDF(current_user):\\n\\n    _id=request.headers[\\'id\\']\\n\\n    propia = Propia( id = _id)\\n    db.session.add(propia)\\n    db.session.commit()\\n    propia = Propia.query.filter_by(id=_id).first()\\n    if request.files[\\'pdf\\'] is not None:\\n        file = request.files[\\'pdf\\']\\n        \\n        filename = secure_filename(file.filename)\\n        file.save(os.path.join(ABSOLUTE_PATH_TO_YOUR_PDF_FOLDER, filename))\\n        propia.pdf = filename\\n        db.session.add(propia)\\n        db.session.commit()\\n    else:\\n        print(\"pdf nulisimo\")\\n\\n    token = jwt.encode({\\'nick\\' : current_user, \\'exp\\': datetime.datetime.utcnow() + datetime.timedelta(minutes=30)}, app.config[\\'SECRET_KEY\\'])\\n    return jsonify({\\'token\\' : token.decode(\\'UTF-8\\')})\\n\\n\\n@app.route(\\'/getPostsPropios\\', methods=[\\'GET\\'])\\n@token_required\\ndef getPostsPropios(current_user):\\n\\n       data= request.get_json()\\n\\n    x = select([Usuario.Nombre_de_usuario]).where((Usuario.nick == current_user))\\n    resultb = db.session.execute(x)\\n    Nombre_de_usuario = \"\"\\n    for b in resultb: \\n        Nombre_de_usuario=b.Nombre_de_usuario\\n    \\n    id = select([Publicacion.id]).where(Publicacion.Usuario_Nicka == current_user).order_by(Publicacion.id.desc())\\n    descripcion = select( [Publicacion.descripcion]).where(Publicacion.Usuario_Nicka == current_user).order_by(Publicacion.id.desc())\\n    timestamp = select([Publicacion.timestamp]).where(Publicacion.Usuario_Nicka == current_user).order_by(Publicacion.id.desc())\\n\\n    results = db.session.execute(id)\\n    resultss = db.session.execute(descripcion)\\n    resultsss = db.session.execute(timestamp)\\n\\n\\n    vector0 = []\\n    vector1 = []\\n    vector2 = []\\n    Gustas = []\\n    Comentarios= []\\n    Guardados= []\\n    for r in results:\\n        \\n        vector0 += r\\n        Gustas += str(db.session.query(Gusta).filter(Gusta.Usuario_Nicka == current_user, Gusta.id == \\'r\\' ).count())\\n        Comentarios += str(db.session.query(Comenta).filter(Comenta.Usuario_Nicka == current_user, Comenta.id == \\'r\\' ).count())\\n        Guardados += str(db.session.query(Guarda).filter(Guarda.Usuario_Nicka == current_user, Guarda.id == \\'r\\').count())\\n    for r in resultss:\\n        vector1 += r\\n    \\n    for r in resultsss:\\n        vector2 += r\\n    \\n\\n    vector3 = []\\n    vector4 = []\\n    vector5 = []\\n    for r in vector0:\\n        link = select([Recomendacion.link]).where((Recomendacion.id == r))\\n        titulo = select([Recomendacion.titulo]).where((Recomendacion.id == r))\\n        autor = select([Recomendacion.autor]).where((Recomendacion.id == r))\\n        resulta = db.session.execute(link)\\n        resultaa = db.session.execute(titulo)\\n        resultaaa = db.session.execute(autor)\\n\\n        for a in resulta:\\n            vector3 +=a\\n        for a in resultaa:\\n            vector4 +=a\\n        for a in resultaaa:\\n            vector5 +=a  \\n\\n        fila = {\\n            \"id\": r.id,\\n            \"nick\": current_user,\\n            \"descripcion\":r.descripcion,\\n            \"timestamp\":r.timestamp,\\n            \"pdf\": \\'http://51.255.50.207:5000/display2/\\' + a.pdf,\\n            \"nlikes\": Gustas,\\n            \"ncomentarios\": Comentarios,\\n            \"nguardados\": Guardados,\\n            \"usuario\": resulta.nombre_de_usuario\\n        }              \\n    fila = {\\n                \"id\": vector0,\\n                \"link\": vector3,\\n                \"titulo\": vector4,\\n                \"autor\": vector5,\\n                \"nick\": current_user,\\n                \"descripcion\": vector1,\\n                \"timestamp\": vector2,\\n                \"nlikes\": Gustas,\\n                \"ncomentarios\": Comentarios,\\n                \"nguardados\": Guardados,\\n                \"usuario\": Nombre_de_usuario,\\n                \\n                \\n                }\\n        \\n    return fila\\n            \\n\\n\\n@app.route(\\'/display2/<filename>\\')\\ndef pdf(filename):\\n    return redirect(url_for(\\'static\\', filename=\\'pdf/\\' + filename),code = 301)\\n\\n@app.route(\\'/getPostsRecomendados\\', methods=[\\'GET\\'])\\n@token_required\\ndef getPostsRecomendados(current_user):\\n\\n    data= request.get_json()\\n\\n    x = select([Usuario.Nombre_de_usuario]).where((Usuario.nick == current_user))\\n    resultb = db.session.execute(x)\\n    Nombre_de_usuario = \"\"\\n    for b in resultb: \\n        Nombre_de_usuario=b.Nombre_de_usuario\\n    \\n    id = select([Publicacion.id]).where(Publicacion.Usuario_Nicka == current_user).order_by(Publicacion.id.desc())\\n    descripcion = select( [Publicacion.descripcion]).where(Publicacion.Usuario_Nicka == current_user).order_by(Publicacion.id.desc())\\n    timestamp = select([Publicacion.timestamp]).where(Publicacion.Usuario_Nicka == current_user).order_by(Publicacion.id.desc())\\n\\n    results = db.session.execute(id)\\n    resultss = db.session.execute(descripcion)\\n    resultsss = db.session.execute(timestamp)\\n\\n\\n    vector0 = []\\n    vector1 = []\\n    vector2 = []\\n    Gustas = []\\n    Comentarios= []\\n    Guardados= []\\n    for r in results:\\n        \\n        vector0 += r\\n        Gustas += str(db.session.query(Gusta).filter(Gusta.Usuario_Nicka == current_user, Gusta.id == \\'r\\' ).count())\\n        Comentarios += str(db.session.query(Comenta).filter(Comenta.Usuario_Nicka == current_user, Comenta.id == \\'r\\' ).count())\\n        Guardados += str(db.session.query(Guarda).filter(Guarda.Usuario_Nicka == current_user, Guarda.id == \\'r\\').count())\\n    for r in resultss:\\n        vector1 += r\\n    \\n    for r in resultsss:\\n        vector2 += r\\n    \\n\\n    vector3 = []\\n    vector4 = []\\n    vector5 = []\\n    for r in vector0:\\n        link = select([Recomendacion.link]).where((Recomendacion.id == r))\\n        titulo = select([Recomendacion.titulo]).where((Recomendacion.id == r))\\n        autor = select([Recomendacion.autor]).where((Recomendacion.id == r))\\n        resulta = db.session.execute(link)\\n        resultaa = db.session.execute(titulo)\\n        resultaaa = db.session.execute(autor)\\n\\n        for a in resulta:\\n            vector3 +=a\\n        for a in resultaa:\\n            vector4 +=a\\n        for a in resultaaa:\\n            vector5 +=a                \\n    fila = {\\n                \"id\": vector0,\\n                \"link\": vector3,\\n                \"titulo\": vector4,\\n                \"autor\": vector5,\\n                \"nick\": current_user,\\n                \"descripcion\": vector1,\\n                \"timestamp\": vector2,\\n                \"nlikes\": Gustas,\\n                \"ncomentarios\": Comentarios,\\n                \"nguardados\": Guardados,\\n                \"usuario\": Nombre_de_usuario,\\n                \\n                \\n                }\\n        \\n    return fila\\n\\ndef check_email(email):\\n\\n    regex = \\'^[a-z0-9]+[\\\\._]?[a-z0-9]+[@]\\\\w+[.]\\\\w{2,3}$\\'\\n\\n    if(re.search(regex,email)):\\n        return True\\n    else:\\n        return False\\n\\n\\n\\ndef check_password(password):\\n\\n    regex = \\'^(?=.*[0-9])(?=.*[a-z])(?=.*[A-Z])(?=.*[*.!@$%^&(){}[]:;<>,.?/~_+-=|\\\\]).{8,32}$\\'\\n\\n    if(re.search(regex,password)):\\n        return True\\n    else:\\n        return False\\n\\n\\n\\nif __name__ == \\'__main__\\':\\n    app.run(debug=True)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 'summary': \"This is a Flask web application that appears to be a social media platform or similar service. It includes several routes and functionalities, such as:\\n\\n1. User registration and login\\n2. Uploading and displaying images (likely for posts)\\n3. Commenting on posts\\n4. Liking posts\\n5. Saving posts\\n6. Retrieving user profiles\\n7. Displaying PDF files\\n\\nKey features include:\\n\\n- User authentication with email and password validation\\n- Image upload functionality using Flask's `request` object\\n- Database interactions using SQLAlchemy ORM\\n- Templating with Jinja2 for HTML rendering\\n- Static file serving for images and PDFs\\n- Basic error handling and logging\\n\\nThe application uses a combination of Python, HTML, CSS, and JavaScript. It appears to be designed for a mobile-friendly interface.\\n\\nSome potential improvements or enhancements could include:\\n\\n- Adding more robust user authentication (e.g., OAuth)\\n- Implementing real-time notifications\\n- Improving the front-end design and responsiveness\\n- Adding search functionality\\n- Enhancing security measures (e.g., CSRF protection)\\n\\nOverall, this is a well-structured Flask application that demonstrates many common web development patterns.\"}\n",
            "Summary: This is a Flask web application that appears to be a social media platform or similar service. It includes several routes and functionalities, such as:\n",
            "\n",
            "1. User registration and login\n",
            "2. Uploading and displaying images (likely for posts)\n",
            "3. Commenting on posts\n",
            "4. Liking posts\n",
            "5. Saving posts\n",
            "6. Retrieving user profiles\n",
            "7. Displaying PDF files\n",
            "\n",
            "Key features include:\n",
            "\n",
            "- User authentication with email and password validation\n",
            "- Image upload functionality using Flask's `request` object\n",
            "- Database interactions using SQLAlchemy ORM\n",
            "- Templating with Jinja2 for HTML rendering\n",
            "- Static file serving for images and PDFs\n",
            "- Basic error handling and logging\n",
            "\n",
            "The application uses a combination of Python, HTML, CSS, and JavaScript. It appears to be designed for a mobile-friendly interface.\n",
            "\n",
            "Some potential improvements or enhancements could include:\n",
            "\n",
            "- Adding more robust user authentication (e.g., OAuth)\n",
            "- Implementing real-time notifications\n",
            "- Improving the front-end design and responsiveness\n",
            "- Adding search functionality\n",
            "- Enhancing security measures (e.g., CSRF protection)\n",
            "\n",
            "Overall, this is a well-structured Flask application that demonstrates many common web development patterns.\n",
            "\n",
            "Processing batch batch_3.json, entry ID: 3\n",
            "Entry: {'code': 'import pprint\\nimport re  \\n\\nimport six\\n\\n\\nclass ApiArtifact(object):\\n    \\n\\n    \\n    swagger_types = {\\n        \\'name\\': \\'str\\',\\n        \\'checksum\\': \\'str\\',\\n        \\'id\\': \\'str\\',\\n        \\'names\\': \\'list[str]\\'\\n    }\\n\\n    attribute_map = {\\n        \\'name\\': \\'name\\',\\n        \\'checksum\\': \\'checksum\\',\\n        \\'id\\': \\'id\\',\\n        \\'names\\': \\'names\\'\\n    }\\n\\n    def __init__(self, name=None, checksum=None, id=None, names=None):  \\n          \\n\\n        self._name = None\\n        self._checksum = None\\n        self._id = None\\n        self._names = None\\n        self.discriminator = None\\n\\n        if name is not None:\\n            self.name = name\\n        if checksum is not None:\\n            self.checksum = checksum\\n        if id is not None:\\n            self.id = id\\n        if names is not None:\\n            self.names = names\\n\\n    @property\\n    def name(self):\\n        \\n        return self._name\\n\\n    @name.setter\\n    def name(self, name):\\n        \\n\\n        self._name = name\\n\\n    @property\\n    def checksum(self):\\n        \\n        return self._checksum\\n\\n    @checksum.setter\\n    def checksum(self, checksum):\\n        \\n\\n        self._checksum = checksum\\n\\n    @property\\n    def id(self):\\n        \\n        return self._id\\n\\n    @id.setter\\n    def id(self, id):\\n        \\n\\n        self._id = id\\n\\n    @property\\n    def names(self):\\n        \\n        return self._names\\n\\n    @names.setter\\n    def names(self, names):\\n        \\n\\n        self._names = names\\n\\n    def to_dict(self):\\n        \\n        result = {}\\n\\n        for attr, _ in six.iteritems(self.swagger_types):\\n            value = getattr(self, attr)\\n            if isinstance(value, list):\\n                result[attr] = list(map(\\n                    lambda x: x.to_dict() if hasattr(x, \"to_dict\") else x,\\n                    value\\n                ))\\n            elif hasattr(value, \"to_dict\"):\\n                result[attr] = value.to_dict()\\n            elif isinstance(value, dict):\\n                result[attr] = dict(map(\\n                    lambda item: (item[0], item[1].to_dict())\\n                    if hasattr(item[1], \"to_dict\") else item,\\n                    value.items()\\n                ))\\n            else:\\n                result[attr] = value\\n        if issubclass(ApiArtifact, dict):\\n            for key, value in self.items():\\n                result[key] = value\\n\\n        return result\\n\\n    def to_str(self):\\n        \\n        return pprint.pformat(self.to_dict())\\n\\n    def __repr__(self):\\n        \\n        return self.to_str()\\n\\n    def __eq__(self, other):\\n        \\n        if not isinstance(other, ApiArtifact):\\n            return False\\n\\n        return self.__dict__ == other.__dict__\\n\\n    def __ne__(self, other):\\n        \\n        return not self == other\\n', 'summary': \"This Python code defines a class `ApiArtifact` that represents an artifact in an API. The class includes properties for the artifact's name, checksum, ID, and names. It provides getter and setter methods for each property to ensure encapsulation. Additionally, it includes methods to convert the object to a dictionary (`to_dict`), to a string representation (`to_str`), and to compare objects for equality (`__eq__` and `__ne__`). The class uses the `six` library to handle compatibility between Python 2 and Python 3.\"}\n",
            "Summary: This Python code defines a class `ApiArtifact` that represents an artifact in an API. The class includes properties for the artifact's name, checksum, ID, and names. It provides getter and setter methods for each property to ensure encapsulation. Additionally, it includes methods to convert the object to a dictionary (`to_dict`), to a string representation (`to_str`), and to compare objects for equality (`__eq__` and `__ne__`). The class uses the `six` library to handle compatibility between Python 2 and Python 3.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Do the first 100 entries\n",
        "\n",
        "for i in range(10):\n",
        "    if i < len(batch_files):\n",
        "        print(f\"Processing batch {i}\")\n",
        "        process_batch_file(f\"batches/batch_{i}.json\")\n",
        "    else:\n",
        "        print(f\"Batch {i} does not exist - fewer than 10 batches total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_summaries_to_json(\"cleaned_data.json\", \"summarized_code.json\")\n",
        "\n",
        "print(\"Summaries added and saved to summarized_code.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
